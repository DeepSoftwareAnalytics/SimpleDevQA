[
    {
        "link": "https://learn.openwaterfoundation.org/owf-learn-linux-shell/best-practices/best-practices",
        "document": "This page lists best practices, based on industry standards and first-hand experience.\n‚Ä¢ Indicate the shell to run in the first line of shell scripts\n‚Ä¢ Check whether the script is running in the correct folder\n‚Ä¢ Learn how to use shell features\n‚Ä¢ Use functions to create reusable blocks of code\n\nIt is often necessary to perform a number of steps to process data and/or automate program calls to complete a task. These steps may be a one-time task, but often will need to be repeated in the future. Rather than relying on written or electronic notes, email, etc., creating a short shell script to memorialize the task can ensure that knowledge is retained. The script can also be enhanced over time to provide more functionality.\n\nA useful best practice is to create a simple shell script in the files being processed, with comments in the shell script to explain its purpose and use. Additionally, a file can be created to provide formatted explanation of the shell script.\n\nThe script and file can be managed in a version control system to track changes over time and serve as a backup.\n\nAny script worth creating and using is probably worth tracking in a version control system. There is nothing more frustrating that asking \"where did I put that script?\" Therefore, use Git and a cloud-hosted version control system like GitHub or Bitbucket to maintain the script. This also provides information about the author so that questions and bugs can be dealt with, for example via the repository issues page.\n\nIf a true version control system is not used, the script can also be saved in a knowledge base or other information platform.\n\nIndicate the shell to run in the first line of shell scripts\n\nA shell script (actually any script) can be written in various languages and language standards. Shell scripts can be written for , , or other command shells. Do not assume that the default command shell that will be used will be correct. Therefore, always specify the shell to run, for example:\n\nIt is common that code is rewritten simply because the original author's work is not understandable. This results in extra cost, potentially bugs, and potentially loss in functionality if the original code was not understood. The urge to rewrite code may be because of a lack of documentation, confusing logic, bad programming style, use of obscure or advanced language syntax without explanation, or other reasons.\n\nDocumenting code at the time it is being written is the best time to document code. If updating code, read the code comments again and if they do not make sense, clarify the comments. A simple rule is to ask \"will the next person working on this code understand it?\"\n\nThe following are some basic guidelines to making code understandable:\n‚Ä¢ Add full grammar comments to code. Don't force people to assume what you mean. Use proper grammar. Sloppy comments and incomplete thoughts can indicate sloppy code.\n‚Ä¢ Explain complex syntax. Don't assume that the next programmer will have a PhD in shell scripting. Yes, every answer can be found on the web, but the web also contains many misleading and out of date examples.\n‚Ä¢ Use variable and function names that are verbose enough to provide context. Code should read like a clear process. Using appropriate names will also reduce the need for code comments.\n‚Ä¢ Be consistent in names and style. If editing someone else's code, try to be consistent with the original style if possible.\n‚Ä¢ Use double or single quotes around strings, as appropriate, to indicate strings.\n‚Ä¢ Use appropriate indentation consistently. Tabs are OK and if used should not be mixed with spaces. Spaces if used should be in groups of 2 or 4. Do not assume that the next person to edit the code will use the same convention in their editor, and make it obvious what is being used by being consistent.\n\nCheck whether the script is running in the correct folder\n\nThe folder from which a script is run often has a large impact on the functionality of the script. Options include:\n‚Ä¢ Allow the script to run in any folder since the task does not depend on the location.\n‚Ä¢ Allow the script to run in any folder and locate input and output based on the environment, such as detecting the user's home folder or a standard folder structure within the environment.\n‚Ä¢ Require the script to be run from a certain folder because input and output folders are relative to the run folder.\n\nGreat pains may need to be taken in a script's code to ensure that a script runs correctly in any folder, in order to ensure that input files are found and output is created in the proper location. However, for simple tasks, it may be easier to require running from a specific folder.\n\nA best practice is to put checks in place, if necessary, to ensure that the script is running in the correct folder. For example, the following does a simple check to make sure that the script is running in a folder. The following check is not fool-proof because running in one folder and specifying a path to another folder would pass the test, but the basic check helps prevent many issues.\n\nA more robust solution is to allow the script to be run from any folder, including finding in the or specifying the path to the script manually. In this case the following syntax can be used to determine the location of the script, and other folders and files can be located relative to that location, assuming there is a standard.\n\nShell scripts can be difficult to troubleshoot, especially if the script coding is not clear and the script user did not write the script. Therefore, it is often helpful to print important configuration information at the start of the script. For example use statements to print important environment variable names and values, names of input files, etc.\n\nIf the script is more advanced, such output could be printed only when a command line parameter is specified, such as .\n\nLogging for shell scripts can be implemented in various ways. The standard for Linux is often to output to the stream (for example ). The script output can then be redirected into a file or piped to another program for further processing. However, diagnostic or progress messages that are separate from analytical output generally need to be separated from the general output.\n\nDepending on the complexity of the script, it may be very useful to save logging messages to a file. This can be done by echoing output to a file in the current folder or a special location. The author of the script probably has a good idea of how logging should be done because they use it themselves. A best practice is to implement options for logging in a way that will benefit users of the script and then provide documentation to explain options. This will help users, especially those who may not fully understand how to do logging with redirection.\n\nThe following is a basic example of implementing logging:\n\nA shell script is only truly useful if someone other than the original author can use it. Therefore, all shell scripts should have documentation in one or more forms, depending on the significance of the script, including:\n‚Ä¢ Code comments, enough to understand the purpose, and good in-line comments.\n‚Ä¢ A or similar function that prints basic usage, run via or , or by default to show user available command options.\n‚Ä¢ User documentation, such as this documentation.\n\nTechnologies can be complicated and shell programming is no different. It is often necessary to search the web for a solution or comparative example to perform a task. Once the solution is coded, it can be difficult to understand the approach. Therefore, include a comment in the code with the link to the web resource that explained the solution. Don't make the next programmer relearn the same material from terse code. Allow the code to be a teaching tool that can be maintained by the next developer. Also, including links is a way to give credit to the person that helped solve a technical issue.\n\nLearn how to use shell features\n\nThere is always a brute force \"quick and dirty\" way to do things, such as by copying and pasting code from a web search. However, there is a balance between the technical debt of quick and dirty solutions, and more elegant solutions that take more time to learn, but are more robust and maintainable in the long run. In particular, quick and dirty solutions that negatively impact the user experience and resources spent by other developers should be avoided. Shell programmers should take the time to learn shell programming concepts and features such as command line parsing, functions, log files, etc. so that they can improve shell script quality and functionality. This documentation is an attempt to provide easily understood examples that go beyond the often terse and trivial examples on the web.\n\nUse functions to create reusable blocks of code\n\nThis should go without saying, but modular code tends to be easier to maintain, especially when a script becomes long. Every script author should consider using functions to organize script functionality. Functions also simplify sharing code between scripts since functions can be copied and pasted between scripts.\n\nThe alternative to writing a function is to write a separate script that can be called with an appropriate command line. This approach is OK as long as the called script is located in a location that can be found by the calling script."
    },
    {
        "link": "https://cycle.io/learn/shell-scripting-best-practices",
        "document": "Shell scripting is a powerful tool in the Linux environment, enabling automation, configuration management, and the streamlining of repetitive tasks. Adhering to best practices when writing shell scripts ensures that your scripts are reliable, maintainable, and efficient. This guide covers essential best practices to follow when creating shell scripts.\n\nUse clear and descriptive variable names to make your script more readable and maintainable. Avoid single-letter variables except for loop counters or very short-lived variables. For example, instead of using , use or .\n\nComment your code generously to explain the purpose of complex sections or commands. This is especially important in scripts that may be revisited after a long time or shared with others. Comments should be concise but informative.\n\nUse at the beginning of your script to ensure the script exits immediately if any command fails. This prevents subsequent commands from running in an unexpected state.\n\nCheck the exit codes of commands to handle errors gracefully. Incorporate custom error messages and exit codes where necessary to make debugging easier.\n\nIf you intend your script to run in different environments, avoid using bash-specific features ( ). Instead, stick to POSIX-compliant syntax, which ensures compatibility across different Unix-like systems.\n\nAlways start your scripts with a shebang ( ) to specify the interpreter. This practice avoids confusion and ensures that the script is executed with the correct shell.\n\nFunctions allow you to structure your script more clearly and avoid repetitive code. Grouping related tasks into functions makes the script easier to read and maintain.\n\nUse descriptive names for functions, and stick to a consistent naming convention. This makes it easier to understand what each function does at a glance.\n\nAlways quote variables to prevent word splitting and globbing issues, especially when dealing with user input or file paths.\n\nWherever possible, prefer over for better portability and predictable behavior across different environments.\n\nThe command can execute arbitrary code and pose a security risk. Avoid using it unless absolutely necessary, and ensure inputs are sanitized if you do use it.\n\nDo not hard-code sensitive information like passwords or API keys in your scripts. Instead, use environment variables or configuration files with appropriate permissions.\n\nA script should ideally do one thing and do it well. Avoid creating overly complex scripts that try to handle too many tasks. If your script grows too large, consider splitting it into multiple scripts.\n\nRelying on too many external commands or tools can make your script fragile and hard to port. Stick to built-in shell commands whenever possible, and document any external dependencies clearly."
    },
    {
        "link": "https://shellscript.sh",
        "document": "This tutorial is written to help people understand some of the basics of shell script programming (aka shell scripting), and hopefully to introduce some of the possibilities of simple but powerful programming available under the Bourne shell. As such, it has been written as a basis for one-on-one or group tutorials and exercises, and as a reference for subsequent use.\n\nGetting The Most Recent Version Of This Tutorial\n\nYou are reading Version , last updated .\n\nThe most recent version of this tutorial is always available at: https://www.shellscript.sh. Always check there for the latest copy. (If you are reading this at some different address, it is probably a copy of the real site, and therefore may be out of date).\n\nSteve Bourne wrote the original Bourne shell which appeared in the Seventh Edition Bell Labs Research version of Unix. Many variants have come and gone over time (csh, ksh, and so on).\n\nThis tutorial restricts itself to being Bourne shell compatible, to provide a baseline. This tutorial covers all shell scripting basics. The Shell Scripting Examples section of the tutorial adds additional examples in particular of how the Bash shell provides additional useful functionality over the standard Bourne shell.\n\nThis tutorial assumes some prior experience; namely:\n‚Ä¢ Use of an interactive Unix/Linux shell\n‚Ä¢ Minimal programming knowledge - use of variables, functions, is useful background knowledge\n‚Ä¢ Understanding of some Unix/Linux commands, and competence in using some of the more common ones. (ls, cp, echo, etc)\n‚Ä¢ Programmers of ruby, perl, python, C, Pascal, or any programming language (even BASIC) who can maybe read shell scripts, but don't feel they understand exactly how they work.\n\nYou may want to review some of the feedback that this tutorial has received to see how useful you might find it.\n\nTypographical Conventions Used in This Tutorial\n\nCode segments and script output will be displayed as monospaced text. Command-line entries will be preceded by the Dollar sign ($). If your prompt is different, enter the command:\n\nThen your interactions should match the examples given (such as below). Script output (such as \"Hello World\" below) is displayed at the start of the line.\n\nEntire scripts will be shown with a like this, and include a reference to the plain text of the script, where available like this: my-script.sh Note that to make a file executable, you must set the eecutable bit, and for a shell script, theeadable bit must also be set. So it is likely that you will need to change the permissions on your script, to make it executable. If your script is named \"myscript.sh\" then you will need to change its permissions, like this:"
    },
    {
        "link": "https://tldp.org/LDP/abs/abs-guide.pdf",
        "document": ""
    },
    {
        "link": "https://google.github.io/styleguide/shellguide.html",
        "document": "Authored, revised and maintained by many Googlers.\n\nWhich Shell to Use\n\nBash is the only shell scripting language permitted for executables.\n\nExecutables must start with and minimal flags. Use to set shell options so that calling your script as does not break its functionality.\n\nRestricting all executable shell scripts to bash gives us a consistent shell language that‚Äôs installed on all our machines. In particular, this means there is generally no need to strive for POSIX-compatibility or otherwise avoid ‚Äúbashisms‚Äù.\n\nThe only exception to the above is where you‚Äôre forced to by whatever you‚Äôre coding for. For example some legacy operating systems or constrained execution environments may require plain Bourne shell for certain scripts.\n\nWhen to use Shell\n\nShell should only be used for small utilities or simple wrapper scripts.\n\nWhile shell scripting isn‚Äôt a development language, it is used for writing various utility scripts throughout Google. This style guide is more a recognition of its use rather than a suggestion that it be used for widespread deployment.\n‚Ä¢ If you‚Äôre mostly calling other utilities and are doing relatively little data manipulation, shell is an acceptable choice for the task.\n‚Ä¢ If performance matters, use something other than shell.\n‚Ä¢ If you are writing a script that is more than 100 lines long, or that uses non-straightforward control flow logic, you should rewrite it in a more structured language now. Bear in mind that scripts grow. Rewrite your script early to avoid a more time-consuming rewrite at a later date.\n‚Ä¢ When assessing the complexity of your code (e.g. to decide whether to switch languages) consider whether the code is easily maintainable by people other than its author.\n\nExecutables should have a extension or no extension.\n‚Ä¢ If the executable will have a build rule that renames the source file then prefer to use a extension. This enables you to use the recommended naming convention, with a source file like and a build rule named .\n‚Ä¢ If the executable will be added directly to the user‚Äôs , then prefer to use no extension. It is not necessary to know what language a program is written in when executing it and shell doesn‚Äôt require an extension so we prefer not to use one for executables that will be directly invoked by users. At the same time, consider whether it is preferable to deploy the output of a build rule rather than deploying the source file directly.\n‚Ä¢ If neither of the above apply, then either choice is acceptable.\n\nLibraries must have a extension and should not be executable.\n\nSUID and SGID are forbidden on shell scripts.\n\nThere are too many security issues with shell that make it nearly impossible to secure sufficiently to allow SUID/SGID. While bash does make it difficult to run SUID, it‚Äôs still possible on some platforms which is why we‚Äôre being explicit about banning it.\n\nUse to provide elevated access if you need it.\n\nAll error messages should go to .\n\nThis makes it easier to separate normal status from actual issues.\n\nA function to print out error messages along with other status information is recommended.\n\nStart each file with a description of its contents.\n\nEvery file must have a top-level comment including a brief overview of its contents. A copyright notice and author information are optional.\n\nAny function that is not both obvious and short must have a function header comment. Any function in a library must have a function header comment regardless of length or complexity.\n\nIt should be possible for someone else to learn how to use your program or to use a function in your library by reading the comments (and self-help, if provided) without reading the code.\n\nAll function header comments should describe the intended API behaviour using:\n‚Ä¢ Globals: List of global variables used and modified.\n‚Ä¢ Returns: Returned values other than the default exit status of the last command run.\n\nComment tricky, non-obvious, interesting or important parts of your code.\n\nThis follows general Google coding comment practice. Don‚Äôt comment everything. If there‚Äôs a complex algorithm or you‚Äôre doing something out of the ordinary, put a short comment in.\n\nUse TODO comments for code that is temporary, a short-term solution, or good-enough but not perfect.\n\nThis matches the convention in the C++ Guide.\n\ns should include the string in all caps, followed by the name, e-mail address, or other identifier of the person with the best context about the problem referenced by the . The main purpose is to have a consistent that can be searched to find out how to get more details upon request. A is not a commitment that the person referenced will fix the problem. Thus when you create a , it is almost always your name that is given.\n\nWhile you should follow the style that‚Äôs already there for files that you‚Äôre modifying, the following are required for any new code.\n\nUse blank lines between blocks to improve readability. Indentation is two spaces. Whatever you do, don‚Äôt use tabs. For existing files, stay faithful to the existing indentation.\n\nException: The only exception for using tabs is for the body of tab-indented here-document.\n\nIf you have to write literal strings that are longer than 80 characters, this should be done with a here document or an embedded newline if possible.\n\nWords that are longer than 80 chars and can‚Äôt sensibly be split are ok, but where possible these items should be on a line of their own, or factored into a variable. Examples include file paths and URLs, particularly where string-matching them (such as ) is valuable for maintenance.\n\nPipelines should be split one per line if they don‚Äôt all fit on one line.\n\nIf a pipeline all fits on one line, it should be on one line.\n\nIf not, it should be split at one pipe segment per line with the pipe on the newline and a 2 space indent for the next section of the pipe. should be consistently used to indicate line continuation. This applies to a chain of commands combined using as well as to logical compounds using and .\n\nThis helps readability when distinguishing a pipeline from a regular long command continuation, particularly if the line is using both.\n\nComments will need to precede the whole pipeline. If the comment and pipeline are large and complex, then it is worth considering moving low level details of them aside by using a helper function.\n\nPut and on the same line as the , , or .\n\nControl flow statements in shell are a bit different, but we follow the same principles as with braces when declaring functions. That is: and should be on the same line as the / / / / . should be on its own line and closing statements ( and ) should be on their own line vertically aligned with the opening statement.\n\nAlthough it is possible to omit in for loops we recommend consistently including it for clarity.\n‚Ä¢ A one-line alternative needs a space after the close parenthesis of the pattern and before the .\n‚Ä¢ Long or multi-command alternatives should be split over multiple lines with the pattern, actions, and on separate lines.\n\nThe matching expressions are indented one level from the and . Multiline actions are indented another level. In general, there is no need to quote match expressions. Pattern expressions should not be preceded by an open parenthesis. Avoid the and notations.\n\nSimple commands may be put on the same line as the pattern and as long as the expression remains readable. This is often appropriate for single-letter option processing. When the actions don‚Äôt fit on a single line, put the pattern on a line on its own, then the actions, then also on a line of its own. When on the same line as the actions, use a space after the close parenthesis of the pattern and another before the .\n\nIn order of precedence: Stay consistent with what you find; quote your variables; prefer over .\n\nThese are strongly recommended guidelines but not mandatory regulation. Nonetheless, the fact that it‚Äôs a recommendation and not mandatory doesn‚Äôt mean it should be taken lightly or downplayed.\n\nThey are listed in order of precedence.\n‚Ä¢ Stay consistent with what you find for existing code.\n‚Ä¢ Quote variables, see Quoting section below.\n‚Ä¢ Don‚Äôt brace-delimit single character shell specials / positional parameters, unless strictly necessary or avoiding deep confusion.\n\nNOTE: Using braces in is not a form of quoting. ‚ÄúDouble quotes‚Äù must be used as well.\n‚Ä¢ Always quote strings containing variables, command substitutions, spaces or shell meta characters, unless careful unquoted expansion is required or it‚Äôs a shell-internal integer (see next point).\n‚Ä¢ Use arrays for safe quoting of lists of elements, especially command-line flags. See Arrays below.\n‚Ä¢ Optionally quote shell-internal, readonly special variables that are defined to be integers: , , , . Prefer quoting of ‚Äúnamed‚Äù internal integer variables, e.g. PPID etc for consistency.\n‚Ä¢ Prefer quoting strings that are ‚Äúwords‚Äù (as opposed to command options or path names).\n‚Ä¢ Be aware of the quoting rules for pattern matches in . See the Test, , and section below.\n‚Ä¢ Use unless you have a specific reason to use , such as simply appending the arguments to a string in a message or log.\n\nThe ShellCheck project identifies common bugs and warnings for your shell scripts. It is recommended for all scripts, large or small.\n\nUse instead of backticks.\n\nNested backticks require escaping the inner ones with . The format doesn‚Äôt change when nested and is easier to read.\n\nis preferred over , and .\n\nreduces errors as no pathname expansion or word splitting takes place between and . In addition, allows for pattern and regular expression matching, while does not.\n\nFor the gory details, see E14 in the Bash FAQ\n\nUse quotes rather than filler characters where possible.\n\nBash is smart enough to deal with an empty string in a test. So, given that the code is much easier to read, use tests for empty/non-empty strings or empty strings rather than filler characters.\n\nTo avoid confusion about what you‚Äôre testing for, explicitly use or .\n\nFor clarity, use for equality rather than even though both work. The former encourages the use of and the latter can be confused with an assignment. However, be careful when using and in which performs a lexicographical comparison. Use or and for numerical comparison.\n\nUse an explicit path when doing wildcard expansion of filenames.\n\nAs filenames can begin with a , it‚Äôs a lot safer to expand wildcards with instead of .\n\nEval munges the input when used for assignment to variables and can set variables without making it possible to check what those variables were.\n\nBash arrays should be used to store lists of elements, to avoid quoting complications. This particularly applies to argument lists. Arrays should not be used to facilitate more complex data structures (see When to use Shell above).\n\nArrays store an ordered collection of strings, and can be safely expanded into individual elements for a command or loop.\n\nUsing a single string for multiple command arguments should be avoided, as it inevitably leads to authors using or trying to nest quotes inside the string, which does not give reliable or readable results and leads to needless complexity.\n‚Ä¢ Using Arrays allows lists of things without confusing quoting semantics. Conversely, not using arrays leads to misguided attempts to nest quoting inside a string.\n‚Ä¢ Arrays make it possible to safely store sequences/lists of arbitrary strings, including strings containing whitespace.\n\nArrays should be used to safely create and pass around lists. In particular, when building a set of command arguments, use arrays to avoid confusing quoting issues. Use quoted expansion ‚Äì ‚Äì to access arrays. However, if more advanced data manipulation is required, shell scripting should be avoided altogether; see above.\n\nUse process substitution or the builtin (bash4+) in preference to piping to . Pipes create a subshell, so any variables modified within a pipeline do not propagate to the parent shell.\n\nThe implicit subshell in a pipe to can introduce subtle bugs that are hard to track down.\n\nUsing process substitution also creates a subshell. However, it allows redirecting from a subshell to a without putting the (or any other command) in a subshell.\n\nAlternatively, use the builtin to read the file into an array, then loop over the array‚Äôs contents. Notice that (for the same reason as above) you need to use a process substitution with rather than a pipe, but with the advantage that the input generation for the loop is located before it, rather than after.\n\nAlways use or rather than or or .\n\nNever use the syntax, the command, or the built-in.\n\nand don‚Äôt perform numerical comparison inside expressions (they perform lexicographical comparisons instead; see Testing Strings). For preference, don‚Äôt use at all for numeric comparisons, use instead.\n\nIt is recommended to avoid using as a standalone statement, and otherwise be wary of its expression evaluating to zero\n‚Ä¢ particularly with enabled. For example, will cause the shell to exit.\n\nStylistic considerations aside, the shell‚Äôs built-in arithmetic is many times faster than .\n\nWhen using variables, the (and ) forms are not required within . The shell knows to look up for you, and omitting the leads to cleaner code. This is slightly contrary to the previous rule about always using braces, so this is a recommendation only.\n\nAlthough commonly seen in files, aliases should be avoided in scripts. As the Bash manual notes:\n\nAliases are cumbersome to work with because they require carefully quoting and escaping their contents, and mistakes can be hard to notice.\n\nFunctions provide a superset of alias‚Äô functionality and should always be preferred. .\n\nLower-case, with underscores to separate words. Separate libraries with . Parentheses are required after the function name. The keyword is optional, but must be used consistently throughout a project.\n\nIf you‚Äôre writing single functions, use lowercase and separate words with underscore. If you‚Äôre writing a package, separate package names with . However, functions intended for interactive use may choose to avoid colons as it can confuse bash auto-completion.\n\nBraces must be on the same line as the function name (as with other languages at Google) and no space between the function name and the parenthesis.\n\nThe keyword is extraneous when ‚Äú()‚Äù is present after the function name, but enhances quick identification of functions.\n\nSame as for function names.\n\nVariables names for loops should be similarly named for any variable you‚Äôre looping through.\n\nConstants and anything exported to the environment should be capitalized, separated with underscores, and declared at the top of the file.\n\nFor the sake of clarity or is recommended vs. the equivalent commands. You can do one after the other, like:\n\nIt‚Äôs OK to set a constant at runtime or in a conditional, but it should be made readonly immediately afterwards.\n\nLowercase, with underscores to separate words if desired.\n\nThis is for consistency with other code styles in Google: or but not .\n\nEnsure that local variables are only seen inside a function and its children by using when declaring them. This avoids polluting the global namespace and inadvertently setting variables that may have significance outside the function.\n\nDeclaration and assignment must be separate statements when the assignment value is provided by a command substitution; as the builtin does not propagate the exit code from the command substitution.\n\nPut all functions together in the file just below constants. Don‚Äôt hide executable code between functions. Doing so makes the code difficult to follow and results in nasty surprises when debugging.\n\nIf you‚Äôve got functions, put them all together near the top of the file. Only includes, statements and setting constants may be done before declaring functions.\n\nA function called is required for scripts long enough to contain at least one other function.\n\nIn order to easily find the start of the program, put the main program in a function called as the bottom-most function. This provides consistency with the rest of the code base as well as allowing you to define more variables as (which can‚Äôt be done if the main code is not a function). The last non-comment line in the file should be a call to :\n\nObviously, for short scripts where it‚Äôs just a linear flow, is overkill and so is not required.\n\nFor unpiped commands, use or check directly via an statement to keep it simple.\n\nBash also has the variable that allows checking of the return code from all parts of a pipe. If it‚Äôs only necessary to check success or failure of the whole pipe, then the following is acceptable:\n\nHowever, as will be overwritten as soon as you do any other command, if you need to act differently on errors based on where it happened in the pipe, you‚Äôll need to assign to another variable immediately after running the command (don‚Äôt forget that is a command and will wipe out ).\n\nGiven the choice between invoking a shell builtin and invoking a separate process, choose the builtin.\n\nWe prefer the use of builtins such as the Parameter Expansion functionality provided by as it‚Äôs more efficient, robust, and portable (especially when compared to things like ). See also the operator.\n\nWhen in Doubt: Be Consistent\n\nUsing one style consistently through our codebase lets us focus on other (more important) issues. Consistency also allows for automation. In many cases, rules that are attributed to ‚ÄúBe Consistent‚Äù boil down to ‚ÄúJust pick one and stop worrying about it‚Äù; the potential value of allowing flexibility on these points is outweighed by the cost of having people argue over them.\n\nHowever, there are limits to consistency. It is a good tie breaker when there is no clear technical argument, nor a long-term direction. Consistency should not generally be used as a justification to do things in an old style without considering the benefits of the new style, or the tendency of the codebase to converge on newer styles over time."
    },
    {
        "link": "https://unix.com/shell-programming-and-scripting/101738-how-calculate-netwrk-ip-address-netmask-using-bitwise-shell-script.html",
        "document": ""
    },
    {
        "link": "https://stackoverflow.com/questions/43876891/given-ip-address-and-netmask-how-can-i-calculate-the-subnet-range-using-bash",
        "document": "Well, you already have the network address. The first host address is just one higher than the network address, which is easy to calculate since you know the low-order bits are zeroes (so there's no overflow to high bytes...)\n\nThen the broadcast address. That's just the address where all the host address bits are set to ones. Those are the bits where the subnet mask is zero. So, to get the broadcast address, invert the mask and do a bitwise . The last host address is just one less from that.\n\nBash's arithmetic supports the same bitwise operators as C and most other languages, so for , for , for xor and for negation. From what you already have, you should be able to produce the missing ones."
    },
    {
        "link": "https://community.unix.com/t/how-to-calculate-netwrk-from-ip-address-and-netmask-using-bitwise-and-in-shell-script/232426",
        "document": "I am having two variables\n\n IP=\"10.150.12.1\"\n\n netmask=\"255.255.255.0\" To get network number, I know that a bitwise & will help.\n\n networkno=IP & netmask I am getting the following error\n\n ./try.sh[5]: 255.255.255.0: not found. What's the mistake in the code.\n\nThe ampersand (&) puts processes in the background, so you are putting networkno=$ip in the background, then trying to execute 255.255.255.0. What is it that you want to accomplish? What's the output you are expecting?\n\n If you give 10.150.12.1 and 255.255.255.0, are you expecting the output to be 10.150.12.0? Or .1? Or .0 ? or 10.150.12.1/24 ?\n\nthanks for the inputs.\n\n What I want is\n\n if IP=\"10.150.12.1\" and netmask=\"255.255.255.0\",\n\n I want networkno to be 10.150.12. I do not know how to change strings into integers.\n\n Also, I have to use shell scripting only. Please help me with the code to accomplish the above requirement\n\n[...] I have to use shell scripting only.[...] Why Shell code only? A C program to calculate IP-Address related stuff (or about anything on a bit manipulation level) can easily be written in ANSI C which will compile on any platform, and it's quite trivial to do so (was one of my first C assignments in school) As for the conversion, it would be something like this pseudo-code. Split on '.' Result=0 For each element Result *= 256 Result += element So 10.150.20.1 would be converted to 177605633. Do this for both the IP and the Netmask and do your &-magic. To get something back do: which will give you the least significant byte first, so you'll probably have to switch them.\n\nHere is how to do it using ksh93. Here is the output for the IP address and subnet mask you supplied followed by the output for a sightly different subnet mask (just to show the difference)\n\nfpmurphy, thanks for your code. I've now changed it to work with bash and included a few other IP/CIDR/Subnet mask related functions. Sorry if my code is not so optimized, but this was my first try \n\n I'm trying to put together code to run on a WRT54G router with DD-WRT firmware. Eventually I want it to remove redundant/encapsulated routing table entries. #!/bin/bash # Convert IP to int function ip_to_int() { SaveIFS=$IFS IFS=. typeset -a IParr=($1) IFS=$SaveIFS result=0 for ((i=0;i<4;i+=1)); do result=$(($result * 256)) result=$((${IParr[$i]} + $result)) done echo $result } # Convert IP from int function int_to_ip() { result=$1 byte=\"\" for ((i=0;i<3;i+=1)); do byte=.$(($result % 256))$byte result=$(($result / 256)) done echo $result$byte } # Calculate number of addresses in subnet function cidr_to_netsize() { echo $((1 << 32 - $1)) } # Calculate bitmask for the 'host' part function cidr_to_hostmask() { echo $(($(($((1 << $1)) - 1)) << $((32 - $1)))) } # Get the Network destination from the IP & Subnet mask function get_network_address() { SaveIFS=$IFS IFS=. typeset -a IParr=($1) typeset -a NMarr=($2) IFS=$SaveIFS echo $((${IParr[0]} & ${NMarr[0]})).$((${IParr[1]} & ${NMarr[1]})).$((${IParr[2]} & ${NMarr[2]})).$((${IParr[3]} & ${NMarr[3]})) } # Get the broadcast address from the IP & Subnet mask function get_broadcast_address() { SaveIFS=$IFS IFS=. typeset -a IParr=($1) typeset -a NMarr=($2) IFS=$SaveIFS echo $((${IParr[0]} | (255 ^ ${NMarr[0]}))).$((${IParr[1]} | (255 ^ ${NMarr[1]}))).$((${IParr[2]} | (255 ^ ${NMarr[2]}))).$((${IParr[3]} | (255 ^ ${NMarr[3]}))) } [[ $# != 2 ]] && { echo \"Usage: $0 CIDR IP-Address\" exit 1 } # Given values cidr=$1 ip=$2 # Calculations netsize=$(cidr_to_netsize $cidr) hostmask=$(cidr_to_hostmask $cidr) subnet=$(int_to_ip $hostmask) int_ip=$(ip_to_int $2) ip_from_int=$(int_to_ip $int_ip) netaddr=$(get_network_address $ip $subnet) broadcast=$(get_broadcast_address $ip $subnet) # Output echo \"Given CIDR: $cidr\" echo \" CIDR to NETWORK SIZE: $netsize\" echo \" CIDR to HOST MASK: $hostmask\" echo \" HOST MASK to SUBNET MASK: $subnet\" echo echo \"Given IP: $ip\" echo \" IP to INT: $int_ip\" echo \" INT to IP: $ip_from_int\" echo echo \"Given IP & SUBNET MASK: $ip & $subnet\" echo \" IP & SUBNET MASK to NETWORK ADDRESS: $netaddr\" echo \" IP & SUBNET MASK to BROADCAST ADDRESS: $broadcast\" exit 0 $ ./ip2int 16 192.168.10.15 Given CIDR: 16 CIDR to NETWORK SIZE: 65536 CIDR to HOST MASK: 4294901760 HOST MASK to SUBNET MASK: 255.255.0.0 Given IP: 192.168.10.15 IP to INT: 3232238095 INT to IP: 192.168.10.15 Given IP & SUBNET MASK: 192.168.10.15 & 255.255.0.0 IP & SUBNET MASK to NETWORK ADDRESS: 192.168.0.0 IP & SUBNET MASK to BROADCAST ADDRESS: 192.168.255.255"
    },
    {
        "link": "https://dev.to/dinifarb/bitwise-operations-for-ipv4-calculations-5cle",
        "document": "When I read/hear about bitwise operations, It is often said; Yeah, that's good to know but in your day to day job as software engineer you don't have to deal with that very often. Especially when you work in higher level apps. That might be true but there is one use case for bitwise operations which is in my opinion very useful and that's when it comes down to validate if a ip address is in a given subnet or not. To make that work you basically use the bits of the subnet mask and start address to validate the bits of the ip address with bitwise operations. Confused? Well me to üòÖ it is always better to draw such things out step by step which I'am going to try now and explain it a bit further:\n\nLet's assume we have a very small network with a subnet mask of and a start address with . Next let's take two ip addresses and . \n\n Yeah I know it is pretty obvious to see by eye which address is in the network and which not but for the example and simplicity it will do üôÇ And of course we wan't to do that in code and not just by eye üòÖ\n\nSo first we have a look on our example addresses and what they look like if we represent them as bits:\n\nNow, as you can see the subnet mask has always a bit in the network ID section and a bit in the host ID section. This bit arrangement applies for all possible subnet masks out there and exactly this behaviour can we use to reach our goal.\n\nIf you are confused about what Network ID and what Host ID is, then let me just say to that:\n\nSource of this quotes and more details you can find here\n\nBack to our task, lets use now the bits of our subnet mask and start address to create some sort of validation bits with a bitwise operation:\n\nIn case you have forgotten how bitwise works you can look it up here. Or just keep in mind and all other possibilities üòâ\n\nAnd now we can do the same for our two ip addresses and compare the result to our validation bits and if they match you can tell that the ip is in the given network.\n\nStarting with the first ip :\n\n\n\nYou can see that the validation bits not match with the result where i marked it red. So this ip is not in our network. If we do the same now for our second address:\n\n\n\nNow before I go on with a code example to actually implement that. If you want do try it by your own you can practise the implementation in a codewars kata which I have created here. It is still in beta though but c#, js and golang are ready to use üòä\n\nIn my example I am going to us golang, which is the language I'am learning at the moment and where I can use some practise üòÖ\n\nFirst of all, we can not really compare bits directly in our code. Therefore we need to parse our bits to a value or more precisely since ip's have no negative values.\n\nThis is actually pretty easy and ready to copy from golang playground here. For simplicity in our example we don't return a error at this function and just do a directly if a wrong ip string is inserted.\n\n\n\nNext we need our comparing or validation function which just returns a bool value whether the ip is or the given network. The bitwise operation is done in the where you can see that we use for both, ip and start address, the subnet mask to create our validation bits (as uint) and then compare it against each other.\n\n\n\nPutting all together which you can use to play around:"
    },
    {
        "link": "https://stackoverflow.com/questions/15429420/given-the-ip-and-netmask-how-can-i-calculate-the-network-address-using-bash",
        "document": "For people who hit this while googling and need an answer that works in , the that's included in BusyBox and therefore on many routers, here's something for that case:\n\nAnd here's what to do if you only have the prefix length:"
    }
]