[
    {
        "link": "https://geeksforgeeks.org/traveling-salesman-problem-tsp-in-python",
        "document": "The Traveling Salesman Problem (TSP) is a classic algorithmic problem in the fields of computer science and operations research. It involves finding the shortest possible route that visits a set of cities and returns to the origin city. The challenge of TSP lies in its NP-hard nature, meaning that as the number of cities increases, the problem becomes exponentially more complex to solve optimally.\n\nIn TSP, a \"salesman\" starts at a home city, visits a list of given cities exactly once, and returns to the home city, minimizing the total travel distance or cost. This problem can be applied to various practical scenarios, including logistics, planning, and manufacturing.\n\nThere are several approaches to solving TSP, ranging from exact algorithms that guarantee an optimal solution to heuristic and metaheuristic methods that provide approximate solutions. Some common methods include:\nâ€¢ Brute Force: Checking all possible permutations of cities to find the shortest route. This method guarantees an optimal solution but is computationally infeasible for large datasets due to its factorial time complexity.\nâ€¢ Dynamic Programming: The Held-Karp algorithm uses dynamic programming to reduce the time complexity to ?(?2â‹…2?) O n n ), which is still exponential but more efficient than brute force for moderately sized problems.\nâ€¢ Greedy Algorithms: These provide quick but often suboptimal solutions by making locally optimal choices at each step.\nâ€¢ Genetic Algorithms: These use principles of natural selection and genetics to find approximate solutions.\nâ€¢ Simulated Annealing: This probabilistic technique approximates the global optimum of a given function by iterative improvement.\n\nLet's implement a simple solution using dynamic programming (Held-Karp algorithm) in Python. This method involves breaking the problem into smaller subproblems and solving each subproblem only once, storing the results to avoid redundant calculations.\nâ€¢ Define the Problem: Represent the cities and the distances between them using a distance matrix.\nâ€¢ Initialize the Dynamic Programming Table: Create a table to store the minimum costs of visiting subsets of cities.\nâ€¢ Iterate Through Subsets: Compute the minimum costs for visiting subsets of cities and update the table.\nâ€¢ Compute the Optimal Path: Reconstruct the optimal path from the dynamic programming table.\n\nBelow is the implementation of the above approach:\n\n# there are four nodes in example graph (graph is 1-based) # dist[i][j] represents shortest distance to go from i to j # this matrix can be calculated for any given graph using # if only ith bit and 1st bit is set in our mask, # it implies we have visited all other nodes already # we have to travel all nodes j in mask and end the path at ith node # so for every node j in mask, recursively calculate cost of # except i and then travel back from node j to node i taking # the shortest path take the minimum of all possible j nodes # try to go from node 1 visiting all nodes in between to i # then return from i taking the shortest route to 1 \"The cost of most efficient tour = \" # This code is contributed by Serjeel Ranjan\n\nTime Complexity : O(n2*2n) where O(n* 2n) are maximum number of unique subproblems/states and O(n) for transition (through for loop as in code) in every states.\n\nAuxiliary Space: O(n*2n), where n is number of Nodes/Cities here."
    },
    {
        "link": "https://medium.com/@suryabhagavanchakkapalli/solving-the-traveling-salesman-problem-in-python-using-the-nearest-neighbor-algorithm-48fcf8db289a",
        "document": "The Traveling Salesman Problem (TSP) is a classic optimization problem in which a salesman needs to visit a number of cities and return to the starting city while minimizing the total distance traveled. The TSP is an NP-hard problem, which means that finding the optimal solution for large instances can be computationally expensive. However, there are several heuristic algorithms that can provide good approximate solutions in a reasonable time. In this blog post, we will focus on the Nearest Neighbor Algorithm, a simple but effective heuristic for the TSP, and show how to implement it in Python.\n\nLetâ€™s start by defining a small instance of the TSP problem. Suppose a salesman needs to visit four cities, labeled A, B, C, and D, and return to the starting city A. The distances between the cities are given by the following distance matrix:\n\nThe task is to find the shortest route that visits all four cities and returns to A.\n\nThe Nearest Neighbor Algorithm is a greedy algorithm that starts at a random city and repeatedly selects the nearest unvisited city until all cities have been visited. Hereâ€™s how the algorithm works:\nâ€¢ While there are unvisited cities: a. Find the nearest unvisited city. b. Move to that city. c. Mark the city as visited.\n\nThe Nearest Neighbor Algorithm is simple and fast, but it may not always find the optimal solution, especially for large instances of the TSP. However, it can provide a good approximate solution and is a good starting point for more advanced algorithms.\n\nLetâ€™s now implement the Nearest Neighbor Algorithm in Python. We will use the distance matrix defined in the problem statement and start at city A.\n\nThe first line imports the NumPy library, which we will use to create and manipulate arrays. The second block of code defines the distance matrix, which represents the distances between each pair of cities. In this example, we have four cities labeled A, B, C, and D, and the distance matrix is a 4x4 array that lists the distances between each pair of cities. For example, the distance between city A and city B is 10, the distance between city B and city C is 35, and so on.\n\nThis block of code defines the Nearest Neighbor Algorithm as a function that takes a distance matrix as input and returns the optimal route as a list of cities. Hereâ€™s a breakdown of what each line does:\nâ€¢ : Computes the number of cities in the distance matrix.\nâ€¢ : Initializes the route with city A, which is the starting city.\nâ€¢ : Initializes the set of visited cities with city A.\nâ€¢ : Loops until all cities have been visited.\nâ€¢ : Retrieves the last city in the route, which is the current city.\nâ€¢ None nearest_city = min([(i, distances[current_city][i]) for i in range(n) if i not in visited], key=lambda x: x[1])[0] : Finds the nearest unvisited city to the current city by computing the distances from the current city to all unvisited cities and selecting the one with the smallest distance.\nâ€¢ : Adds the nearest unvisited city to the route.\nâ€¢ : Adds the nearest unvisited city to the set of visited cities.\nâ€¢ : Adds city A to the end of the route to complete the loop.\n\nFinally, this block of code applies the Nearest Neighbor Algorithm to the distance matrix and prints the optimal route and the total distance traveled. The optimal route is computed by calling the function with the distance matrix as input. The total distance is computed by summing the distances between each pair of adjacent cities in the optimal route.\n\nIn conclusion, the Traveling Salesman Problem (TSP) is a classic optimization problem that seeks to find the shortest possible route that visits all cities exactly once and returns to the starting city. The problem is NP-hard, which means that finding the exact solution for large instances of the problem is computationally infeasible.\n\nIn this blog post, we discussed one of the most popular and simple heuristics for solving the TSP, the Nearest Neighbor Algorithm. We showed how to implement the algorithm in Python using NumPy and applied it to a small example problem consisting of four cities.\n\nWhile the Nearest Neighbor Algorithm is not guaranteed to provide the optimal solution to the TSP, it often produces good results, especially for small or medium-sized instances of the problem. For larger instances of the TSP, more advanced techniques such as Integer Linear Programming or Metaheuristics may be necessary to find good solutions in a reasonable amount of time.\n\nOverall, the TSP is a fascinating problem with many real-world applications, such as route planning, logistics, and DNA sequencing. By using the techniques and tools introduced in this blog post, you can start exploring this exciting field of optimization and contribute to the development of new and better algorithms for solving TSP and other similar problems."
    },
    {
        "link": "https://stackoverflow.com/questions/71196078/scalable-implementation-of-the-travelling-salesman-problem-in-python",
        "document": "I have (let's say) a 100 points. I want to generate a path between them, the shorter, the better. This is the Travelling salesperson problem. Since the TSP is NP-hard, I am satisfied with not finding a global solution. I method which gives a solution quickly & scales well.\n\nGenerate distance matrix, where the entry contains distance between and . Using this answer:\n\nHow do I continue, to find a shortest path, with at least locally minimal pathlength?\n\nThis thread: Travelling Salesman in scipy provides code for finding a solution to the TSP. It works in an iterative way though, so if the number of points to visit is large, the script does not produce a solution in reasonable times.\n\nThis thread: How to solve the Cumulative Traveling Salesman Problem using or-tools in python? does not have a code answer, and is not focused on classical TSP.\n\nThis thread: Optimizing a Traveling Salesman Algorithm (Time Traveler Algorithm) provides iterative solutions to the problem (which means bad scaling)"
    },
    {
        "link": "https://github.com/xbeat/Machine-Learning/blob/main/Solving%20the%20Traveling%20Salesman%20Problem%20with%20Machine%20Learning%20in%20Python.md",
        "document": "The Traveling Salesman Problem (TSP) is a famous optimization problem in computer science and operations research. It involves finding the shortest possible route for a salesman to visit a set of cities exactly once and return to the starting point. The problem is NP-hard, meaning that there is no known efficient algorithm to solve it optimally for large instances. Machine learning techniques can be applied to find approximate solutions in a reasonable amount of time.\n\nIn Python, we can represent the TSP as a list of city coordinates or a distance matrix. The distance matrix is a 2D array where each element represents the distance between two cities. Here's an example of a distance matrix for a 4-city problem:\n\nOne way to solve the TSP is to try all possible permutations of the city order and calculate the total distance for each permutation. Then, choose the permutation with the shortest distance. This approach is computationally expensive and becomes impractical for large problem instances.\n\nThe Nearest Neighbor Algorithm is a simple heuristic approach to solve the TSP. It starts from a random city and then visits the nearest unvisited city until all cities have been visited. This algorithm is fast but does not guarantee an optimal solution.\n\nMachine learning techniques can be used to find approximate solutions to the TSP. These techniques typically involve training a model on a large dataset of TSP instances and their corresponding optimal or near-optimal solutions. The trained model can then be used to predict solutions for new TSP instances.\n\nOne machine learning approach to solving the TSP is to train a neural network to predict the next city to visit based on the current partial route and the remaining unvisited cities. The network is trained on a dataset of optimal or near-optimal TSP solutions.\n\nReinforcement learning can also be applied to the TSP. In this approach, an agent learns to construct routes by receiving rewards for shorter routes and penalties for longer routes. The agent explores different routes and updates its policy based on the received rewards/penalties.\n\nGenetic algorithms are a type of optimization algorithm inspired by natural evolution. They can be applied to the TSP by representing candidate solutions as chromosomes and evolving them through mutation, crossover, and selection operations.\n\nAnt Colony Optimization (ACO) is a nature-inspired metaheuristic for solving optimization problems, including the TSP. It simulates the behavior of ants searching for the shortest path between their nest and a food source by depositing pheromones along the way.\n\nIn some cases, combining multiple techniques can lead to better results for solving the TSP. For example, one could use a genetic algorithm to find a good initial solution and then refine it using a local search algorithm or a neural network.\n\nFor large-scale TSP instances, parallelization and distributed computing techniques can be employed to speed up the solution process. This can involve splitting the problem into smaller sub-problems and solving them simultaneously on multiple processors or machines.\n\nWhen solving the TSP using machine learning or other approximation methods, it's important to evaluate the quality of the obtained solutions. One way to do this is to compare the lengths of the predicted routes against the optimal solutions (if known) or lower bounds calculated using techniques like the nearest neighbor heuristic or the minimum spanning tree.\n\nFor further reading and exploration of the Traveling Salesman Problem and its solutions using machine learning, here are some recommended resources from arXiv.org:\nâ€¢ \"Neural Combinatorial Optimization with Reinforcement Learning\" by Dmitri Krioukov et al. (https://arxiv.org/abs/1611.09940)\nâ€¢ \"Learning to Solve the Traveling Salesman Problem Using Pointer Networks\" by Wouter Kool and Matthew Wiele (https://arxiv.org/abs/1805.09512)\nâ€¢ \"A Reinforcement Learning Approach to the Travelling Salesman Problem\" by Thiago P. Santos et al. (https://arxiv.org/abs/1909.05363)\nâ€¢ \"Solving the Traveling Salesman Problem Using the Hopfield Neural Network\" by Benjamin Peherstorfer et al. (https://arxiv.org/abs/2004.03505)\nâ€¢ \"A Genetic Algorithm for the Traveling Salesman Problem Based on Greedy Partition Crossover\" by Jianyong Sun et al. (https://arxiv.org/abs/1911.03673)"
    },
    {
        "link": "https://geeksforgeeks.org/traveling-salesman-problem-tsp-implementation",
        "document": "Given a 2d matrix cost[][] of size n where cost[i][j] denotes the cost of moving from city i to city j. The task is to complete a tour from city 0 (0-based index) to all other cities such that we visit each city exactly once and then at the end come back to city 0 at minimum cost.\n\nNote the difference between Hamiltonian Cycle and TSP. The Hamiltonian cycle problem is to find if there exists a tour that visits every city exactly once. Here we know that Hamiltonian Tour exists (because the graph is complete) and in fact, many such tours exist, the problem is to find a minimum weight Hamiltonian Cycle.\n\nThe given graph is a complete graph, meaning there is an edge between every pair of nodes. A naive approach to solve this problem is to generate all permutations of the nodes, and calculate the cost for each permutation, and select the minimum cost among them. An important observation in the Traveling Salesman Problem (TSP) is that the choice of the starting node does not affect the solution. This is because the optimal path forms a cyclic tour. For example, if the optimal tour is a1â†’a2â†’a3â†’a4â†’a1, starting from any other node, such as a2, results in the equivalent tour a2â†’a3â†’a4â†’a1â†’a2 with same total cost. To simplify the problem, we can fix one node (e.g., node 1) as the starting point and only consider permutations of the remaining nodes.\n\n// C++ program to find the shortest possible route // that visits every city exactly once and returns to // Generate all permutations of the remaining nodes // Calculate the cost of the current permutation // Add the cost to return to the starting node // Update the minimum cost if the current cost // Java program to find the shortest possible route // that visits every city exactly once and returns to // Generate all permutations of the remaining nodes // Calculate the cost of the current permutation // Add the cost to return to the starting node // Update the minimum cost if the current cost // function to generate the next lexicographical // Find the first pair where nodes[i] < nodes[i + 1] // Find the smallest element larger than nodes[i] to // Reverse the sequence from i + 1 to the end # Python program to find the shortest possible route # that visits every city exactly once and returns to # Generate all permutations of the # Calculate the cost of the current permutation # Add the cost to return to the starting node # Update the minimum cost if the current cost // C# program to find the shortest possible route // that visits every city exactly once and returns to // Generate all permutations of the remaining nodes // Calculate the cost of the current permutation // Add the cost to return to the starting node // Update the minimum cost if the current cost // Helper function to generate all permutations of a // JavaScript program to find the shortest possible route // that visits every city exactly once and returns to // Generate all permutations of the remaining nodes // Calculate the cost of the current permutation // Add the cost to return to the starting node // Update the minimum cost if the current cost is // Helper function to generate all permutations of an array\n\nTime complexity: O(n!) where n is the number of vertices in the graph. This is because the algorithm uses the next_permutation function which generates all the possible permutations of the vertex set. \n\nAuxiliary Space: O(n) as we are using a vector to store all the vertices."
    },
    {
        "link": "https://medium.com/aimonks/traveling-salesman-problem-tsp-using-genetic-algorithm-fea640713758",
        "document": "For decades, the Traveling Salesman Problem (TSP) has been an intriguing challenge for mathematicians, computer scientists, and operations researchers. It involves determining the shortest route for a salesman to take to visit a set of cities and return to the starting point. As the number of cities increases, the complexity of the problem grows exponentially, which is known as a combinatorial explosion. Solutions for the TSP have been attempted through a variety of algorithms and techniques, such as dynamic programming, branch-and-bound, genetic algorithms, and simulated annealing.\n\nThe computational complexity of algorithms for solving the Traveling Salesman Problem (TSP) can vary significantly depending on the approach used. Hereâ€™s a brief overview of some common algorithms and their complexities:\n\nThe brute-force approach exhaustively explores all possible permutations of cities to find the optimal solution.\n\nFor a TSP with â€œnâ€ cities, there are (n-1) choices for the second city, (n-2) choices for the third city, and so on until there is only one choice left for the last city. The total number of permutations is calculated as the factorial of (n-1), denoted as (n-1)!. For example, if there are 5 cities (n=5), the number of permutations is (5â€“1)! = 4! = 4 x 3 x 2 x 1 = 24. Since the salesman must return to the starting city to complete the tour. Therefore, after calculating the number of permutations, we multiply it by â€œnâ€ to account for starting the tour from each of the â€œnâ€ cities. In the example with 5 cities, we have 24 permutations for each starting city, resulting in a total of 24 x 5 = 120 possible tours to evaluate.\n\nThe time complexity is determined by the total number of permutations. Since the number of permutations is (n-1)! * n, the time complexity of the brute force method to solve the TSP is O((n-1)! * n) which can be simplified to O(n!).\n\nGenetic Algorithms involve a heuristic process based on the concept of natural selection. These algorithms may not deliver the best possible solution, but they can quickly identify good approximations. It is difficult to estimate the amount of time it takes to complete a genetic algorithm since it is dependent on population size, number of generations, and other factors.\n\nIt is important to be aware that the Traveling Salesman Problem is an NP-hard problem, meaning no algorithm that is polynomial-time has been found to solve it. This is why the algorithms discussed above are either exact yet slow for larger instances or heuristic, providing close-to-accurate solutions quickly. This has caused the TSP to be a very interesting and difficult issue in the realm of computational optimization, causing scientists to keep on developing more effective and precise algorithms.\n\nIn this article, we shall discuss the solution of the TSP using genetic algorithms in detail.\n\nGenetic algorithms are a type of evolutionary algorithm inspired by the processes of natural selection and genetics. They are widely used for optimization and search problems. The main components of a genetic algorithm include:\n\nThe optimization problem is composed of an array of possible solutions, known as a â€œpopulationâ€. Every single solution is symbolized as a â€œchromosomeâ€ or â€œindividualâ€. The population changes over time, and its quantity and variety can affect the effectiveness of the algorithm.\n\nThe above function would initialize the required number of individuals, which together form the algorithm's initial population. Please note that each individual in our case is a probable solution, which means that each individual is a sequence of cities without any repetition, as the traveling salesman should not pass any city twice while completing his or her journey. One individual example could be: [Gliwice, Cairo, Rome, Krakow, Paris, Alexandria, Berlin, Tokyo, Hong Kong, Rio]\n\nAs each individual is a probable solution, we need to evaluate this solutionâ€™s performance by measuring the total distance traveled by the salesman, as the distance traveled is the only metric that undergoes optimization in our example under the assumption that the lines or edges connecting the cities are straight lines and there are no better roads than the others. In real life, roads are not built in straight lines; some are wider than others, and some have traffic. These restrictions can be translated into time or the duration of the journey, but for simplicity, the only metric weâ€™re optimizing for here is the total distance.\n\nThe above function calculates the Euclidean distance between two cities, which is the length of the edge connecting the two cities together.\n\nThis function calculates the total distance traveled by a single individual by utilizing the function that calculates the distance between two cities.\n\nAs of now, we can assess the performance of each individual, which is a potential solution to the problem. If we generate all the probable solutions to the problem and measure the total distance traveled by each solution (individual), we â€Œthen have a winner which is the individual with the least traveled distance. However, we would need enormous computational power and time as the complexity of the problem increases significantly as the number of cities increases. This approach of assessing the performance of all the potential solutions is called the brute force approach. In our example, we only generated a few individuals to start our GA optimization with.\n\nThe fitness function assesses the quality of each individual in the population, assessing how well each potential solution solves the problem. This function guides the search process by giving higher scores to better solutions.\n\nThis function converts the total distance traveled by an individual in the population into a probability. This can facilitate the next step of selecting the best-fit individuals.\n\nIn the selection process, individuals with higher fitness values have a higher probability of being chosen for reproduction. This is an emulation of the concept of â€œthe strong prevailâ€ from natural selection, where those with beneficial features have a greater likelihood of passing down their genes to the next generation. The selection approach used in this example is Roullette Wheel Selection.\n\nWhen selecting an individual based on its fitness, a random number between 0 and 1 is generated from a uniform distribution and this generated number will be used to select a certain individual. If the individual has a higher fitness, then itâ€™s more likely to cover a bigger area as shown in the above circle. The uniform distribution to draw a number is used because, at this point, we donâ€™t want to favor one individual over another but rather let their fitness probabilities give them a higher or lower chance of being chosen. In the above animation, it is clear that those with greater fitness are more likely to be selected. However, that does not mean that those who are less fit will never be chosen.\n\nCrossover is the process of creating new individuals by combining genetic information from two or more parent individuals. It emulates the genetic recombination that occurs during sexual reproduction in biology. Crossover points are selected on the parent chromosomes, and the genetic material is exchanged to create new offspring.\n\nHere is the part where the selected individuals are mating or mixing to generate new ones (offspring). For example, if we have two individuals with 10 elements each, we can take the first 3 elements from the first individual and the last 7 elements from the second individual. Generally Selecting a subset of elements from one individual and the remaining elements from the other, ensuring that no duplicate elements are taken from the first individual. Choosing the number of offspring produced by each pair of parents can be considered part of the population management process. Additionally, the selection of how many elements to take from the first individual can be randomized using a uniform distribution. Although this choice might not have a specific philosophy behind it, using the uniform distribution ensures higher variability in the selection process, enabling the genetic algorithm to explore a more diverse set of solutions.\n\nMutation introduces small random changes to the genetic information of individuals. It helps introduce new genetic material into the population, promoting exploration of the search space and preventing premature convergence to suboptimal solutions.\n\nIn this code snippet, the mutation process is implemented using a straightforward switching step. A random element is selected, and it is swapped with another element which is also chosen randomly. This simple switching process enables the genetic algorithm to introduce mutation to selected individuals.\n\nThe mutation rate (The percentage of individuals that will experience mutation) can have a huge influence on the outcome and the optimization procedure. The two animations featured above demonstrate the impact of a high and low mutation rate before optimization is applied. In this case, what is happening is the sole influence of mutation, without taking into account the rest of the optimization process.\n\nOnce selection, crossover, and mutation have occurred, the newly generated individuals (offspring) replace some of the original population. This replacement tactic ensures the population is maintained at a fixed size between generations, which is also a component of population management techniques.\n\nBy iteratively applying these components, genetic algorithms explore the search space, gradually improving the quality of solutions over generations. Through selection, crossover, and mutation, the algorithm can efficiently converge towards optimal or near-optimal solutions.\n\nPopulation Size: The population size defines the number of candidate solutions (individuals) present in each generation. A larger population size increases the diversity of the population, promoting exploration of the search space. However, it also leads to increased computation time. Finding the right balance is essential to striking a trade-off between exploration and exploitation.\n\nCrossover Rate: The crossover rate defines the probability of applying crossover (recombination) to create new offspring from selected parent individuals. Crossover helps combine beneficial traits from different parents and is crucial for exploration and maintaining diversity in the population.\n\nMutation Rate: The mutation rate determines the probability of introducing random changes to the genetic information of individual chromosomes. Mutation aids in exploration, allowing the algorithm to escape local optima. However, setting a mutation rate too high can lead to excessive exploration and divergence from good solutions.\n\nNumber of Generations: The number of generations determines how many iterations or cycles the genetic algorithm will run. Each generation produces a new set of individuals through selection, crossover, and mutation. A higher number of generations generally allows more time for the algorithm to explore the search space thoroughly.\n\nTermination Criteria: The termination criteria determine when the genetic algorithm stops running. Common termination criteria include reaching a maximum number of generations, finding a satisfactory solution, or reaching a predefined fitness level. Proper termination criteria help avoid unnecessary computation and improve efficiency.\n\nIn the given code snippet, the algorithm parameters are specified as follows: The population size is set to 250 individuals. After the selection process, 80% of the selected individuals will undergo crossover, while only 20% of the resulting offspring will undergo mutation. The algorithm is set to terminate after 200 generations, meaning that the entire process, including selection, crossover, and mutation, will be repeated 200 times in an attempt to achieve convergence.\n\nIn the above code snippet, the cities are represented using (x, y) coordinates, where each pair (x, y) corresponds to a point on the Cartesian plane. Itâ€™s important to note that in real-world applications, cities are typically represented using longitude and latitude coordinates. Also, the city names used in this example are for illustration purposes only and do not reflect the actual distances between these cities but were chosen purely for the convenience of this demonstration. The last line of code creates a dictionary where each city name is the dictionary key and the corresponding (x, y) coordinates are the dictionary value.\n\nPutting it all together\n\nThese are the important libraries used in this example.\n\nThe above function performs the algorithmâ€™s steps in the following order:\nâ€¢ Replaces a subset of the old population with new offspring (Replacement)\nâ€¢ Shuffles the new population and returns it\nâ€¢ Repeat for number of generations and terminate\n\nIn the above code snippet, the algorithm is being executed with the specified inputs, the least distance that an individual has traveled is set in the minimum_distance variable as well as the path traversed to reach this distance.\n\nThe minimum_distance and the optimal solution is 61.137\n\nAs demonstrated in the animation, the GA achieved convergence in far fewer generations than expected, as 200 generations was the initial assumed maximum. However, it is essential to adjust the number of generations to reach the best and most speedy outcomes.\n\nIn some situations, a genetic algorithm can become trapped in a local minimum, hindering its ability to find the global optimum. To address this, the mutation rate becomes a valuable parameter as it introduces random changes that aid in escaping local minima. However, while mutation can be effective in exploring new areas, excessive mutation can lead to divergence, as seen in the above animation, even after reaching a promising solution. Consequently, the selection of algorithm parameters becomes crucial in dealing with such challenges. Finding the right set of parameters is essential for achieving a stable, fast, and near-optimal solution. This process of searching for the best parameter configuration is vital to maximizing the algorithmâ€™s performance and ensuring it converges efficiently towards the global minimum.\n\nIn conclusion, the application of genetic algorithms to solve the Traveling Salesman Problem (TSP) has proven to be a powerful and flexible approach. The algorithm operates by mimicking the principles of natural selection, employing components such as population, fitness evaluation, selection, crossover, and mutation. These mechanisms enable the genetic algorithm to explore the vast search space efficiently and gradually converge towards optimal or near-optimal solutions.\n\nHowever, the success of a genetic algorithm in solving the TSP heavily depends on the careful selection of its parameters. The most critical parameters include â€Œpopulation size, mutation rate, crossover rate, and the number of generations. Each of these parameters influences the algorithmâ€™s behavior and performance in distinctive ways. For instance, a larger population size promotes exploration but increases computation time, while a higher mutation rate helps escape local minima but might lead to divergence if set excessively.\n\nFinding the right balance among these parameters becomes critical to achieving the best performance. An unsuitable parameter configuration can lead to bad performance, trapping the algorithm in suboptimal solutions, or excessive exploration that prolongs the optimization process unnecessarily.\n\nHence, researchers and practitioners must conduct thorough parameter tuning to identify the optimal combination for their specific GA instances. This process often involves experimentation and iterative refinement to strike a balance between exploration and exploitation. By selecting appropriate parameters, the genetic algorithm can efficiently explore the search space, escape local minima, and converge towards a stable, near-optimal solution in a timely manner.\n\nGAs provide a robust and adaptable approach for solving the TSP, and their effectiveness is highly dependent on skillful parameter selection. By understanding the impact of each parameter, researchers can control the algorithmâ€™s potential to tackle complex real-world traveling salesman scenarios effectively. As the field of optimization continues to evolve, refining genetic algorithmsâ€™ parameters will remain a critical aspect of maximizing their performance and relevance in solving a wide range of combinatorial optimization problems.\n\nPlease find the full code here:\n\nðŸ‘ Clap for the story if you liked it.\n\nâ“ Feel free to drop your question in the comments."
    },
    {
        "link": "https://researchgate.net/publication/364049954_A_Performance_Evaluation_of_Genetic_Algorithm_and_Simulated_Annealing_for_the_Solution_of_TSP_with_Profit_Using_Python",
        "document": ""
    },
    {
        "link": "https://researchgate.net/publication/354177153_PERFORMANCE_ANALYSIS_OF_GENETIC_ALGORITHM_AND_PARTICLE_SWARM_OPTIMIZATION_ALGORITHM/download",
        "document": "space of possible solutions. Each individual is\n\nas components. These variable components are\n\n(individual) is composed of several genes\n\nEach and every individual in the population\n\nability of an individual to competeâ€\n\nalgorithm is based on an analogy with genetic\n\nstructure and behavior of chromosome of the\n\nFollowing is the analogy:\n\nmate and produces more off-springs than others.\n\nwhere the fitness of off-springs is more than\n\neither of the parent.\n\n4.Even after the operations applied if the fitness\n\nscore of child is not better than their parents the\n\ninspired by the social behavior such as bird\n\nwhich is a possible solution to the given problem\n\n, whose trajectories are adjusted by a stochastic\n\nand a deterministic component. Each particle is\n\ninfluenced by its â€˜bestâ€™ achieved position and the\n\ngroup â€˜bestâ€™ position, but tends to move\n\nrandomly. A particle is defined by its position\n\nwhere and denote the best particle\n\nposition and best group position and the\n\nparameters , , , and are respectively\n\ninertia weight, two positive constants and two\n\nFirst , the initial population is created and then\n\nthe algori thm is used to evolve the generation\n\nAs the fitness scores of individuals are a lready\n\nindividuals with best fitness scores and allow\n\nthem to produce off-springs, through which the\n\nparents genes are passed to the next generation ."
    },
    {
        "link": "https://medium.com/@schrapff.ant/genetic-algorithms-for-unresolvable-optimization-problem-in-python-6c4fb43faa83",
        "document": "The traveling salesman problem is an unsolvable optimization puzzle. It challenges us to find the shortest possible route between multiple cities, but its complexity grows so rapidly with each added city that finding the perfect solution becomes practically impossible.\n\nSince perfect solutions are hard to find, nature-inspired algorithms like the genetic algorithm provide a smart alternative by using evolution-like techniques to discover the best possible routes.\n\nThis article presents both the Traveling Salesman Problem (TSP) and a solution using Genetic algorithm. It is completed by python code which are present in the following repository : https://github.com/VSCHY/GenAlgo_Salesman\n\nComputational complexity is a fundamental concept in computer science that examines the resources required to solve computational problems. These resources can include time (how long an algorithm takes to run), space (how much memory it uses), and other factors such as parallelism and energy consumption.\n\nTime complexity measures the amount of time an algorithm takes to complete as a function of the size of its input. It is often expressed using Big O notation, which provides an upper bound on the growth rate of the algorithmâ€™s running time. For example, an algorithm with a time complexity of O(n) is said to have linear time complexity, meaning its running time increases linearly with the size of the input. Other common complexities include O(log n) for logarithmic time, O(nÂ²) for quadratic time, and O(2^n) for exponential time.\n\nIn addition to categorizing individual algorithms, computational complexity also helps us classify entire problems. Problems are grouped into complexity classes based on the resources needed to solve them. For instance, the class P consists of problems that can be solved in polynomial time, while the class NP includes problems for which a solution can be verified in polynomial time. One of the most famous open questions in computer science, the P vs. NP problem, asks whether every problem whose solution can be verified quickly (in polynomial time) can also be solved quickly.\n\nNP-hard problems represent some of the most challenging issues in computational complexity. An NP-hard problem is at least as difficult as the hardest problems in NP (nondeterministic polynomial time), but it is not necessarily a member of NP itself. This means that while solutions to NP-hard problems can be verified quickly (in polynomial time) if provided, finding these solutions is believed to require non-polynomial time, making them exceptionally difficult to solve efficiently. NP-hard problems encompass a wide range of computational tasks, from optimization problems like the Traveling Salesman Problem.\n\nThe Traveling Salesman Problem (TSP) is a classic and notoriously challenging optimization problem. Despite extensive research, no polynomial-time solution exists, making it an NP-hard problem.\n\nThe Traveling Salesman Problem can be resumed as follows: given a list of cities and the distances between each pair of cities, find the shortest possible route that visits each city exactly once. Despite its simplicity, the Traveling Salesman Problem is computationally intractable for large numbers of cities because the number of possible routes increases factorially with the number of cities.\n\nThe history of the Traveling Salesman Problem (TSP) has origins that date back to the 19th century. The formalization in the 1930s and 1940s. In the early 1930s, Karl Menger, a Viennese mathematician, introduced the problem in lectures on the â€œcombinatorial distance problem.â€ This was part of his broader exploration of geometric and graph theoretical concepts. Around the same time, notable mathematicians like Hassler Whitney and Merrill Flood began discussing the problem in relation to its practical applications in routing and logistics.\n\nIn the 1940s, the problem gained more formal attention with the work of Merrill Flood and other researchers at Princeton University, as he was involved in optimizing school bus routes.\n\nThroughout the latter half of the 20th century, TSP continued to be a central problem in optimization research, driving the development of new algorithms and computational techniques.\n\nGenetic algorithms (GAs) are inspired by the process of natural selection. They are used to finding approximate solutions to optimization and search problems. GAs work by evolving a population of candidate solutions through iterations called generations.\n\nAs a result, brute force methods, which involve evaluating all possible permutations, quickly become impractical for even moderately sized instances. However, Genetic Algorithms (GAs) offer a smart and elegant approach to exploring possible solutions. Inspired by the principles of natural selection and evolution, GAs simulate the process of natural evolution to iteratively improve solutions, balancing exploration and exploitation in the search space. This project leverages the power of GAs to provide an educational and practical implementation for solving the TSP, demonstrating how nature-inspired algorithms can effectively tackle complex computational problems.\nâ€¢ Fitness: the performance of each solution can be measured through what is called fitness\nâ€¢ Selection: the fitness is used to select individual among the population for crossing them (2 solutions having a child solution) and keep some elements to apply them mutation\nâ€¢ Mutation: process of applying random variation in a particular solution.\nâ€¢ Selection: Evaluate the fitness of each candidate and select the best-performing candidates for reproduction.\nâ€¢ Crossover: Combine pairs of candidates to produce offspring for the next generation.\nâ€¢ Mutation: Introduce random changes to some candidates to maintain genetic diversity.\nâ€¢ Termination: Repeat the process until a stopping criterion is met, such as a maximum number of generations or a satisfactory fitness level.\n\nThe Traveling Salesman Problem must be described using a distance matrix containing all distance between 2 cities. In this case, distance in both sense are the same, therefore the matrix is symmetric.\n\nWe consider that each one of the N cities visited is referred to as a number between 1 and N (included). A solution is presented as a vector of size N containing each number between 1and N only once. This will be the â€œDNAâ€ of each individual. In these illustration, the number N has been kept small. In the practical example, N will be equal to 30 (cf. code implementation).\n\nIn the example above, it means that the traveler first is in city 2, then goes to 4 then to 3 etc.\n\nThe fitness function for a vector is the total distance for a specific individual. The objective is to minimize it. Considering N cities to travel by, noting d the distance matrix and I the vector for a certain individual, the fitness is calculated as shown in Equation 1.\n\nThe crossover between two individuals I1 and I2 in a genetic algorithm is defined by the following steps:\nâ€¢ Selecting two integers a and b: such that 3 â‰¤ a < b â‰¤ 30, with the additional constraints that a â‰¤ 27.\nâ€¢ Creating the initial segment of the child from I1: Copy the elements from positions a to b from I1 directly into the child.\n\nInitially, the child will be:\n\nRemoving the copied segment elements from I2: Eliminate the elements present in the segment I1[a:b] from I2.\n\nFilling the remaining positions in the child: Fill the remaining empty positions in the child with the remaining elements from I2 and fill the child with these remaining elements:\n\nFor each mutation operation, randomly select two distinct indices within the array. The elements at the selected indices are swapped. This swap changes the arrangement of elements in the array, creating a new variant of the solution.\n\nIf multiple mutations are required, repeat the process of random selection and swapping. Each subsequent mutation builds upon the previous one, further diversifying the solution.\n\nIn the present implementation, we decided to select on one side 70% of the population to use them as â€œparentsâ€ in the crossing process, each couple of parents has 2 children. Then 30% of the population is also kept for next generation but with mutation.\n\nThere are different ways to select parents and individual to be affected by mutation:\nâ€¢ UNIFORM: selection over the population using uniform probability\nâ€¢ LOTTERY: random selection over the population but weighted by the performance of elements. Here fitness is a function to be minimized, so we define the probability as: (1/fitness)/(sum_population(1/fitness))\nâ€¢ ELITIST: select the elements with best fitness (lowest fitness)\nâ€¢ TOURNAMENT: select randomly sample of the population. In these sample select a certain percentage of the best elements.\nâ€¢ RANDOM: Another method of full random regeneration of the population at each step (like during initialization) has also be implemented for comparison.\n\nThe genetic algorithm is implemented in a single class to facilitate its use:\n\nIn the following experiment, the size of the population has been set at 200.000. The initial population is generated randomly.\n\nFor each option (uniform, elitist, tournament, lottery, and random), 10 experiments have been run, each one with the 20 consecutive generation from the initial one. 70% of the population is generated by crossing (each couple get 2 children) and 30% from mutation of the original population. Therefore, the size of the population remains stable.\n\nFor the tournament, the sample size is defined as 20000 and 10% of the best element from the sample is selected for crossing and mutation.\n\nOnce the genetic algorithm has run for the specified experiments, we can analyze the output to see the quality of the solution.\n\nDifferent indicator can be considered:\nâ€¢ Best performance: What is the evolution of the best performance over the previous run for each generation.\nâ€¢ Average performance: What is the average performance among the population.\nâ€¢ Diversity: Did the population maintain diversity, or did it converge prematurely ? (not assessed in this case)\n\nBest fitness: Figure 5 shows that the elitist and tournament simulations leads to better result compared to random generation. Tournament, in particular, shows impressive difference (random remains above 20.000 km while tournament reaches 10.000 km).\n\nAverage fitness: Figure 5 shows that the lottery, elitist and tournament simulations leads to decreased average fitness, while the random one remains stable. This means that these algorithm leads to overall improvement of the solutions composing the population.\n\nAgain, the tournament option shows impressive difference. In this case we might wonder if this is not related to a too fast convergence over a part of the population with good result neglecting the fact of keeping good diversity to explore all possible solutions.\n\nGenetic algorithms are a valuable approach to solving the Traveling Salesman Problem offering a robust method for finding near-optimal solutions through mechanisms inspired by natural evolution.\n\nHowever, as technology has advanced, other modern algorithms offers alternative to Genetic Algorithm with good efficiency. Notable alternatives include Ant Colony Optimization (ACO), which mimics the foraging behavior of ants to explore optimal paths, and Particle Swarm Optimization (PSO), which draws inspiration from social behavior patterns in animals.\n\nAdditionally, Simulated Annealing (SA) and advanced versions of Local Search algorithms have proven effective in addressing the TSP.\n\nThe evolution of this problem-solving domain has also led to practical applications in contemporary logistics, such as coordinating deliveries using combinations of drones and trucks. This hybrid approach optimizes delivery routes by leveraging the speed and flexibility of drones for last-mile delivery while maintaining the efficiency and capacity of trucks for longer distances.\n\nIt can also be useful for other applications such as smart city infrastructure maintenance (scheduling and routing maintenance activities for smart city infrastructure, such as automated street cleaning, waste collection, and utility inspections), automated urban mobility (in particular ride-sharing services), food delivery services."
    },
    {
        "link": "https://ripublication.com/ijaer18/ijaerv13n9_42.pdf",
        "document": ""
    },
    {
        "link": "https://github.com/tirotir-ir/py_visual_algo",
        "document": "is a Python library designed for visualizing and understanding algorithms, including sorting, searching, graph traversal, and evolutionary algorithms. Using real-time visualizations and step-by-step animations, it transforms complex algorithmic concepts into intuitive, interactive experiences. Perfect for educators, students, and developers, bridges the gap between theoretical concepts and practical implementation.\nâ€¢ Real-Time Visualizations\n\n Watch algorithms execute in real-time with live updates and insights.\nâ€¢ Step-by-Step Animations\n\n Follow every decision, iteration, and operation of an algorithm.\nâ€¢ Graph Integration\n\n Leverage to visualize and work with graph-based algorithms.\nâ€¢ Evolutionary Algorithms\n\n Explore optimization problems with cutting-edge techniques like genetic algorithms, particle swarm optimization, and more.\nâ€¢ Extensive Algorithm Coverage\n\n Includes a wide range of algorithms such as:\nâ€¢ Customizable API\n\n Tailor algorithm visualizations, themes, and execution parameters to fit your unique requirements.\nâ€¢ Educational Focus\n\n Designed for teaching, learning, and presentations, making it the ideal tool for instructors and students.\n\nWhether you're an educator aiming to simplify algorithmic concepts, a student trying to grasp algorithms interactively, or a developer experimenting with optimization techniques, is your go-to solution.\nâ€¢ Customizable API: Adapt algorithm execution and visualizations to your needs.\n\nThis comprehensive set of algorithms makes a versatile library for various applications, including education, research, and development.\n\nThe library includes a variety of examples to demonstrate its capabilities. These examples are located in the directory.\n\nThe library includes a user-friendly Graphical User Interface (GUI) to browse and run examples interactively. Follow these steps to use the GUI:\n\nActivate your virtual environment to use the installed library:\n\nIf the library is not already installed in the virtual environment, install it using pip:\n\nEnsure the examples folder is either included in the installed package or downloaded separately there (see Step 3).\n\nThe folder must be located two levels above the GUI script ( ). If the library is installed in a virtual environment, place the folder under:\n\nFor example, in a typical virtual environment, the directory structure should look like this:\n\nMove the folder to the correct location by running:\n\nOnce the directory structure is correct and the virtual environment is active, run the GUI:\nâ€¢ It will dynamically load available examples from the folder.\nâ€¢ Select an example from the list displayed in the GUI.\nâ€¢ Click Run Example to execute it.\n\nEnsure the folder contains valid Python files (e.g., , ). The output or visualization will appear after the example runs successfully.\n\nIf you prefer to run examples individually without using the GUI, follow these steps:\n\nThe folder contains Python scripts for various algorithms. Ensure the folder is downloaded and placed in the correct location:\n\nNavigate to the folder and execute any example script directly. For example:\n\nReplace with the path to your virtual environment.\nâ€¢ No Examples Displayed in the GUI:\nâ€¢ Verify the folder is in the correct location ( ).\nâ€¢ \nâ€¢ Ensure the virtual environment is activated before running the GUI or examples.\n\nBy following these steps, you can explore and run the library's examples interactively or individually.\n\nThis project is licensed under the MIT License. See the LICENSE file for details."
    },
    {
        "link": "https://pypi.org/project/MetaHeuristicsFS",
        "document": "A required part of this site couldnâ€™t load. This may be due to a browser extension, network issues, or browser settings. Please check your connection, disable any ad blockers, or try using a different browser."
    },
    {
        "link": "https://datacamp.com/tutorial/swarm-intelligence",
        "document": "Discover how to extract business value from AI. Learn to scope opportunities for AI, create POCs, implement solutions, and develop an AI strategy."
    },
    {
        "link": "https://medium.com/codex/python-project-idea-graph-traversal-and-pathfinding-algorithm-visualisations-99595c414293",
        "document": "Pathfinding methods are graph search algorithms that explore routes between nodes. i.e. the objective of the pathfinding algorithm is to move from a start node to an end node and track the path taken to reach the target. In this project, I implemented four key algorithms; Breadth-First Search, Depth First Search, Dijkstraâ€™s and A* (A star). There are numerous excellent resources available online that clearly describe these fundamental concepts. Think of a graph as a network of nodes. For example, figure 1 illustrates an undirected and a directed graph.\nâ€¢ Undirected graphs have connections with no direction. A two-way relationship exists between each edge.\nâ€¢ Directed graphs have links between vertices with arrows indicating which way information can travel along the edges. A grid effectively serves as a network of nodes. As the exploration transpires, the past, present and future of the nodes must be identified. Gist 1 shows the which encapsulates all possible state values. Gist 2 gives the Python code containing the class. Key properties include its grid position, the list of the surrounding elements, and the current .\n\nBreadth-First Search (BFS) and Depth First Search (DFS) are fundamental graph traversal algorithms. BFS walks through all nodes on the current level before moving on to the next level. Gist 3 gives the Python implementation of the BFS iterative algorithm used to find the path between two nodes in the grid. Coding interview challenges can often involve either of these techniques as a first-step analysis. Figure 2 illustrates the BFS algorithm in operation. DFS proceeds through the nodes as far as possible until we reach the node with no unvisited nearby nodes. The DFS Python solver is provided in Gist 4. To read about the comparison between these algorithms, see the Difference between BFS and DFS. DFS is visualised in Figure 3.\n\nDijkstraâ€™s and A* find the shortest path, which means they calculate the most concise route between a pair of nodes. Thus, they identify optimal ways between a starting and end node. Practical use cases for shortest route-finding methods like A* include logistics planning and IP routing.Â¹ Figure 4 illustrates Dijkstraâ€™s method. Weighted nodes exist on the canvas, which adds a further layer of complexity to the technique. Previous methods, BFS and DFS, did not account for weights. The A* algorithm improves the Dijkstra process by including extra information through a heuristic function that determines which paths to explore next. An example of such a heuristic is the Euclidean distance between the start- and endpoint. This optimisation results in finding the shortest paths more quickly. The A* algorithm can find the shortest paths between single pairs of locations where GPS coordinates are known. Figure 5 shows this method's efficiency on a much more extensive network than the other samples. A* and Dijkstra's algorithms are more or less the same, except that A* uses the heuristic. Therefore, both of these algorithms are implemented in the same with a to indicate which one is desired for use. See the code in Gist 5 for both methods."
    },
    {
        "link": "https://smartmobilityalgorithms.github.io/book/content/GraphSearchAlgorithms/BlindSearch.html",
        "document": "Blind Search algorithms can be split into traversal and shortest path algorithms.\n\nGraph traversal refers to a process that traverses vertices of a graph following a certain order (starting from user-input sources). This category of graph search algorithms only seeks to find a path between two nodes, without optimizing for the length of the final route. In applications where the weight of edges in a graph are all equal (e.g. 1), BFS and DFS algorithms outperform shortest path algorithms like Dijkstraâ€™s. Letâ€™s first find the largest connected component centered around our location, with a specified distance on each side. The reference point is the centre of the University of Torontoâ€™s downtown campus. To plot the network, we will also need to highlight the starting and ending nodes. For the sake of simplicity, we will use the node id directly. To review how to get the closest node to a given location, refer back to the previous section. This book uses the package for some operations, in order to simplify the process of visualizing graphs. You can find out more about downloading and installing the package here. # marking both the source and destination node Traceback (most recent call last) in : No module named 'smart_mobility_utilities' Letâ€™s visualize the above graph on a map, using a helper function from the package. For the purposes of this map, we use the option so that the map will be rendered by . Normally, when there are more than 1,000 nodes in a graph, performance is very slow. The visualization tools in will automatically switch to when there are more than 1,000 nodes, unless the flag is used. See the docs for for more information. Currently, each node in the above graph is represented as a python with many attributes that are of no interest to us. This makes accessing certain properties of nodes overly complicated and verbose. To minimize this, we can use the class from to redefine the nodes, and only retain key information like parent, edge length from parent, and the node itself. # First convert the source and destination nodes to Node BFS is an algorithm where the traversal starts at a specified node (the source or starting node) and continues along the graph layerwise, thus exploring all exploring all of the the current nodeâ€™s neighbouring nodes (those which are directly connected to the current node). If a result is not found, the algorithm proceeds to search the next-level neighbour nodes. \n\n\n\n BREADTH-FIRST-SEARCH(source,destination) return a route â† \n\n â† empty\n\n â† False\n\n\n\n while is not empty and is False do\n\n node â† .pop()\n\n add node to \n\n for child in node.expand() do child is not in and child is not in then child is destination then add child to return route \n\n\n\n Using BFS, search for the shortest path between The Equestrian Statue and the Bahen Centre. This example uses the same data as in From Road Network to Graph. The DFS algorithm is a recursive algorithm that uses the idea of backtracking. It involves exhaustive searches of all the nodes by going as deep as possible into the graph. When it reaches the last layer with no result, it â€œbacktracksâ€ up a layer and continues the search. DEPTH-FIRST-SEARCH(source,destination) return a route â† \n\n â† empty\n\n â† False\n\n\n\n while is not empty and is False do\n\n node â† .pop()\n\n add node to \n\n for child in node.expand() do child is not in and child is not in then child is destination then add child to return route \n\n\n\n As you may have the noticed, the only difference between DFS and BFS is in the way that works. Rather than working down layer by layer (FIFO), DFS drills down to the bottom-most layer and moves its way back to the starting node (LIFO). Letâ€™s implement this algorithm with our previous example. It is very evident that the paths generated by our DFS and BFS implementations are not the most direct route. This is because both DFS and BFS are algorithms that can find routes between two nodes, but make no guarantees that they will return the shortest path. Additionally, DFS generally returns â€œdeeperâ€ results as it traverses the entire depth of the graph and works backwards to find a solution.\n\nDijkstraâ€™s algorithm allows us to find the shortest path between any two vertices of a graph. The algorithm creates a tree of shortest paths from the starting vertex, the source, to all other points in the graph. Dijkstraâ€™s algorithm , published in 1959 and named after Dutch computer scientist Edsger Dijkstra, is the base of several other graph search algorithms commonly used to solve routing problems in popular navigation apps. \n\n The following pseudocode and `python` implementation for Dijkstra's algorithm has been modified to work with our OSM data. This is because graphs generated from maps will naturally have self-loops and parallel edges. Parallel edges may result in a route that is not the shortest available, as the route length depends heavily on which parallel edge was chosen when a particular path was generated. In the example below, the shortest path may be returned as 7, if the first edge connecting and is chosen when calculating that path. Self-loops also cause trouble for the original Dijkstra algorithm. If a graph contains a self-loop, it may be the case that the shortest path to a node comes from itself. At that point, we would be unable to generate a route. These two issues are generally easy but non-trivial to avoid. For parallel edges, we select the edge with the lowest weight (shortest length), and discard any other parallel edge. With self-loops, we can ignore the loop entirely as negative-weight loops do not exist in routing problems (a road cannot have negative length), and positive-weight loops cannot be part of a shortest path. \n\n\n\n DIJKSTRA-SEARCH(graph,source,destination) return a route â† empty\n\n â† empty\n\n â† empty\n\n\n\n \n\n for node in graph \n\n [source] â† 0\n\n â† False\n\n\n\n while is not empty and is False do node â† .pop()\n\n add node to \n\n if node is destination then for child in node.expand() do child in then skip\n\n distance â† [node] + length of edge to child\n\n if distance < [child] then return route \n\n\n\n # Using a set here avoids the problem with self loops # relaxing the node, so this node's value in shortest_dist is the shortest distance between the origin and destination # if the destination node has been relaxed then that is the route we want # otherwise, let's relax edges of its neighbours Uniform-Cost Search (UCS) algorithm is a blind search algorithm that uses the lowest cumulative cost to find a path from the origin to the destination. This variant of Dijkstraâ€™s algorithm is useful for large graphs as it is less time consuming and has fewer space requirements, where the priority queue is filled gradually as opposed to Dijkstraâ€™s, which adds all nodes to the queue on start with an infinite cost. UNIFORM-COST-SEARCH(graph,source,destination) return a route â† source\n\n â† False\n\n â† source\n\n\n\n while is not empty and is False do node â† .pop()\n\n â† node\n\n â† cumulative distance from origin\n\n if node is destination then for child in node.expand() do return route \n\n\n\n Essentially, the algorithm organizes nodes to be explored by their cost (with lowest cost as highest priority). As nodes are popped from the queue, the nodeâ€™s children are added to the queue. If a child already exists in the priority queue, the priorities of both copies of the child are compared, and the lowest cost (highest priority) is accepted. This ensures that the path to each child is the shortest one available. We also maintain a visited list to avoid revisiting nodes that have already been popped from the queue. # This implementation uses a heap with tuples (a,b), # a is the cost of a node, and b is the node id. # Update the entry if the new priority is better As you can see, the results are identical to that of Dijkstraâ€™s (the optimal solution), but this algorithm handles larger graphs much better, as it does not require all the nodes to be added to the queue at the very beginning."
    }
]