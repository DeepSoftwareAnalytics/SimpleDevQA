[
    {
        "link": "https://haskell.org/tutorial/goodies.html",
        "document": "Because Haskell is a purely functional language, all computations are done via the evaluation of expressions (syntactic terms) to yield values (abstract entities that we regard as answers). Every value has an associated type. (Intuitively, we can think of types as sets of values.) Examples of expressions include atomic values such as the integer , the character , and the function , as well as structured values such as the list and the pair .\n\nJust as expressions denote values, type expressions are syntactic terms that denote type values (or just types). Examples of type expressions include the atomic types (infinite-precision integers), (characters), (functions mapping to ), as well as the structured types (homogeneous lists of integers) and (character, integer pairs).\n\nAll Haskell values are \"first-class\"---they may be passed as arguments to functions, returned as results, placed in data structures, etc. Haskell types, on the other hand, are not first-class. Types in a sense describe values, and the association of a value with its type is called a typing. Using the examples of values and types above, we write typings as follows: The \" \" can be read \"has type.\"\n\nFunctions in Haskell are normally defined by a series of equations. For example, the function can be defined by the single equation: An equation is an example of a declaration. Another kind of declaration is a type signature declaration (§4.4.1), with which we can declare an explicit typing for : We will have much more to say about function definitions in Section 3.\n\nFor pedagogical purposes, when we wish to indicate that an expression e evaluates, or \"reduces,\" to another expression or value e , we will write:\n\nFor example, note that:\n\nHaskell's static type system defines the formal relationship between types and values (§4.1.4). The static type system ensures that Haskell programs are type safe; that is, that the programmer has not mismatched types in some way. For example, we cannot generally add together two characters, so the expression is ill-typed. The main advantage of statically typed languages is well-known: All type errors are detected at compile-time. Not all errors are caught by the type system; an expression such as is typable but its evaluation will result in an error at execution time. Still, the type system finds many program errors at compile time, aids the user in reasoning about programs, and also permits a compiler to generate more efficient code (for example, no run-time type tags or tests are required).\n\nThe type system also ensures that user-supplied type signatures are correct. In fact, Haskell's type system is powerful enough to allow us to avoid writing any type signatures at all; (With a few exceptions to be described later.) we say that the type system infers the correct types for us. Nevertheless, judicious placement of type signatures such as that we gave for is a good idea, since type signatures are a very effective form of documentation and help bring programming errors to light.\n\n[The reader will note that we have capitalized identifiers that denote specific types, such as and , but not identifiers that denote values, such as . This is not just a convention: it is enforced by Haskell's lexical syntax. In fact, the case of the other characters matters, too: , , and are all distinct identifiers.]\n\nHaskell also incorporates polymorphic types---types that are universally quantified in some way over all types. Polymorphic type expressions essentially describe families of types. For example, (forall ) is the family of types consisting of, for every type , the type of lists of . Lists of integers (e.g. ), lists of characters ( ), even lists of lists of integers, etc., are all members of this family. (Note, however, that is not a valid example, since there is no single type that contains both and .)\n\n[Identifiers such as above are called type variables, and are uncapitalized to distinguish them from specific types such as . Furthermore, since Haskell has only universally quantified types, there is no need to explicitly write out the symbol for universal quantification, and thus we simply write in the example above. In other words, all type variables are implicitly universally quantified.]\n\nLists are a commonly used data structure in functional languages, and are a good vehicle for explaining the principles of polymorphism. The list in Haskell is actually shorthand for the list , where is the empty list and is the infix operator that adds its first argument to the front of its second argument (a list). ( and are like Lisp's and , respectively.) Since is right associative, we can also write this list as .\n\nAs an example of a user-defined function that operates on lists, consider the problem of counting the number of elements in a list: This definition is almost self-explanatory. We can read the equations as saying: \"The length of the empty list is 0, and the length of a list whose first element is and remainder is is 1 plus the length of .\" (Note the naming convention used here; is the plural of , and should be read that way.)\n\nAlthough intuitive, this example highlights an important aspect of Haskell that is yet to be explained: pattern matching. The left-hand sides of the equations contain patterns such as and . In a function application these patterns are matched against actual parameters in a fairly intuitive way ( only matches the empty list, and will successfully match any list with at least one element, binding to the first element and to the rest of the list). If the match succeeds, the right-hand side is evaluated and returned as the result of the application. If it fails, the next equation is tried, and if all equations fail, an error results.\n\nDefining functions by pattern matching is quite common in Haskell, and the user should become familiar with the various kinds of patterns that are allowed; we will return to this issue in Section 4.\n\nThe function is also an example of a polymorphic function. It can be applied to a list containing elements of any type, for example , , or .\n\nHere are two other useful polymorphic functions on lists that will be used later. Function returns the first element of a list, function returns all but the first. Unlike , these functions are not defined for all possible values of their argument. A runtime error occurs when these functions are applied to an empty list.\n\nWith polymorphic types, we find that some types are in a sense strictly more general than others in the sense that the set of values they define is larger. For example, the type is more general than . In other words, the latter type can be derived from the former by a suitable substitution for . With regard to this generalization ordering, Haskell's type system possesses two important properties: First, every well-typed expression is guaranteed to have a unique principal type (explained below), and second, the principal type can be inferred automatically (§4.1.4). In comparison to a monomorphically typed language such as C, the reader will find that polymorphism improves expressiveness, and type inference lessens the burden of types on the programmer.\n\nAn expression's or function's principal type is the least general type that, intuitively, \"contains all instances of the expression\". For example, the principal type of is ; , , or even are correct types, but too general, whereas something like is too specific. The existence of unique principal types is the hallmark feature of the Hindley-Milner type system, which forms the basis of the type systems of Haskell, ML, Miranda, (\"Miranda\" is a trademark of Research Software, Ltd.) and several other (mostly functional) languages.\n\nWe can define our own types in Haskell using a declaration, which we introduce via a series of examples (§4.2.1).\n\nAn important predefined type in Haskell is that of truth values: The type being defined here is , and it has exactly two values: and . Type is an example of a (nullary) type constructor, and and are (also nullary) data constructors (or just constructors, for short).\n\nSimilarly, we might wish to define a color type: Both and are examples of enumerated types, since they consist of a finite number of nullary data constructors.\n\nHere is an example of a type with just one data constructor: Because of the single constructor, a type like is often called a tuple type, since it is essentially just a cartesian product (in this case binary) of other types. (Tuples are somewhat like records in other languages.) In contrast, multi-constructor types, such as and , are called (disjoint) union or sum types.\n\nMore importantly, however, is an example of a polymorphic type: for any type t, it defines the type of cartesian points that use t as the coordinate type. The type can now be seen clearly as a unary type constructor, since from the type t it constructs a new type t. (In the same sense, using the list example given earlier, is also a type constructor. Given any type t we can \"apply\" to yield a new type t . The Haskell syntax allows t to be written as t . Similarly, is a type constructor: given two types t and u, t u is the type of functions mapping elements of type t to elements of type u.)\n\nNote that the type of the binary data constructor is , and thus the following typings are valid: On the other hand, an expression such as is ill-typed because and are of different types.\n\nIt is important to distinguish between applying a data constructor to yield a value, and applying a type constructor to yield a type; the former happens at run-time and is how we compute things in Haskell, whereas the latter happens at compile-time and is part of the type system's process of ensuring type safety.\n\n[Type constructors such as and data constructors such as are in separate namespaces. This allows the same name to be used for both a type constructor and data constructor, as in the following: While this may seem a little confusing at first, it serves to make the link between a type and its data constructor more obvious.]\n\nTypes can also be recursive, as in the type of binary trees: Here we have defined a polymorphic binary tree type whose elements are either leaf nodes containing a value of type , or internal nodes (\"branches\") containing (recursively) two sub-trees.\n\nWhen reading data declarations such as this, remember again that is a type constructor, whereas and are data constructors. Aside from establishing a connection between these constructors, the above declaration is essentially defining the following types for and :\n\nWith this example we have defined a type sufficiently rich to allow defining some interesting (recursive) functions that use it. For example, suppose we wish to define a function that returns a list of all the elements in the leaves of a tree from left to right. It's usually helpful to write down the type of new functions first; in this case we see that the type should be . That is, is a polymorphic function that, for any type , maps trees of into lists of . A suitable definition follows: Here is the infix operator that concatenates two lists (its full definition will be given in Section 9.1). As with the example given earlier, the function is defined using pattern matching, except that here we see patterns involving user-defined constructors: and . [Note that the formal parameters are easily identified as the ones beginning with lower-case letters.]\n\nFor convenience, Haskell provides a way to define type synonyms; i.e. names for commonly used types. Type synonyms are created using a declaration (§4.2.2). Here are several examples:\n\nType synonyms do not define new types, but simply give new names for existing types. For example, the type is precisely equivalent to . The new names are often shorter than the types they are synonymous with, but this is not the only purpose of type synonyms: they can also improve readability of programs by being more mnemonic; indeed, the above examples highlight this. We can even give new names to polymorphic types: This is the type of \"association lists\" which associate values of type with those of type .\n\nEarlier we introduced several \"built-in\" types such as lists, tuples, integers, and characters. We have also shown how new user-defined types can be defined. Aside from special syntax, are the built-in types in any way more special than the user-defined ones? The answer is no. The special syntax is for convenience and for consistency with historical convention, but has no semantic consequences.\n\nWe can emphasize this point by considering what the type declarations would look like for these built-in types if in fact we were allowed to use the special syntax in defining them. For example, the type might be written as: \n\n \n\n data Char = 'a' | 'b' | 'c' | ... -- This is not valid\n\n | 'A' | 'B' | 'C' | ... -- Haskell code!\n\n | '1' | '2' | '3' | ...\n\n ...\n\n \n\n These constructor names are not syntactically valid; to fix them we would have to write something like: Even though these constructors are more concise, they are quite unconventional for representing characters.\n\nIn any case, writing \"pseudo-Haskell\" code in this way helps us to see through the special syntax. We see now that is just an enumerated type consisting of a large number of nullary constructors. Thinking of in this way makes it clear that we can pattern-match against characters in function definitions, just as we would expect to be able to do so for any of a type's constructors.\n\n[This example also demonstrates the use of comments in Haskell; the characters and all subsequent characters to the end of the line are ignored. Haskell also permits nested comments which have the form ... and can appear anywhere (§2.2).]\n\nSimilarly, we could define (fixed precision integers) and by: where and , say, are the maximum and minimum fixed precision integers for a given implementation. is a much larger enumeration than , but it's still finite! In contrast, the pseudo-code for is intended to convey an infinite enumeration.\n\nTuples are also easy to define playing this game: Each declaration above defines a tuple type of a particular length, with playing a role in both the expression syntax (as data constructor) and type-expression syntax (as type constructor). The vertical dots after the last declaration are intended to convey an infinite number of such declarations, reflecting the fact that tuples of all lengths are allowed in Haskell.\n\nLists are also easily handled, and more interestingly, they are recursive: We can now see clearly what we described about lists earlier: is the empty list, and is the infix list constructor; thus must be equivalent to the list . ( is right associative.) The type of is , and the type of is .\n\n[The way \" \" is defined here is actually legal syntax---infix constructors are permitted in declarations, and are distinguished from infix operators (for pattern-matching purposes) by the fact that they must begin with a \" \" (a property trivially satisfied by \" \").]\n\nAt this point the reader should note carefully the differences between tuples and lists, which the above definitions make abundantly clear. In particular, note the recursive nature of the list type whose elements are homogeneous and of arbitrary length, and the non-recursive nature of a (particular) tuple type whose elements are heterogeneous and of fixed length. The typing rules for tuples and lists should now also be clear:\n\nFor e e ... e , n>=2, if t is the type of e , then the type of the tuple is t t ... t .\n\nFor e e ... e , n>=0, each e must have the same type t, and the type of the list is t .\n\nAs with Lisp dialects, lists are pervasive in Haskell, and as with other functional languages, there is yet more syntactic sugar to aid in their creation. Aside from the constructors for lists just discussed, Haskell provides an expression known as a list comprehension that is best explained by example: This expression can intuitively be read as \"the list of all such that is drawn from .\" The similarity to set notation is not a coincidence. The phrase is called a generator, of which more than one is allowed, as in: This list comprehension forms the cartesian product of the two lists and . The elements are selected as if the generators were \"nested\" from left to right (with the rightmost generator varying fastest); thus, if is and is , the result is .\n\nBesides generators, boolean expressions called guards are permitted. Guards place constraints on the elements generated. For example, here is a concise definition of everybody's favorite sorting algorithm:\n\nTo further support the use of lists, Haskell has special syntax for arithmetic sequences, which are best explained by a series of examples:\n\nMore will be said about arithmetic sequences in Section 8.2, and \"infinite lists\" in Section 3.4.\n\nAs another example of syntactic sugar for built-in types, we note that the literal string is actually shorthand for the list of characters . Indeed, the type of is , where is a predefined type synonym (that we gave as an earlier example): This means we can use predefined polymorphic list functions to operate on strings. For example:"
    },
    {
        "link": "https://haskell.org/haskellwiki/type",
        "document": "In Haskell, types are how you describe the data your program will work with.\n\nOne introduces, or declares, a type in Haskell via the statement. In general a data declaration looks like:\n\nwhich probably explains nothing if you don't already know Haskell!\n\nThe essence of the above statement is that you use the keyword , supply an optional context, give the type name and a variable number of type variables. This is then followed by a variable number of constructors, each of which has a list of type variables or type constants. At the end, there is an optional .\n\nThere are a number of other subtleties associated with this, such as requiring parameters to the data constructors to be eager, what classes are allowed in the deriving, use of field names in the constructors and what the context actually does. Please refer to the specific articles for more on each of those.\n\nLet's look at some examples. The Haskell standard data type Maybe is typically declared as:"
    },
    {
        "link": "https://learnyouahaskell.com/making-our-own-types-and-typeclasses",
        "document": "Making Our Own Types and Typeclasses\n\nIn the previous chapters, we covered some existing Haskell types and typeclasses. In this chapter, we'll learn how to make our own and how to put them to work!\n\nSo far, we've run into a lot of data types. Bool, Int, Char, Maybe, etc. But how do we make our own? Well, one way is to use the data keyword to define a type. Let's see how the Bool type is defined in the standard library.\n\ndata means that we're defining a new data type. The part before the = denotes the type, which is Bool. The parts after the = are value constructors. They specify the different values that this type can have. The | is read as or. So we can read this as: the Bool type can have a value of True or False. Both the type name and the value constructors have to be capital cased.\n\nIn a similar fashion, we can think of the Int type as being defined like this:\n\nThe first and last value constructors are the minimum and maximum possible values of Int. It's not actually defined like this, the ellipses are here because we omitted a heapload of numbers, so this is just for illustrative purposes.\n\nNow, let's think about how we would represent a shape in Haskell. One way would be to use tuples. A circle could be denoted as (43.1, 55.0, 10.4) where the first and second fields are the coordinates of the circle's center and the third field is the radius. Sounds OK, but those could also represent a 3D vector or anything else. A better solution would be to make our own type to represent a shape. Let's say that a shape can be a circle or a rectangle. Here it is:\n\nNow what's this? Think of it like this. The Circle value constructor has three fields, which take floats. So when we write a value constructor, we can optionally add some types after it and those types define the values it will contain. Here, the first two fields are the coordinates of its center, the third one its radius. The Rectangle value constructor has four fields which accept floats. The first two are the coordinates to its upper left corner and the second two are coordinates to its lower right one.\n\nNow when I say fields, I actually mean parameters. Value constructors are actually functions that ultimately return a value of a data type. Let's take a look at the type signatures for these two value constructors.\n\nCool, so value constructors are functions like everything else. Who would have thought? Let's make a function that takes a shape and returns its surface.\n\nThe first notable thing here is the type declaration. It says that the function takes a shape and returns a float. We couldn't write a type declaration of Circle -> Float because Circle is not a type, Shape is. Just like we can't write a function with a type declaration of True -> Int. The next thing we notice here is that we can pattern match against constructors. We pattern matched against constructors before (all the time actually) when we pattern matched against values like [] or False or 5, only those values didn't have any fields. We just write a constructor and then bind its fields to names. Because we're interested in the radius, we don't actually care about the first two fields, which tell us where the circle is.\n\nYay, it works! But if we try to just print out Circle 10 20 5 in the prompt, we'll get an error. That's because Haskell doesn't know how to display our data type as a string (yet). Remember, when we try to print a value out in the prompt, Haskell first runs the show function to get the string representation of our value and then it prints that out to the terminal. To make our Shape type part of the Show typeclass, we modify it like this:\n\nWe won't concern ourselves with deriving too much for now. Let's just say that if we add deriving (Show) at the end of a data declaration, Haskell automagically makes that type part of the Show typeclass. So now, we can do this:\n\nValue constructors are functions, so we can map them and partially apply them and everything. If we want a list of concentric circles with different radii, we can do this.\n\nOur data type is good, although it could be better. Let's make an intermediate data type that defines a point in two-dimensional space. Then we can use that to make our shapes more understandable.\n\nNotice that when defining a point, we used the same name for the data type and the value constructor. This has no special meaning, although it's common to use the same name as the type if there's only one value constructor. So now the Circle has two fields, one is of type Point and the other of type Float. This makes it easier to understand what's what. Same goes for the rectangle. We have to adjust our surface function to reflect these changes.\n\nThe only thing we had to change were the patterns. We disregarded the whole point in the circle pattern. In the rectangle pattern, we just used a nested pattern matching to get the fields of the points. If we wanted to reference the points themselves for some reason, we could have used as-patterns.\n\nHow about a function that nudges a shape? It takes a shape, the amount to move it on the x axis and the amount to move it on the y axis and then returns a new shape that has the same dimensions, only it's located somewhere else.\n\nPretty straightforward. We add the nudge amounts to the points that denote the position of the shape.\n\nIf we don't want to deal directly with points, we can make some auxilliary functions that create shapes of some size at the zero coordinates and then nudge those.\n\nYou can, of course, export your data types in your modules. To do that, just write your type along with the functions you are exporting and then add some parentheses and in them specify the value constructors that you want to export for it, separated by commas. If you want to export all the value constructors for a given type, just write ...\n\nIf we wanted to export the functions and types that we defined here in a module, we could start it off like this:\n\nBy doing Shape(..), we exported all the value constructors for Shape, so that means that whoever imports our module can make shapes by using the Rectangle and Circle value constructors. It's the same as writing Shape (Rectangle, Circle).\n\nWe could also opt not to export any value constructors for Shape by just writing Shape in the export statement. That way, someone importing our module could only make shapes by using the auxilliary functions baseCircle and baseRect. Data.Map uses that approach. You can't create a map by doing Map.Map [(1,2),(3,4)] because it doesn't export that value constructor. However, you can make a mapping by using one of the auxilliary functions like Map.fromList. Remember, value constructors are just functions that take the fields as parameters and return a value of some type (like Shape) as a result. So when we choose not to export them, we just prevent the person importing our module from using those functions, but if some other functions that are exported return a type, we can use them to make values of our custom data types.\n\nNot exporting the value constructors of a data types makes them more abstract in such a way that we hide their implementation. Also, whoever uses our module can't pattern match against the value constructors.\n\nOK, we've been tasked with creating a data type that describes a person. The info that we want to store about that person is: first name, last name, age, height, phone number, and favorite ice-cream flavor. I don't know about you, but that's all I ever want to know about a person. Let's give it a go!\n\nO-kay. The first field is the first name, the second is the last name, the third is the age and so on. Let's make a person.\n\nThat's kind of cool, although slightly unreadable. What if we want to create a function to get seperate info from a person? A function that gets some person's first name, a function that gets some person's last name, etc. Well, we'd have to define them kind of like this.\n\nWhew! I certainly did not enjoy writing that! Despite being very cumbersome and BORING to write, this method works.\n\nThere must be a better way, you say! Well no, there isn't, sorry.\n\nJust kidding, there is. Hahaha! The makers of Haskell were very smart and anticipated this scenario. They included an alternative way to write data types. Here's how we could achieve the above functionality with record syntax.\n\nSo instead of just naming the field types one after another and separating them with spaces, we use curly brackets. First we write the name of the field, for instance, firstName and then we write a double colon :: (also called Paamayim Nekudotayim, haha) and then we specify the type. The resulting data type is exactly the same. The main benefit of this is that it creates functions that lookup fields in the data type. By using record syntax to create this data type, Haskell automatically made these functions: firstName, lastName, age, height, phoneNumber and flavor.\n\nThere's another benefit to using record syntax. When we derive Show for the type, it displays it differently if we use record syntax to define and instantiate the type. Say we have a type that represents a car. We want to keep track of the company that made it, the model name and its year of production. Watch.\n\nIf we define it using record syntax, we can make a new car like this.\n\nWhen making a new car, we don't have to necessarily put the fields in the proper order, as long as we list all of them. But if we don't use record syntax, we have to specify them in order.\n\nUse record syntax when a constructor has several fields and it's not obvious which field is which. If we make a 3D vector data type by doing data Vector = Vector Int Int Int, it's pretty obvious that the fields are the components of a vector. However, in our Person and Car types, it wasn't so obvious and we greatly benefited from using record syntax.\n\nA value constructor can take some values parameters and then produce a new value. For instance, the Car constructor takes three values and produces a car value. In a similar manner, type constructors can take types as parameters to produce new types. This might sound a bit too meta at first, but it's not that complicated. If you're familiar with templates in C++, you'll see some parallels. To get a clear picture of what type parameters work like in action, let's take a look at how a type we've already met is implemented.\n\nThe a here is the type parameter. And because there's a type parameter involved, we call Maybe a type constructor. Depending on what we want this data type to hold when it's not Nothing, this type constructor can end up producing a type of Maybe Int, Maybe Car, Maybe String, etc. No value can have a type of just Maybe, because that's not a type per se, it's a type constructor. In order for this to be a real type that a value can be part of, it has to have all its type parameters filled up.\n\nSo if we pass Char as the type parameter to Maybe, we get a type of Maybe Char. The value Just 'a' has a type of Maybe Char, for example.\n\nYou might not know it, but we used a type that has a type parameter before we used Maybe. That type is the list type. Although there's some syntactic sugar in play, the list type takes a parameter to produce a concrete type. Values can have an [Int] type, a [Char] type, a [[String]] type, but you can't have a value that just has a type of [].\n\nLet's play around with the Maybe type.\n\nType parameters are useful because we can make different types with them depending on what kind of types we want contained in our data type. When we do :t Just \"Haha\", the type inference engine figures it out to be of the type Maybe [Char], because if the a in the Just a is a string, then the a in Maybe a must also be a string.\n\nNotice that the type of Nothing is Maybe a. Its type is polymorphic. If some function requires a Maybe Int as a parameter, we can give it a Nothing, because a Nothing doesn't contain a value anyway and so it doesn't matter. The Maybe a type can act like a Maybe Int if it has to, just like 5 can act like an Int or a Double. Similarly, the type of the empty list is [a]. An empty list can act like a list of anything. That's why we can do [1,2,3] ++ [] and [\"ha\",\"ha\",\"ha\"] ++ [].\n\nUsing type parameters is very beneficial, but only when using them makes sense. Usually we use them when our data type would work regardless of the type of the value it then holds inside it, like with our Maybe a type. If our type acts as some kind of box, it's good to use them. We could change our Car data type from this:\n\nBut would we really benefit? The answer is: probably no, because we'd just end up defining functions that only work on the Car String String Int type. For instance, given our first definition of Car, we could make a function that displays the car's properties in a nice little text.\n\nA cute little function! The type declaration is cute and it works nicely. Now what if Car was Car a b c?\n\nWe'd have to force this function to take a Car type of (Show a) => Car String String a. You can see that the type signature is more complicated and the only benefit we'd actually get would be that we can use any type that's an instance of the Show typeclass as the type for c.\n\nIn real life though, we'd end up using Car String String Int most of the time and so it would seem that parameterizing the Car type isn't really worth it. We usually use type parameters when the type that's contained inside the data type's various value constructors isn't really that important for the type to work. A list of stuff is a list of stuff and it doesn't matter what the type of that stuff is, it can still work. If we want to sum a list of numbers, we can specify later in the summing function that we specifically want a list of numbers. Same goes for Maybe. Maybe represents an option of either having nothing or having one of something. It doesn't matter what the type of that something is.\n\nAnother example of a parameterized type that we've already met is Map k v from Data.Map. The k is the type of the keys in a map and the v is the type of the values. This is a good example of where type parameters are very useful. Having maps parameterized enables us to have mappings from any type to any other type, as long as the type of the key is part of the Ord typeclass. If we were defining a mapping type, we could add a typeclass constraint in the data declaration:\n\nHowever, it's a very strong convention in Haskell to never add typeclass constraints in data declarations. Why? Well, because we don't benefit a lot, but we end up writing more class constraints, even when we don't need them. If we put or don't put the Ord k constraint in the data declaration for Map k v, we're going to have to put the constraint into functions that assume the keys in a map can be ordered. But if we don't put the constraint in the data declaration, we don't have to put (Ord k) => in the type declarations of functions that don't care whether the keys can be ordered or not. An example of such a function is toList, that just takes a mapping and converts it to an associative list. Its type signature is toList :: Map k a -> [(k, a)]. If Map k v had a type constraint in its data declaration, the type for toList would have to be toList :: (Ord k) => Map k a -> [(k, a)], even though the function doesn't do any comparing of keys by order.\n\nSo don't put type constraints into data declarations even if it seems to make sense, because you'll have to put them into the function type declarations either way.\n\nLet's implement a 3D vector type and add some operations for it. We'll be using a parameterized type because even though it will usually contain numeric types, it will still support several of them.\n\nvplus is for adding two vectors together. Two vectors are added just by adding their corresponding components. scalarMult is for the scalar product of two vectors and vectMult is for multiplying a vector with a scalar. These functions can operate on types of Vector Int, Vector Integer, Vector Float, whatever, as long as the a from Vector a is from the Num typeclass. Also, if you examine the type declaration for these functions, you'll see that they can operate only on vectors of the same type and the numbers involved must also be of the type that is contained in the vectors. Notice that we didn't put a Num class constraint in the data declaration, because we'd have to repeat it in the functions anyway.\n\nOnce again, it's very important to distinguish between the type constructor and the value constructor. When declaring a data type, the part before the = is the type constructor and the constructors after it (possibly separated by |'s) are value constructors. Giving a function a type of Vector t t t -> Vector t t t -> t would be wrong, because we have to put types in type declaration and the vector type constructor takes only one parameter, whereas the value constructor takes three. Let's play around with our vectors.\n\nIn the Typeclasses 101 section, we explained the basics of typeclasses. We explained that a typeclass is a sort of an interface that defines some behavior. A type can be made an instance of a typeclass if it supports that behavior. Example: the Int type is an instance of the Eq typeclass because the Eq typeclass defines behavior for stuff that can be equated. And because integers can be equated, Int is a part of the Eq typeclass. The real usefulness comes with the functions that act as the interface for Eq, namely == and /=. If a type is a part of the Eq typeclass, we can use the == functions with values of that type. That's why expressions like 4 == 4 and \"foo\" /= \"bar\" typecheck.\n\nWe also mentioned that they're often confused with classes in languages like Java, Python, C++ and the like, which then baffles a lot of people. In those languages, classes are a blueprint from which we then create objects that contain state and can do some actions. Typeclasses are more like interfaces. We don't make data from typeclasses. Instead, we first make our data type and then we think about what it can act like. If it can act like something that can be equated, we make it an instance of the Eq typeclass. If it can act like something that can be ordered, we make it an instance of the Ord typeclass.\n\nIn the next section, we'll take a look at how we can manually make our types instances of typeclasses by implementing the functions defined by the typeclasses. But right now, let's see how Haskell can automatically make our type an instance of any of the following typeclasses: Eq, Ord, Enum, Bounded, Show, Read. Haskell can derive the behavior of our types in these contexts if we use the deriving keyword when making our data type.\n\nIt describes a person. Let's assume that no two people have the same combination of first name, last name and age. Now, if we have records for two people, does it make sense to see if they represent the same person? Sure it does. We can try to equate them and see if they're equal or not. That's why it would make sense for this type to be part of the Eq typeclass. We'll derive the instance.\n\nWhen we derive the Eq instance for a type and then try to compare two values of that type with == or /=, Haskell will see if the value constructors match (there's only one value constructor here though) and then it will check if all the data contained inside matches by testing each pair of fields with ==. There's only one catch though, the types of all the fields also have to be part of the Eq typeclass. But since both String and Int are, we're OK. Let's test our Eq instance.\n\nOf course, since Person is now in Eq, we can use it as the a for all functions that have a class constraint of Eq a in their type signature, such as elem.\n\nThe Show and Read typeclasses are for things that can be converted to or from strings, respectively. Like with Eq, if a type's constructors have fields, their type has to be a part of Show or Read if we want to make our type an instance of them. Let's make our Person data type a part of Show and Read as well.\n\nNow we can print a person out to the terminal.\n\nHad we tried to print a person on the terminal before making the Person data type part of Show, Haskell would have complained at us, claiming it doesn't know how to represent a person as a string. But now that we've derived a Show instance for it, it does know.\n\nRead is pretty much the inverse typeclass of Show. Show is for converting values of our a type to a string, Read is for converting strings to values of our type. Remember though, when we use the read function, we have to use an explicit type annotation to tell Haskell which type we want to get as a result. If we don't make the type we want as a result explicit, Haskell doesn't know which type we want.\n\nIf we use the result of our read later on in a way that Haskell can infer that it should read it as a person, we don't have to use type annotation.\n\nWe can also read parameterized types, but we have to fill in the type parameters. So we can't do read \"Just 't'\" :: Maybe a, but we can do read \"Just 't'\" :: Maybe Char.\n\nWe can derive instances for the Ord type class, which is for types that have values that can be ordered. If we compare two values of the same type that were made using different constructors, the value which was made with a constructor that's defined first is considered smaller. For instance, consider the Bool type, which can have a value of either False or True. For the purpose of seeing how it behaves when compared, we can think of it as being implemented like this:\n\nBecause the False value constructor is specified first and the True value constructor is specified after it, we can consider True as greater than False.\n\nIn the Maybe a data type, the Nothing value constructor is specified before the Just value constructor, so a value of Nothing is always smaller than a value of Just something, even if that something is minus one billion trillion. But if we compare two Just values, then it goes to compare what's inside them.\n\nBut we can't do something like Just (*3) > Just (*2), because (*3) and (*2) are functions, which aren't instances of Ord.\n\nWe can easily use algebraic data types to make enumerations and the Enum and Bounded typeclasses help us with that. Consider the following data type:\n\nBecause all the value constructors are nullary (take no parameters, i.e. fields), we can make it part of the Enum typeclass. The Enum typeclass is for things that have predecessors and successors. We can also make it part of the Bounded typeclass, which is for things that have a lowest possible value and highest possible value. And while we're at it, let's also make it an instance of all the other derivable typeclasses and see what we can do with it.\n\nBecause it's part of the Show and Read typeclasses, we can convert values of this type to and from strings.\n\nBecause it's part of the Eq and Ord typeclasses, we can compare or equate days.\n\nIt's also part of Bounded, so we can get the lowest and highest day.\n\nIt's also an instance of Enum. We can get predecessors and successors of days and we can make list ranges from them!\n\nPreviously, we mentioned that when writing types, the [Char] and String types are equivalent and interchangeable. That's implemented with type synonyms. Type synonyms don't really do anything per se, they're just about giving some types different names so that they make more sense to someone reading our code and documentation. Here's how the standard library defines String as a synonym for [Char].\n\nWe've introduced the type keyword. The keyword might be misleading to some, because we're not actually making anything new (we did that with the data keyword), but we're just making a synonym for an already existing type.\n\nIf we make a function that converts a string to uppercase and call it toUpperString or something, we can give it a type declaration of toUpperString :: [Char] -> [Char] or toUpperString :: String -> String. Both of these are essentially the same, only the latter is nicer to read.\n\nWhen we were dealing with the Data.Map module, we first represented a phonebook with an association list before converting it into a map. As we've already found out, an association list is a list of key-value pairs. Let's look at a phonebook that we had.\n\nWe see that the type of phoneBook is [(String,String)]. That tells us that it's an association list that maps from strings to strings, but not much else. Let's make a type synonym to convey some more information in the type declaration.\n\nNow the type declaration for our phonebook can be phoneBook :: PhoneBook. Let's make a type synonym for String as well.\n\nGiving the String type synonyms is something that Haskell programmers do when they want to convey more information about what strings in their functions should be used as and what they represent.\n\nSo now, when we implement a function that takes a name and a number and sees if that name and number combination is in our phonebook, we can give it a very pretty and descriptive type declaration.\n\nIf we decided not to use type synonyms, our function would have a type of String -> String -> [(String,String)] -> Bool. In this case, the type declaration that took advantage of type synonyms is easier to understand. However, you shouldn't go overboard with them. We introduce type synonyms either to describe what some existing type represents in our functions (and thus our type declarations become better documentation) or when something has a long-ish type that's repeated a lot (like [(String,String)]) but represents something more specific in the context of our functions.\n\nType synonyms can also be parameterized. If we want a type that represents an association list type but still want it to be general so it can use any type as the keys and values, we can do this:\n\nNow, a function that gets the value by a key in an association list can have a type of (Eq k) => k -> AssocList k v -> Maybe v. AssocList is a type constructor that takes two types and produces a concrete type, like AssocList Int String, for instance.\n\nFonzie says: Aaay! When I talk about concrete types I mean like fully applied types like or if we're dealin' with one of them polymorphic functions, or and stuff. And like, sometimes me and the boys say that is a type, but we don't mean that, cause every idiot knows is a type constructor. When I apply an extra type to , like , then I have a concrete type. You know, values can only have types that are concrete types! So in conclusion, live fast, love hard and don't let anybody else use your comb!\n\nJust like we can partially apply functions to get new functions, we can partially apply type parameters and get new type constructors from them. Just like we call a function with too few parameters to get back a new function, we can specify a type constructor with too few type parameters and get back a partially applied type constructor. If we wanted a type that represents a map (from Data.Map) from integers to something, we could either do this:\n\nOr we could do it like this:\n\nEither way, the IntMap type constructor takes one parameter and that is the type of what the integers will point to.\n\nOh yeah. If you're going to try and implement this, you'll probably going to do a qualified import of . When you do a qualified import, type constructors also have to be preceeded with a module name. So you'd write .\n\nMake sure that you really understand the distinction between type constructors and value constructors. Just because we made a type synonym called IntMap or AssocList doesn't mean that we can do stuff like AssocList [(1,2),(4,5),(7,9)]. All it means is that we can refer to its type by using different names. We can do [(1,2),(3,5),(8,9)] :: AssocList Int Int, which will make the numbers inside assume a type of Int, but we can still use that list as we would any normal list that has pairs of integers inside. Type synonyms (and types generally) can only be used in the type portion of Haskell. We're in Haskell's type portion whenever we're defining new types (so in data and type declarations) or when we're located after a ::. The :: is in type declarations or in type annotations.\n\nAnother cool data type that takes two types as its parameters is the Either a b type. This is roughly how it's defined:\n\nIt has two value constructors. If the Left is used, then its contents are of type a and if Right is used, then its contents are of type b. So we can use this type to encapsulate a value of one type or another and then when we get a value of type Either a b, we usually pattern match on both Left and Right and we different stuff based on which one of them it was.\n\nSo far, we've seen that Maybe a was mostly used to represent the results of computations that could have either failed or not. But somtimes, Maybe a isn't good enough because Nothing doesn't really convey much information other than that something has failed. That's cool for functions that can fail in only one way or if we're just not interested in how and why they failed. A Data.Map lookup fails only if the key we were looking for wasn't in the map, so we know exactly what happened. However, when we're interested in how some function failed or why, we usually use the result type of Either a b, where a is some sort of type that can tell us something about the possible failure and b is the type of a successful computation. Hence, errors use the Left value constructor while results use Right.\n\nAn example: a high-school has lockers so that students have some place to put their Guns'n'Roses posters. Each locker has a code combination. When a student wants a new locker, they tell the locker supervisor which locker number they want and he gives them the code. However, if someone is already using that locker, he can't tell them the code for the locker and they have to pick a different one. We'll use a map from Data.Map to represent the lockers. It'll map from locker numbers to a pair of whether the locker is in use or not and the locker code.\n\nSimple stuff. We introduce a new data type to represent whether a locker is taken or free and we make a type synonym for the locker code. We also make a type synonym for the type that maps from integers to pairs of locker state and code. And now, we're going to make a function that searches for the code in a locker map. We're going to use an Either String Code type to represent our result, because our lookup can fail in two ways — the locker can be taken, in which case we can't tell the code or the locker number might not exist at all. If the lookup fails, we're just going to use a String to tell what's happened.\n\nWe do a normal lookup in the map. If we get a Nothing, we return a value of type Left String, saying that the locker doesn't exist at all. If we do find it, then we do an additional check to see if the locker is taken. If it is, return a Left saying that it's already taken. If it isn't, then return a value of type Right Code, in which we give the student the correct code for the locker. It's actually a Right String, but we introduced that type synonym to introduce some additional documentation into the type declaration. Here's an example map:\n\nNow let's try looking up some locker codes.\n\nWe could have used a Maybe a to represent the result but then we wouldn't know why we couldn't get the code. But now, we have information about the failure in our result type.\n\nAs we've seen, a constructor in an algebraic data type can have several (or none at all) fields and each field must be of some concrete type. With that in mind, we can make types whose constructors have fields that are of the same type! Using that, we can create recursive data types, where one value of some type contains values of that type, which in turn contain more values of the same type and so on.\n\nThink about this list: [5]. That's just syntactic sugar for 5:[]. On the left side of the :, there's a value and on the right side, there's a list. And in this case, it's an empty list. Now how about the list [4,5]? Well, that desugars to 4:(5:[]). Looking at the first :, we see that it also has an element on its left side and a list (5:[]) on its right side. Same goes for a list like 3:(4:(5:6:[])), which could be written either like that or like 3:4:5:6:[] (because : is right-associative) or [3,4,5,6].\n\nWe could say that a list can be an empty list or it can be an element joined together with a : with another list (that can be either the empty list or not).\n\nLet's use algebraic data types to implement our own list then!\n\nThis reads just like our definition of lists from one of the previous paragraphs. It's either an empty list or a combination of a head with some value and a list. If you're confused about this, you might find it easier to understand in record syntax.\n\nYou might also be confused about the Cons constructor here. cons is another word for :. You see, in lists, : is actually a constructor that takes a value and another list and returns a list. We can already use our new list type! In other words, it has two fields. One field is of the type of a and the other is of the type [a].\n\nWe called our Cons constructor in an infix manner so you can see how it's just like :. Empty is like [] and 4 `Cons` (5 `Cons` Empty) is like 4:(5:[]).\n\nWe can define functions to be automatically infix by making them comprised of only special characters. We can also do the same with constructors, since they're just functions that return a data type. So check this out.\n\nFirst off, we notice a new syntactic construct, the fixity declarations. When we define functions as operators, we can use that to give them a fixity (but we don't have to). A fixity states how tightly the operator binds and whether it's left-associative or right-associative. For instance, *'s fixity is infixl 7 * and +'s fixity is infixl 6. That means that they're both left-associative (4 * 3 * 2 is (4 * 3) * 2) but * binds tighter than +, because it has a greater fixity, so 5 * 4 + 3 is (5 * 4) + 3.\n\nOtherwise, we just wrote a :-: (List a) instead of Cons a (List a). Now, we can write out lists in our list type like so:\n\nWhen deriving Show for our type, Haskell will still display it as if the constructor was a prefix function, hence the parentheses around the operator (remember, 4 + 3 is (+) 4 3).\n\nLet's make a function that adds two of our lists together. This is how ++ is defined for normal lists:\n\nSo we'll just steal that for our own list. We'll name the function .++.\n\nAnd let's see if it works ...\n\nNice. Is nice. If we wanted, we could implement all of the functions that operate on lists on our own list type.\n\nNotice how we pattern matched on (x :-: xs). That works because pattern matching is actually about matching constructors. We can match on :-: because it is a constructor for our own list type and we can also match on : because it is a constructor for the built-in list type. Same goes for []. Because pattern matching works (only) on constructors, we can match for stuff like that, normal prefix constructors or stuff like 8 or 'a', which are basically constructors for the numeric and character types, respectively.\n\nNow, we're going to implement a binary search tree. If you're not familiar with binary search trees from languages like C, here's what they are: an element points to two elements, one on its left and one on its right. The element to the left is smaller, the element to the right is bigger. Each of those elements can also point to two elements (or one, or none). In effect, each element has up to two sub-trees. And a cool thing about binary search trees is that we know that all the elements at the left sub-tree of, say, 5 are going to be smaller than 5. Elements in its right sub-tree are going to be bigger. So if we need to find if 8 is in our tree, we'd start at 5 and then because 8 is greater than 5, we'd go right. We're now at 7 and because 8 is greater than 7, we go right again. And we've found our element in three hops! Now if this were a normal list (or a tree, but really unbalanced), it would take us seven hops instead of three to see if 8 is in there.\n\nSets and maps from Data.Set and Data.Map are implemented using trees, only instead of normal binary search trees, they use balanced binary search trees, which are always balanced. But right now, we'll just be implementing normal binary search trees.\n\nHere's what we're going to say: a tree is either an empty tree or it's an element that contains some value and two trees. Sounds like a perfect fit for an algebraic data type!\n\nOkay, good, this is good. Instead of manually building a tree, we're going to make a function that takes a tree and an element and inserts an element. We do this by comparing the value we want to insert to the root node and then if it's smaller, we go left, if it's larger, we go right. We do the same for every subsequent node until we reach an empty tree. Once we've reached an empty tree, we just insert a node with that value instead of the empty tree.\n\nIn languages like C, we'd do this by modifying the pointers and values inside the tree. In Haskell, we can't really modify our tree, so we have to make a new sub-tree each time we decide to go left or right and in the end the insertion function returns a completely new tree, because Haskell doesn't really have a concept of pointer, just values. Hence, the type for our insertion function is going to be something like a -> Tree a - > Tree a. It takes an element and a tree and returns a new tree that has that element inside. This might seem like it's inefficient but laziness takes care of that problem.\n\nSo, here are two functions. One is a utility function for making a singleton tree (a tree with just one node) and a function to insert an element into a tree.\n\nThe singleton function is just a shortcut for making a node that has something and then two empty sub-trees. In the insertion function, we first have the edge condition as a pattern. If we've reached an empty sub-tree, that means we're where we want and instead of the empty tree, we put a singleton tree with our element. If we're not inserting into an empty tree, then we have to check some things. First off, if the element we're inserting is equal to the root element, just return a tree that's the same. If it's smaller, return a tree that has the same root value, the same right sub-tree but instead of its left sub-tree, put a tree that has our value inserted into it. Same (but the other way around) goes if our value is bigger than the root element.\n\nNext up, we're going to make a function that checks if some element is in the tree. First, let's define the edge condition. If we're looking for an element in an empty tree, then it's certainly not there. Okay. Notice how this is the same as the edge condition when searching for elements in lists. If we're looking for an element in an empty list, it's not there. Anyway, if we're not looking for an element in an empty tree, then we check some things. If the element in the root node is what we're looking for, great! If it's not, what then? Well, we can take advantage of knowing that all the left elements are smaller than the root node. So if the element we're looking for is smaller than the root node, check to see if it's in the left sub-tree. If it's bigger, check to see if it's in the right sub-tree.\n\nAll we had to do was write up the previous paragraph in code. Let's have some fun with our trees! Instead of manually building one (although we could), we'll use a fold to build up a tree from a list. Remember, pretty much everything that traverses a list one by one and then returns some sort of value can be implemented with a fold! We're going to start with the empty tree and then approach a list from the right and just insert element after element into our accumulator tree.\n\nIn that foldr, treeInsert was the folding function (it takes a tree and a list element and produces a new tree) and EmptyTree was the starting accumulator. nums, of course, was the list we were folding over.\n\nWhen we print our tree to the console, it's not very readable, but if we try, we can make out its structure. We see that the root node is 5 and then it has two sub-trees, one of which has the root node of 3 and the other a 7, etc.\n\nSo as you can see, algebraic data structures are a really cool and powerful concept in Haskell. We can use them to make anything from boolean values and weekday enumerations to binary search trees and more!\n\nSo far, we've learned about some of the standard Haskell typeclasses and we've seen which types are in them. We've also learned how to automatically make our own types instances of the standard typeclasses by asking Haskell to derive the instances for us. In this section, we're going to learn how to make our own typeclasses and how to make types instances of them by hand.\n\nA quick recap on typeclasses: typeclasses are like interfaces. A typeclass defines some behavior (like comparing for equality, comparing for ordering, enumeration) and then types that can behave in that way are made instances of that typeclass. The behavior of typeclasses is achieved by defining functions or just type declarations that we then implement. So when we say that a type is an instance of a typeclass, we mean that we can use the functions that the typeclass defines with that type.\n\nTypeclasses have pretty much nothing to do with classes in languages like Java or Python. This confuses many people, so I want you to forget everything you know about classes in imperative languages right now.\n\nFor example, the Eq typeclass is for stuff that can be equated. It defines the functions == and /=. If we have a type (say, Car) and comparing two cars with the equality function == makes sense, then it makes sense for Car to be an instance of Eq.\n\nThis is how the Eq class is defined in the standard prelude:\n\nWoah, woah, woah! Some new strange syntax and keywords there! Don't worry, this will all be clear in a second. First off, when we write class Eq a where, this means that we're defining a new typeclass and that's called Eq. The a is the type variable and it means that a will play the role of the type that we will soon be making an instance of Eq. It doesn't have to be called a, it doesn't even have to be one letter, it just has to be a lowercase word. Then, we define several functions. It's not mandatory to implement the function bodies themselves, we just have to specify the type declarations for the functions.\n\nSome people might understand this better if we wrote and then specified the type declarations like .\n\nAnyway, we did implement the function bodies for the functions that Eq defines, only we defined them in terms of mutual recursion. We said that two instances of Eq are equal if they are not different and they are different if they are not equal. We didn't have to do this, really, but we did and we'll see how this helps us soon.\n\nIf we have say and then define a type declaration within that class like , then when we examine the type of that function later on, it will have the type of .\n\nSo once we have a class, what can we do with it? Well, not much, really. But once we start making types instances of that class, we start getting some nice functionality. So check out this type:\n\nIt defines the states of a traffic light. Notice how we didn't derive any class instances for it. That's because we're going to write up some instances by hand, even though we could derive them for types like Eq and Show. Here's how we make it an instance of Eq.\n\nWe did it by using the instance keyword. So class is for defining new typeclasses and instance is for making our types instances of typeclasses. When we were defining Eq, we wrote class Eq a where and we said that a plays the role of whichever type will be made an instance later on. We can see that clearly here, because when we're making an instance, we write instance Eq TrafficLight where. We replace the a with the actual type.\n\nBecause == was defined in terms of /= and vice versa in the class declaration, we only had to overwrite one of them in the instance declaration. That's called the minimal complete definition for the typeclass — the minimum of functions that we have to implement so that our type can behave like the class advertises. To fulfill the minimal complete definition for Eq, we have to overwrite either one of == or /=. If Eq was defined simply like this:\n\nwe'd have to implement both of these functions when making a type an instance of it, because Haskell wouldn't know how these two functions are related. The minimal complete definition would then be: both == and /=.\n\nYou can see that we implemented == simply by doing pattern matching. Since there are many more cases where two lights aren't equal, we specified the ones that are equal and then just did a catch-all pattern saying that if it's none of the previous combinations, then two lights aren't equal.\n\nLet's make this an instance of Show by hand, too. To satisfy the minimal complete definition for Show, we just have to implement its show function, which takes a value and turns it into a string.\n\nOnce again, we used pattern matching to achieve our goals. Let's see how it works in action:\n\nNice. We could have just derived Eq and it would have had the same effect (but we didn't for educational purposes). However, deriving Show would have just directly translated the value constructors to strings. But if we want lights to appear like \"Red light\", then we have to make the instance declaration by hand.\n\nYou can also make typeclasses that are subclasses of other typeclasses. The class declaration for Num is a bit long, but here's the first part:\n\nAs we mentioned previously, there are a lot of places where we can cram in class constraints. So this is just like writing class Num a where, only we state that our type a must be an instance of Eq. We're essentially saying that we have to make a type an instance of Eq before we can make it an instance of Num. Before some type can be considered a number, it makes sense that we can determine whether values of that type can be equated or not. That's all there is to subclassing really, it's just a class constraint on a class declaration! When defining function bodies in the class declaration or when defining them in instance declarations, we can assume that a is a part of Eq and so we can use == on values of that type.\n\nBut how are the Maybe or list types made as instances of typeclasses? What makes Maybe different from, say, TrafficLight is that Maybe in itself isn't a concrete type, it's a type constructor that takes one type parameter (like Char or something) to produce a concrete type (like Maybe Char). Let's take a look at the Eq typeclass again:\n\nFrom the type declarations, we see that the a is used as a concrete type because all the types in functions have to be concrete (remember, you can't have a function of the type a -> Maybe but you can have a function of a -> Maybe a or Maybe Int -> Maybe String). That's why we can't do something like\n\nBecause like we've seen, the a has to be a concrete type but Maybe isn't a concrete type. It's a type constructor that takes one parameter and then produces a concrete type. It would also be tedious to write instance Eq (Maybe Int) where, instance Eq (Maybe Char) where, etc. for every type ever. So we could write it out like so:\n\nThis is like saying that we want to make all types of the form Maybe something an instance of Eq. We actually could have written (Maybe something), but we usually opt for single letters to be true to the Haskell style. The (Maybe m) here plays the role of the a from class Eq a where. While Maybe isn't a concrete type, Maybe m is. By specifying a type parameter (m, which is in lowercase), we said that we want all types that are in the form of Maybe m, where m is any type, to be an instance of Eq.\n\nThere's one problem with this though. Can you spot it? We use == on the contents of the Maybe but we have no assurance that what the Maybe contains can be used with Eq! That's why we have to modify our instance declaration like this:\n\nWe had to add a class constraint! With this instance declaration, we say this: we want all types of the form Maybe m to be part of the Eq typeclass, but only those types where the m (so what's contained inside the Maybe) is also a part of Eq. This is actually how Haskell would derive the instance too.\n\nMost of the times, class constraints in class declarations are used for making a typeclass a subclass of another typeclass and class constraints in instance declarations are used to express requirements about the contents of some type. For instance, here we required the contents of the Maybe to also be part of the Eq typeclass.\n\nWhen making instances, if you see that a type is used as a concrete type in the type declarations (like the a in a -> a -> Bool), you have to supply type parameters and add parentheses so that you end up with a concrete type.\n\nTake into account that the type you're trying to make an instance of will replace the parameter in the class declaration. The from will be replaced with a real type when you make an instance, so try mentally putting your type into the function type declarations as well. doesn't make much sense but does. But this is just something to think about, because will always have a type of , no matter what instances we make.\n\nOoh, one more thing, check this out! If you want to see what the instances of a typeclass are, just do :info YourTypeClass in GHCI. So typing :info Num will show which functions the typeclass defines and it will give you a list of the types in the typeclass. :info works for types and type constructors too. If you do :info Maybe, it will show you all the typeclasses that Maybe is an instance of. Also :info can show you the type declaration of a function. I think that's pretty cool.\n\nIn JavaScript and some other weakly typed languages, you can put almost anything inside an if expression. For example, you can do all of the following: if (0) alert(\"YEAH!\") else alert(\"NO!\"), if (\"\") alert (\"YEAH!\") else alert(\"NO!\"), if (false) alert(\"YEAH\") else alert(\"NO!), etc. and all of these will throw an alert of NO!. If you do if (\"WHAT\") alert (\"YEAH\") else alert(\"NO!\"), it will alert a \"YEAH!\" because JavaScript considers non-empty strings to be a sort of true-ish value.\n\nEven though strictly using Bool for boolean semantics works better in Haskell, let's try and implement that JavaScript-ish behavior anyway. For fun! Let's start out with a class declaration.\n\nPretty simple. The YesNo typeclass defines one function. That function takes one value of a type that can be considered to hold some concept of true-ness and tells us for sure if it's true or not. Notice that from the way we use the a in the function, a has to be a concrete type.\n\nNext up, let's define some instances. For numbers, we'll assume that (like in JavaScript) any number that isn't 0 is true-ish and 0 is false-ish.\n\nEmpty lists (and by extensions, strings) are a no-ish value, while non-empty lists are a yes-ish value.\n\nNotice how we just put in a type parameter a in there to make the list a concrete type, even though we don't make any assumptions about the type that's contained in the list. What else, hmm ... I know, Bool itself also holds true-ness and false-ness and it's pretty obvious which is which.\n\nHuh? What's id? It's just a standard library function that takes a parameter and returns the same thing, which is what we would be writing here anyway.\n\nLet's make Maybe a an instance too.\n\nWe didn't need a class constraint because we made no assumptions about the contents of the Maybe. We just said that it's true-ish if it's a Just value and false-ish if it's a Nothing. We still had to write out (Maybe a) instead of just Maybe because if you think about it, a Maybe -> Bool function can't exist (because Maybe isn't a concrete type), whereas a Maybe a -> Bool is fine and dandy. Still, this is really cool because now, any type of the form Maybe something is part of YesNo and it doesn't matter what that something is.\n\nPreviously, we defined a Tree a type, that represented a binary search tree. We can say an empty tree is false-ish and anything that's not an empty tree is true-ish.\n\nCan a traffic light be a yes or no value? Sure. If it's red, you stop. If it's green, you go. If it's yellow? Eh, I usually run the yellows because I live for adrenaline.\n\nCool, now that we have some instances, let's go play!\n\nRight, it works! Let's make a function that mimics the if statement, but it works with YesNo values.\n\nPretty straightforward. It takes a yes-no-ish value and two things. If the yes-no-ish value is more of a yes, it returns the first of the two things, otherwise it returns the second of them.\n\nSo far, we've encountered a lot of the typeclasses in the standard library. We've played with Ord, which is for stuff that can be ordered. We've palled around with Eq, which is for things that can be equated. We've seen Show, which presents an interface for types whose values can be displayed as strings. Our good friend Read is there whenever we need to convert a string to a value of some type. And now, we're going to take a look at the Functor typeclass, which is basically for things that can be mapped over. You're probably thinking about lists now, since mapping over lists is such a dominant idiom in Haskell. And you're right, the list type is part of the Functor typeclass.\n\nWhat better way to get to know the Functor typeclass than to see how it's implemented? Let's take a peek.\n\nAlright. We see that it defines one function, fmap, and doesn't provide any default implementation for it. The type of fmap is interesting. In the definitions of typeclasses so far, the type variable that played the role of the type in the typeclass was a concrete type, like the a in (==) :: (Eq a) => a -> a -> Bool. But now, the f is not a concrete type (a type that a value can hold, like Int, Bool or Maybe String), but a type constructor that takes one type parameter. A quick refresher example: Maybe Int is a concrete type, but Maybe is a type constructor that takes one type as the parameter. Anyway, we see that fmap takes a function from one type to another and a functor applied with one type and returns a functor applied with another type.\n\nIf this sounds a bit confusing, don't worry. All will be revealed soon when we check out a few examples. Hmm, this type declaration for fmap reminds me of something. If you don't know what the type signature of map is, it's: map :: (a -> b) -> [a] -> [b].\n\nAh, interesting! It takes a function from one type to another and a list of one type and returns a list of another type. My friends, I think we have ourselves a functor! In fact, map is just a fmap that works only on lists. Here's how the list is an instance of the Functor typeclass.\n\nThat's it! Notice how we didn't write instance Functor [a] where, because from fmap :: (a -> b) -> f a -> f b, we see that the f has to be a type constructor that takes one type. [a] is already a concrete type (of a list with any type inside it), while [] is a type constructor that takes one type and can produce types such as [Int], [String] or even [[String]].\n\nSince for lists, fmap is just map, we get the same results when using them on lists.\n\nWhat happens when we map or fmap over an empty list? Well, of course, we get an empty list. It just turns an empty list of type [a] into an empty list of type [b].\n\nTypes that can act like a box can be functors. You can think of a list as a box that has an infinite amount of little compartments and they can all be empty, one can be full and the others empty or a number of them can be full. So, what else has the properties of being like a box? For one, the Maybe a type. In a way, it's like a box that can either hold nothing, in which case it has the value of Nothing, or it can hold one item, like \"HAHA\", in which case it has a value of Just \"HAHA\". Here's how Maybe is a functor.\n\nAgain, notice how we wrote instance Functor Maybe where instead of instance Functor (Maybe m) where, like we did when we were dealing with Maybe and YesNo. Functor wants a type constructor that takes one type and not a concrete type. If you mentally replace the fs with Maybes, fmap acts like a (a -> b) -> Maybe a -> Maybe b for this particular type, which looks OK. But if you replace f with (Maybe m), then it would seem to act like a (a -> b) -> Maybe m a -> Maybe m b, which doesn't make any damn sense because Maybe takes just one type parameter.\n\nAnyway, the fmap implementation is pretty simple. If it's an empty value of Nothing, then just return a Nothing. If we map over an empty box, we get an empty box. It makes sense. Just like if we map over an empty list, we get back an empty list. If it's not an empty value, but rather a single value packed up in a Just, then we apply the function on the contents of the Just.\n\nAnother thing that can be mapped over and made an instance of Functor is our Tree a type. It can be thought of as a box in a way (holds several or no values) and the Tree type constructor takes exactly one type parameter. If you look at fmap as if it were a function made only for Tree, its type signature would look like (a -> b) -> Tree a -> Tree b. We're going to use recursion on this one. Mapping over an empty tree will produce an empty tree. Mapping over a non-empty tree will be a tree consisting of our function applied to the root value and its left and right sub-trees will be the previous sub-trees, only our function will be mapped over them.\n\nNice! Now how about Either a b? Can this be made a functor? The Functor typeclass wants a type constructor that takes only one type parameter but Either takes two. Hmmm! I know, we'll partially apply Either by feeding it only one parameter so that it has one free parameter. Here's how Either a is a functor in the standard libraries:\n\nWell well, what did we do here? You can see how we made Either a an instance instead of just Either. That's because Either a is a type constructor that takes one parameter, whereas Either takes two. If fmap was specifically for Either a, the type signature would then be (b -> c) -> Either a b -> Either a c because that's the same as (b -> c) -> (Either a) b -> (Either a) c. In the implementation, we mapped in the case of a Right value constructor, but we didn't in the case of a Left. Why is that? Well, if we look back at how the Either a b type is defined, it's kind of like:\n\nWell, if we wanted to map one function over both of them, a and b would have to be the same type. I mean, if we tried to map a function that takes a string and returns a string and the b was a string but the a was a number, that wouldn't really work out. Also, from seeing what fmap's type would be if it operated only on Either values, we see that the first parameter has to remain the same while the second one can change and the first parameter is actualized by the Left value constructor.\n\nThis also goes nicely with our box analogy if we think of the Left part as sort of an empty box with an error message written on the side telling us why it's empty.\n\nMaps from Data.Map can also be made a functor because they hold values (or not!). In the case of Map k v, fmap will map a function v -> v' over a map of type Map k v and return a map of type Map k v'.\n\nNote, the has no special meaning in types just like it doesn't have special meaning when naming values. It's used to denote things that are similar, only slightly changed.\n\nTry figuring out how Map k is made an instance of Functor by yourself!\n\nWith the Functor typeclass, we've seen how typeclasses can represent pretty cool higher-order concepts. We've also had some more practice with partially applying types and making instances. In one of the next chapters, we'll also take a look at some laws that apply for functors.\n\nJust one more thing! Functors should obey some laws so that they may have some properties that we can depend on and not think about too much. If we use over the list , we expect the result to be and not its reverse, . If we use (the identity function, which just returns its parameter) over some list, we expect to get back the same list as a result. For example, if we gave the wrong functor instance to our type, using over a tree where the left sub-tree of a node only has elements that are smaller than the node and the right sub-tree only has nodes that are larger than the node might produce a tree where that's not the case. We'll go over the functor laws in more detail in one of the next chapters.\n\nType constructors take other types as parameters to eventually produce concrete types. That kind of reminds me of functions, which take values as parameters to produce values. We've seen that type constructors can be partially applied (Either String is a type that takes one type and produces a concrete type, like Either String Int), just like functions can. This is all very interesting indeed. In this section, we'll take a look at formally defining how types are applied to type constructors, just like we took a look at formally defining how values are applied to functions by using type declarations. You don't really have to read this section to continue on your magical Haskell quest and if you don't understand it, don't worry about it. However, getting this will give you a very thorough understanding of the type system.\n\nSo, values like 3, \"YEAH\" or takeWhile (functions are also values, because we can pass them around and such) each have their own type. Types are little labels that values carry so that we can reason about the values. But types have their own little labels, called kinds. A kind is more or less the type of a type. This may sound a bit weird and confusing, but it's actually a really cool concept.\n\nWhat are kinds and what are they good for? Well, let's examine the kind of a type by using the :k command in GHCI.\n\nA star? How quaint. What does that mean? A * means that the type is a concrete type. A concrete type is a type that doesn't take any type parameters and values can only have types that are concrete types. If I had to read * out loud (I haven't had to do that so far), I'd say star or just type.\n\nOkay, now let's see what the kind of Maybe is.\n\nThe Maybe type constructor takes one concrete type (like Int) and then returns a concrete type like Maybe Int. And that's what this kind tells us. Just like Int -> Int means that a function takes an Int and returns an Int, * -> * means that the type constructor takes one concrete type and returns a concrete type. Let's apply the type parameter to Maybe and see what the kind of that type is.\n\nJust like I expected! We applied the type parameter to Maybe and got back a concrete type (that's what * -> * means. A parallel (although not equivalent, types and kinds are two different things) to this is if we do :t isUpper and :t isUpper 'A'. isUpper has a type of Char -> Bool and isUpper 'A' has a type of Bool, because its value is basically True. Both those types, however, have a kind of *.\n\nWe used :k on a type to get its kind, just like we can use :t on a value to get its type. Like we said, types are the labels of values and kinds are the labels of types and there are parallels between the two.\n\nLet's look at another kind.\n\nAha, this tells us that Either takes two concrete types as type parameters to produce a concrete type. It also looks kind of like a type declaration of a function that takes two values and returns something. Type constructors are curried (just like functions), so we can partially apply them.\n\nWhen we wanted to make Either a part of the Functor typeclass, we had to partially apply it because Functor wants types that take only one parameter while Either takes two. In other words, Functor wants types of kind * -> * and so we had to partially apply Either to get a type of kind * -> * instead of its original kind * -> * -> *. If we look at the definition of Functor again\n\nwe see that the f type variable is used as a type that takes one concrete type to produce a concrete type. We know it has to produce a concrete type because it's used as the type of a value in a function. And from that, we can deduce that types that want to be friends with Functor have to be of kind * -> *.\n\nNow, let's do some type-foo. Take a look at this typeclass that I'm just going to make up right now:\n\nMan, that looks weird. How would we make a type that could be an instance of that strange typeclass? Well, let's look at what its kind would have to be. Because j a is used as the type of a value that the tofu function takes as its parameter, j a has to have a kind of *. We assume * for a and so we can infer that j has to have a kind of * -> *. We see that t has to produce a concrete value too and that it takes two types. And knowing that a has a kind of * and j has a kind of * -> *, we infer that t has to have a kind of * -> (* -> *) -> *. So it takes a concrete type (a), a type constructor that takes one concrete type (j) and produces a concrete type. Wow.\n\nOK, so let's make a type with a kind of * -> (* -> *) -> *. Here's one way of going about it.\n\nHow do we know this type has a kind of * -> (* -> *) - > *? Well, fields in ADTs are made to hold values, so they must be of kind *, obviously. We assume * for a, which means that b takes one type parameter and so its kind is * -> *. Now we know the kinds of both a and b and because they're parameters for Frank, we see that Frank has a kind of * -> (* -> *) -> * The first * represents a and the (* -> *) represents b. Let's make some Frank values and check out their types.\n\nHmm. Because frankField has a type of form a b, its values must have types that are of a similar form as well. So they can be Just \"HAHA\", which has a type of Maybe [Char] or it can have a value of ['Y','E','S'], which has a type of [Char] (if we used our own list type for this, it would have a type of List Char). And we see that the types of the Frank values correspond with the kind for Frank. [Char] has a kind of * and Maybe has a kind of * -> *. Because in order to have a value, it has to be a concrete type and thus has to be fully applied, every value of Frank blah blaah has a kind of *.\n\nMaking Frank an instance of Tofu is pretty simple. We see that tofu takes a j a (so an example type of that form would be Maybe Int) and returns a t a j. So if we replace Frank with j, the result type would be Frank Int Maybe.\n\nNot very useful, but we did flex our type muscles. Let's do some more type-foo. We have this data type:\n\nAnd now we want to make it an instance of Functor. Functor wants types of kind * -> * but Barry doesn't look like it has that kind. What is the kind of Barry? Well, we see it takes three type parameters, so it's going to be something -> something -> something -> *. It's safe to say that p is a concrete type and thus has a kind of *. For k, we assume * and so by extension, t has a kind of * -> *. Now let's just replace those kinds with the somethings that we used as placeholders and we see it has a kind of (* -> *) -> * -> * -> *. Let's check that with GHCI.\n\nAh, we were right. How satisfying. Now, to make this type a part of Functor we have to partially apply the first two type parameters so that we're left with * -> *. That means that the start of the instance declaration will be: instance Functor (Barry a b) where. If we look at fmap as if it was made specifically for Barry, it would have a type of fmap :: (a -> b) -> Barry c d a -> Barry c d b, because we just replace the Functor's f with Barry c d. The third type parameter from Barry will have to change and we see that it's conviniently in its own field.\n\nThere we go! We just mapped the f over the first field.\n\nIn this section, we took a good look at how type parameters work and kind of formalized them with kinds, just like we formalized function parameters with type declarations. We saw that there are interesting parallels between functions and type constructors. They are, however, two completely different things. When working on real Haskell, you usually won't have to mess with kinds and do kind inference by hand like we did now. Usually, you just have to partially apply your own type to * -> * or * when making it an instance of one of the standard typeclasses, but it's good to know how and why that actually works. It's also interesting to see that types have little types of their own. Again, you don't really have to understand everything we did here to read on, but if you understand how kinds work, chances are that you have a very solid grasp of Haskell's type system."
    },
    {
        "link": "https://serokell.io/blog/algebraic-data-types-in-haskell",
        "document": "Most programming languages have a way to make compound data types. In Haskell, we can do that via algebraic data types. Even though the name might sound scary at first, it’s simply a way to construct types.\n\nThis article will introduce you to the concept of algebraic data types and show you how to use them.\n• how to create your own custom Haskell data types;\n• what product and sum types are;\n• how to use common Haskell ADTs such as and ;\n\nIf you want to watch this article as a 10-minute video, you can do that on our YouTube channel.\n\nNew data types are created via the keyword. To create a data type, we need to provide a type constructor (the name of our type) and a data constructor (used to construct new instances of the type), followed by the types our type will contain.\n\nA few notes on this piece of code.\n\nFirst of all, there’s a difference between the type constructor and the data constructor. In our example, they are called the same, but they could have been and , for example. This frequently confuses beginners.\n\nSecond, adding to the type definition above makes it possible to print values of the type and to compare them for equality. You can read more about deriving in this blog post.\n\nLet’s play with our type in GHCi.\n\nWe can create new values of this type via the data constructor.\n\nAnd we can create functions that pattern match on constructors and values inside them.\n\nWe call (and all types with a similar structure) a product type. All product types combine multiple elements that are in the data structure at the same time. It’s the same as saying that you need this type and that type.\n\nOur previously created data type can contain only double-precision floats.\n\nIn some cases, we would want it to work with other numbers as well. If so, we need to make it polymorphic (able to work with multiple different data types).\n\nHere, we provide the type constructor with a type variable , which we can later use in the definition of our type. In contrast to our previous type, is a type that needs to be “completed” by providing it with a concrete type.\n\nTo better illustrate this fact, we can look at the kinds of both functions. While it is not possible to fully explain kinds in this article, you can think of them as type signatures for types.\n\nIf you wish to read more about kinds, I suggest this article by Diogo Castro.\n\nAs we can see, is a concrete type.\n\nIn contrast, is a function that takes a type and returns a concrete type.\n\nAnother typical example of a polymorphic product type is the tuple type.\n\nIt takes two types – and – and returns a type that has in the first slot and in the second slot.\n\nThe individual types of our type are not named. While it doesn’t really add any difficulty right now, working with something like can be confusing.\n\nAn alternative is to use records, which have field labels.\n\nRecords also provide us with getter functions for free. The names of those getters are the same as the field names.\n\nYou can update a record by providing the fields you want to update (rest will stay the same).\n\nAnd you can put these two things together to create functional record updates.\n\nOf course, you can also work with records via pattern matching as with basic product types.\n\nThere’s another flavor of types – sum types – that lists several possible variants a type could have. You might have encountered something similar under the name of enums or union types.\n\nThe simplest example of a sum type is .\n\ncan be constructed by either or .\n\nWe can make functions such as a negation that work on the values of .\n\nThere are a lot of sum types in the wild that you wouldn’t even necessarily recognize as such. While it is not defined that way, an can be thought of as the enumeration of all the entries in , for example.\n\nA more nontrivial example of a sum type would be a data type that fits both a 2-dimensional and a 3-dimensional point.\n\nNow we can write a function that accepts both types of points by pattern matching on the data constructors.\n\nHere’s an example of its usage:\n\nLike product types, sum types are a way of putting together basic types to create a more complex one. But in comparison to product types, only one of those types can be present in any given instance of the type.\n\nIn other words, using a sum type is like saying that you need type a or type b: “I need True or False”, “I need a 2D point or a 3D point”, etc.\n\nHere’s a small table to help you remember the differences between these two groups of types.\n\nSo why are these types called product and sum types? Let’s get into it.\n\nIf you remember your school math lessons, you worked with numbers ( 1, 2, 3, etc.), variables ( x, y, z, etc.), and operators ( +, −, ∗, etc.). In algebraic data types, our numbers are the number of possible values a type can have and our operators are and data constructors.\n\nIf we use in the definition of a type, the type can have a value from the values of types on either side of the operator. As such, the amount of possible values it has is the sum of the amount of values those types have.\n\nFor example, contains only one value. also contains only one value. contains 1+1 values. If we add an value to , we will have a type with three possible values, and so on.\n\nIf we use a data constructor, our type can have all the possible combinations of the sets of values we provide. As such, the amount of possible values it has is the product of the amount of values those types have.\n\nFor example, if our type consists of two booleans, such as whether a person checked in for both parts of a return flight, it will have 2∗2=4 possible values.\n\nBy putting together sum and product types, we can construct elaborate types out of simple building blocks.\n\nAnd this is what algebraic data types work with. They are a collection of one or more data constructors, composed with the operator. In other words, they are a sum of products.\n\nNow, let’s look at two commonly used ADTs in Haskell: and .\n\nFirst ADT we’ll cover is , which you might have encountered in other languages as .\n\nSometimes, a function might not be able to return a value for a certain input. In that case, we can use the type. It has two possible data constructors: or . If the function succeeds, we wrap the result in . Otherwise, we return , which symbolizes something similar to null.\n\nFor example, has a scary function called , which works on lists but not all of them.\n\nIn case we call it with an empty list, we’ll get an exception:\n\nWe can make it give a result for each input by pattern matching on the contents of the list and returning in the case of an empty list.\n\nAll in all, you can think of as a safer alternative to null.\n\nNow, what if you want to know what made the function fail?\n\nIn that case, there is another data type that we can use – . It functions similarly to what is called in other languages.\n\nIn contrast to , it can store something on the left side, such as an error message.\n\nAll in all, you can think of as a safer alternative to exceptions.\n\nTo blow your mind a little bit in the end: functions can also add to our “type algebra” since they also have types.\n\nImagine we have a data type for traffic lights.\n\nHow many possible values are in the type ? (One can imagine that they encode all possible rules for when is it legal to cross the street.)\n\nLet’s try to write them all out.\n• True if it is Green, False if it is Yellow or Red.\n• True if it is Green or Yellow, False if it is Red.\n• True if it is Green, Yellow, or Red.\n• True if it is Yellow or Red, False if it is Green.\n• True if it is Red, False if it is Green or Yellow.\n• False if it is Green, Yellow, or Red.\n• True if it is Green or Red, False if it is Yellow.\n• True if it is Yellow, False if it is Green or Red.\n\nThe final number is 8, or 23.\n\nTurns out, if we have two types a and b with the amount of values inside those types being ∣a∣ and ∣b∣, respectively, then there are ∣b∣∣a∣ functions in the set of possible functions from a to b.\n\nIn this article, we explored common ways of defining your own data types in Haskell. We looked at product types and sum types and how they work together to create algebraic data types. We also looked at common data types such as and and saw how functions are exponential data types.\n\nHaskell’s type system is large and enables you to be very expressive, so there are a lot of things that we didn’t cover in our blog post, such as newtypes.\n\nIf you want to read more of our Haskell articles, follow us on Twitter or Dev.\n\nIn case you want some practice with algebraic data types, here are a couple of quick exercises.\n• Create a data type called that stores a person’s full name, address, and phone number. Create a function for getting a person’s name and a function for changing their phone number.\n• Convert the data type created in exercise 1 to a record.\n• Given a data type for days of the week: , write two functions:\n• , which takes a day of the week and returns if it’s Wednesday and otherwise.\n• , which takes a day of the week and returns the day of the week that comes after it.\n• Recall the data type we covered earlier. Write a ‘tail’ function for a list with the type signature of . It should take a list and return the list without the first element, wrapped in . In case that is not possible, it should return . \n\n\n\n Some examples of its behavior: * Nothing * Just [] * Just [ , , , ]\n\nHere’s a handy table of some of the types we have covered in this article and how to compute the cardinality (how many members the type has) of those types, assuming that the cardinalities of their components are known.\n\nNote: ∣a∣ notes the cardinality of the type a in the table.\n\nVisit our Haskell programming page to discover Serokell’s services in this language."
    },
    {
        "link": "https://stackoverflow.com/questions/8507724/example-of-function-definition-in-the-data-constructor-of-a-new-type",
        "document": "We can use type synonym for function definitions, e.g.\n\nThis avoids us writing long function definition every time.\n\nwhich is more readable and less code as well.\n\nSimple algebraic data types are straight forward and easy to do pattern matching etc, e.g.\n\nAs I look more into Haskell data types, I found we can have function definition in data constructor when defining new type.\n\nThis puzzles me a bit and haven't seen many examples of this around. In a way, the idea of high-order function where a function can take another function as argument is similar to this situation, except here it applies to data type. The Haskell wiki does not say much about \"high-order data type definition\". I realise I may be getting all these terms wrong, so please correct me, and point me to more reading. I really want to see a concrete usage of this. Thanks!"
    },
    {
        "link": "https://cis.upenn.edu/~cis1940/fall16/lectures/10-testing.html",
        "document": "Let’s say I want to merge two sorted lists.\n\nDoes this function work as expected? I could run a few tries in GHCi, but that’s a little unsatisfactory: I have to do the work to think up a test, but I get to use it only once. Instead, it’s much better to write the test in my file, and that way I can re-run it every time I update my merge function.\n\nThe technique described above is often referred to as unit testing and is used exensively in the real world. But is unit testing even that great? Sure you can re-run all your tests whenever you want, but that doesn’t get around the issue that you actually have to write all of the tests in the first place. Coming up with specific test cases is often tedious, repetitive, and arbitrary.\n\nCan we do better?\n\nWriting test cases is boring. And, it’s easy to miss out on unexpected behavior. Much better (and, more along the lines of wholemeal programming) is to define properties we wish our function to have. Then, we can get the computer to generate the test cases for us.\n\nQuickCheck is the standard Haskell library for property-based testing. The idea is that you define a so-called property, which is then tested using pseudo-random data.\n\nThis property is saying that the sum of the lengths of the input lists should be the same as the length of the output list. (It is customary to begin property names with .) Let’s try it!\n\nThe first thing we notice is that our function is clearly wrong, with lots of stars and even an exclamation point! We then see that QuickCheck got through 5 tests before discovering the failing test case, so our function isn’t terrible. QuickCheck tells us what the failing arguments are: and . Indeed GHCi tells us that is , which is wrong.\n\nWhat’s so nice here is that QuickCheck found us such a nice, small test case to show that our function is wrong. The way it can do so is that it uses a technique called shrinking. After QuickCheck finds a test case that causes failure, it tries successively smaller and smaller arguments (according to a customizable definition of “smaller”) that keep failing. QuickCheck then reports only the smallest failing test case. This is wonderful, because otherwise the test cases QuickCheck produces would be unwieldy and hard to reason about.\n\nA final note about this property is that the type signature tells us that the property takes lists of integers, not any type . This is so that GHC doesn’t choose a silly type to test on, such as . We must always be careful about this when writing properties of polymorphic functions. Numbers are almost always a good choice.\n\nLet us take another stab at our function:\n\nIs that it? Are we done? Not quite. Let’s try another property:\n\nDrat. QuickCheck quite reasonably tried the list as an input to our function. Of course, this isn’t going to work because it’s not already sorted. We need to specify an implication property:\n\nIn , we see the use of the operator . Its type is . It takes a and a thing and produces a . Note how returns a , not a . We’ll sort these types out fully later, but I wanted to draw your attention to the appearance of there.\n\nLet’s see how this works:\n\nThere aren’t any failures, but there aren’t a lot of successes either. We can see the problem if we use instead of : QuickCheck will run the test only when both randomly-generated lists are in sorted order. The odds that a randomly-generated list of length is sorted is , which is generally quite small. And we need two sorted lists. This isn’t going to work out well.\n\nHow does QuickCheck generate the arbitrary test cases, anyway? It uses the class:\n\nWe’ll leave to the online documentation and focus on . The method gives us a – a generator for the type . Of course, the method for lists doesn’t care about ordering (indeed, it can’t, due to parametricity), but we do. Luckily, this is a common problem, and QuickCheck offers a solution in the form of , a wrapper around lists that have the right instance for our needs:\n\nHuzzah! Just by changing the types a bit, we can affect instance selection to get what we want.\n\nYet, this all seems like black magic. How does QuickCheck do it? Let’s look more in depth at the types.\n\nWe can anything that’s . Boolean values are , as are the somewhat mysterious s. But it’s the last instance listed here of that piques our curiosity. It says that a function is as long as its argument has an method, the argument can be printed (in case of failure), and the result is .\n\nIs ? Sure it is. Recall that is equivalent to . Because has both an instance and a instance, we can use the last instance above as long as is . And that’s because we (still) have an and a instance for , and is . So, that’s how works – it uses the instances for the argument types. And, that’s how changing the argument types to got us the result we wanted.\n\nWhen you want to use QuickCheck over your own datatypes, it is necessary to write an instance for them. Here, we’ll learn how to do so.\n\nLet’s have a look at our own list type\n\nIf we want an instance, we must define the method, of type . Luckily for us, is a monad (did you see that coming?), so some of its details are already familiar. We also realize that if we want arbitrary lists of , we’ll need to make arbitrary s. So, our instance looks like\n\nAt this point, check out the combinators available in the “Generator combinators” section of the QuickCheck documentation.\n\nIt’s helpful to think about how you, as a human, would generate an arbitrary list. One way to do it is to choose an arbitrary length (say, between 0 and 10), and then choose each element arbitrarily. Here is an implementation:\n\nLet’s try it out:\n\nThe arbitrary lengths are working, but the element generation sure is boring. Let’s use a type annotation to spruce things up (and override GHC’s default choice of )!\n\nThis generation still isn’t great, though, because perhaps a function written over s fails only for lists longer than 10. We’d like unbounded lengths. Here’s one way to do it:\n\nThe lengths are unbounded, but we’re getting a lot of empty lists. This is because at every entry in the list, there’s a 50% chance of producing . That means that a list of length \\(n\\) will appear only one out of \\(2^n\\) times. So, lengths are unbounded, but very unlikely.\n\nThe way to make progress here is to use the combinator. QuickCheck is set up to try “simple” arbitrary things before “complex” arbitrary things. The way it does this is using a size parameter, internal to the monad. The more generating QuickCheck does, the higher this parameter gets. We want to use the size parameter to do our generation.\n\nLet’s look at the type of :\n\nAn example is the best way of explaining how this works:\n\nThat worked nicely – the lists tend to get longer the later they appear. The idea is that takes a continuation: the thing to do with the size parameter. We just use a lambda function as the one argument to , where the lambda binds the parameter, and then we can use it internally. If that’s too painful (say we just want to produce the size parameter, without using a continuation), you could always do something like this:\n\nI’ll leave it to you to figure out how that works. Follow the types!\n\nAs one last example, we can also choose arbitrary generators from a list based on frequency. Although the length method of works well for lists, the following technique is much better for trees:\n\nLet’s look at the type of :\n\nIt takes a list of pairs and produces a . The numbers in the list give the likelihood of choosing that element. Above, we fixed the frequency of at 1, but let the likelihood of vary according to the desired size. Then, in the recursive call to , we used to lower the parameter. Otherwise, it’s too likely to get a runaway list that goes on toward infinity.\n\nProperty based testing is an amazingly effective and satisfying approach to testing. It works especially well in Haskell because of the combination of purity, which means that one only needs to vary the arguments to a function, and the type system, which allows us to use type classes to very generically and composable create code that comes up with random input. QuickCheck came out in 1999 has since then inspired re-implementations in other languages as well.\n\nVery likely, your project has some code that can be tested this way, and you should do that. Here are some pointers to look at.\n• QuickCheck is random, which is nice. An alternative approach is to test all input, up to a given size. This way your test suite is deterministic, and at least no small corner cases remain. A library implementing that approach is SmallCheck.\n• Unit tests are still useful. The default library to go for is HUnit.\n• You do not want to run your tests in GHCi only. There are libraries that allow you to name and group your tests and create an executable that runs your tests and has nice shiny colored output. Check out tasty for one of those. It has support for QuickCheck, SmallCheck, HUnit and more."
    },
    {
        "link": "https://typeable.io/blog/2021-08-09-pbt",
        "document": "Showing how the real code can be effectively tested using QuickCheck\n\nProperty-based testing (PBT) is the approach to software testing that implies an automatic check of the function properties (predicates) specified by the tester. Checking, i.e. search for counter-examples is carried out using the automatically generated input data. PBT allows developers to increase the test coverage significantly and spend their time efficiently saving them the trouble of inventing the input data for tests on their own. Normally, the values generated during property-based testing is not limited by anything, which is why the check can be carried out using the values the developer may have forgotten or neglected to include in the unit tests (surely, you won’t brute force all the values of input parameters).\n\nThe PBT approach was popularized by the QuickCheck library written in Haskell, and in this post, we’ll show how to use this tool effectively.\n\nAs a rule, PBT libraries consist of two parts:\n• Runners, which are in charge of running the tests and checking the validity of the predicate.\n• Arbitraries that take care of pseudo-random data generation while enabling shrinking, i.e. the way to “simplify” the found counter-example.\n\nIn my opinion, the skill of PBT consists in the ability to create a fast and effective data generator that allows obtaining potentially “problematic” values. To that end, you need both the knowledge of the subject domain and the skill of using the tools provided by the QuickCheck library.\n\nIn this post, I’ll show how the real code can be tested using QuickCheck.\n\nThe type responsible for data generation is the wrapper around a function that accepts the pseudo-random generator and also an integer parameter setting restrictions on the generated data size.\n\nThe size constraint is needed for inductive types, e.g. for the tree depth (so that the tree wouldn’t be infinite).\n\nThe generator size can be changed using the functions and , and the current generator parameter can be obtained using the function:\n\nImplementation of the arbitrary values generation and shrinking for a specific type is an instance of the class that has two methods: , i.e. the value generator itself, and , which is the function used to get the list of “shrunken” values.\n\nProperties are set using the type . We won’t go into the details of its implementation because the library provides combinators to create various properties of the functions which allow, among other things, checking the truth or the falsehood of predicates.\n\nThe properties check is started by the function that goes by the same name, .\n\nIn addition to the above said, allows displaying information about the test data values distribution analysis.\n\nFurther, we’ll describe all these features of the library using a small example.\n\nBy way of example, let’s consider a naive parser and serializer for a JSON subset where there are no Boolean or Null types, and where spaces that are optional in JSON are prohibited.\n\nThe data type is declared in the following way:\n\nTo set the limit for the tree size, we should avoid creating new branches if the size parameter is equal to zero and enable the parameter reduction in recursive calls.\n\nIt should be noted that here we’re dividing the by 2 and don’t decrease by one. The instance for the list will produce a list of the length not exceeding the . In this way, we can create a logarithmic, not exponential, dependency of a medium-size tree on the . In practice, we don’t need a linear dependency, we only need to avoid the discrepancy occurring because each of the constructors or generates an infinite tree (this is because the exit from recursion is statistically rarer than the generation of new constructors). Here the constant “2” is selected randomly.\n\nAs we can see, the instance for the type generates “potentially problematic” lines to try and trigger typical errors in the applications using the data. The programmer should keep in mind special symbols, empty lines, whitespaces, etc.\n\nNow let’s implement the serializer and the parser for our data type.\n\nWe’ll carry out parsing using the standard approach implemented in the libraries of parser combinators – all parsing functions will be of the type , where is the type we want to obtain as the result, and the second component of the pair (of the type) is the line part that was not taken up by the parser.\n\nThe selected format is convenient because we can see from the first symbol what type we’re dealing with, which makes backtracking unnecessary.\n\nHere we won’t describe the code itself but will move on to testing.\n\nFinally, the will let us get the result only if the line has been successfully parsed using :\n\nLet’s formulate the property we’d like to test (parsing is the inverse function for serialization, i.e. the function applied to a serialized value produces the initial value).\n\nNow let’s run the check of this property:\n\nObviously, we’ve forgotten about the part of escape sequences used in the instance .\n\nFor the sake of simplicity, let’s give up our homebrewed implementation of the and reuse from the .\n\nIt is assumed that the opening quotation mark was taken up by the calling function, so it’s necessary to get it back:\n\nWe also find out that the numbers can be negative:\n\nWhich can be also easily accounted for in our parser:\n\nLet’s try and test our implementation of the JSON subset with regard to the existing one (the library ). We want to make sure that serialization returns a valid JSON:\n\nOf course, we’re working with the escape sequences incorrectly. The instance for the doesn’t process them in the same way as the decoder.\n\nSurely, we should have implemented the serialization correctly but since this post is devoted to QuickCheck, it would be more interesting to show how to make QuickCheck omit the values we are definitely not interested in.\n\nLet’s assume that we’ve decided on limiting the lines only to printed characters with the code range 32-126.\n\nTo do this, we can use the function that allows generating the values satisfying the specified predicate (in our case, this is the code range constraint):\n\nAfter running such a test, we’ll notice that the time of its operation has increased significantly because now we’re rejecting the lines containing even one symbol from the unspecified interval.\n\nThe following code lets us know that we use approximately 6% of generated examples. We use the function that prints out the percent of the test cases which were useful for us:\n\n6% is not much, that’s why this method of lines generation is not suitable. To make the tests fast, it’s necessary to try and generate the data meeting the desired invariants at once instead of using the function or similar functions.\n\nThe situation becomes somewhat better if you place the inside the (the in Haskell is the list of symbols ( )):\n\nHowever, generating a symbol from the specified interval is even quicker:\n\nUnfortunately, it’s not often easy to write a generator producing only the values meeting a specific predicate, especially if the predicate requires any constraints, which are interrelated in some way, for various parts of the structure.\n\nShrinking is a way to “reduce” the found example to the minimum possible. The function comes in after the counter-example has been found.\n\nmust return the finite (and probably empty) list of all possible “simplifications” of the value with the type . An empty list will mean that the minimal counter-example has already been found.\n\nYou can view the result of the operation by running . Suppose that we want to check a rather strange assertion that no lines contain exactly two symbols. Obviously, here the line is the minimum counter-example. After finding the first counter-example we see how is trying, again and again, to reduce the line to find this minimum counter-example:\n\nThis search algorithm was implemented in the function :\n\nThe is trying to:\n• Delete one half of the list, one-quarter of the list, one-eighth part and so on starting from the end and from the beginning\n• Apply to one of the list elements\n\nLet’s write for JSON (we’ll just reuse implementations for pair, list, line, and number):\n\nIn the example described above, we implemented the method manually mostly for illustrative purposes. However, in a real production code where dozens or hundreds of data types are declared this may become a tiring process. The [ ] library (https://hackage.haskell.org/package/generic-random) allows obtaining the instance of automatically.\n\nIts operation is based on the generic programming of data types (datatype-generic programming). To describe this approach briefly, we can represent the data types in a general way as a sum type (an alternative of several constructors, as in our example with ) or as a product type (a structure with several fields).\n\nIf it’s known how to obtain an arbitrary value for each of the alternatives in this sum type, we can use these values to get an arbitrary value of the sum type itself. Moreover, each constructor in the alternative can have a certain weight so that it would occur more often or less often than the rest. For a product type (more simply, a structure), if it’s known how to obtain an arbitrary value of each field, we can use them to create an arbitrary value of the structure as a whole.\n\nFor recursive types, we can indicate the value for the recursion base during generation when the structure size reaches zero. In our “manual” implementation of the instance for the type, it was the value .\n\nLet’s use to write a new definition of for :\n\nreduces the size of generated structure at each recursive call; sets a uniform distribution for the constructors in the alternative; indicates what generator should be called for a zero-size structure.\n\nThus, we’ve seen in this tutorial how the library is used for property-based testing and in particular, learned how to:\n• Describe the test data generators and adjust them to improve the efficiency and reduce the test execution time;\n• Describe simple properties of the functions and run tests to check them;\n• Analyze the examples of data used for testing;\n• Search for the minimum counter-example for which the tests fail;\n\nThank you for your attention!"
    },
    {
        "link": "https://cseweb.ucsd.edu/classes/wi14/cse230-a/lectures/lec-quickcheck.html",
        "document": "In this lecture, we will look at QuickCheck, a technique that cleverly exploits typeclasses and monads to deliver a powerful automatic testing methodology.\n\nQuickcheck was developed by Koen Claessen and John Hughes more than ten years ago, and has since been ported to other languages and is currently used, among other things to find subtle concurrency bugs in telecommunications code.\n\nThe key idea on which QuickCheck is founded, is property-based testing. That is, instead of writing individual test cases (eg unit tests corresponding to input-output pairs for particular functions) one should write properties that are desired of the functions, and then automatically generate random tests which can be run to verify (or rather, falsify) the property.\n\nBy emphasizing the importance of specifications, QuickCheck yields several benefits:\n• None The developer is forced to think about what the code should do,\n• None The tool finds corner-cases where the specification is violated, which leads to either the code or the specification getting fixed,\n• None The specifications live on as rich, machine-checkable documentation about how the code should behave.\n\nA QuickCheck property is essentially a function whose output is a boolean. The standard “hello-world” QC property is\n\nThat is, a property looks a bit like a mathematical theorem that the programmer believes is true. A QC convention is to use the prefix for QC properties. Note that the type signature for the property is not the usual polymorphic signature; we have given the concrete type for the elements of the list. This is because QC uses the types to generate random inputs, and hence is restricted to monomorphic properties (that don’t contain type variables.)\n\nTo check a property, we simply invoke the function\n\nlets try it on our example property above\n\nWhats that ?! Well, lets run the property function on the two inputs\n\nQC has found a sample input for which the property function fails ie, returns . Of course, those of you who are paying attention will realize there was a bug in our property, namely it should be\n\nbecause will flip the order of the two parts and of . Now, when we run\n\nThat is, Haskell generated 100 test inputs and for all of those, the property held. You can up the stakes a bit by changing the number of tests you want to run\n\nand then do\n\nLets look at a slightly more interesting example. Here is the canonical implementation of quicksort in Haskell.\n\nReally doesn’t need much explanation! Lets run it “by hand” on a few inputs\n\nLooks good – lets try to test that the output is in fact sorted. We need a function that checks that a list is ordered\n\nand then we can use the above to write a property\n\nHere are several other properties that we might want. First, repeated should not change the list. That is,\n\nSecond, the head of the result is the minimum element of the input\n\nHowever, when we run this, we run into a glitch\n\nBut of course! The earlier properties held for all inputs while this property makes no sense if the input list is empty! This is why thinking about specifications and properties has the benefit of clarifying the preconditions under which a given piece of code is supposed to work.\n\nIn this case we want a conditional properties where we only want the output to satisfy to satisfy the spec if the input meets the precondition that it is non-empty.\n\nWe can write a similar property for the maximum element too. This time around, both the properties hold\n\nNote that now, instead of just being a the output of the function is a a special type built into the QC library. Similarly the implies combinator is on of many QC combinators that allow the construction of rich properties.\n\nWe could keep writing different properties that capture various aspects of the desired functionality of . Another approach for validation is to test that our is behaviourally identical to a trusted reference implementation which itself may be too inefficient or otherwise unsuitable for deployment. In this case, lets use the standard library’s function\n\nwhich we can put to the test\n\nUgh! So close, and yet … Can you spot the bug in our code?\n\nWe’re assuming that the only occurrence of (the value) is itself! That is, if there are any copies of in the tail, they will not appear in either or and hence they get thrown out of the output.\n\nIs this a bug in the code? What is a bug anyway? Perhaps the fact that all duplicates are eliminated is a feature! At any rate there is an inconsistency between our mental model of how the code should behave as articulated in and the actual behavior of the code itself.\n\nWe can rectify matters by stipulating that the produces lists of distinct elements\n\nand then, weakening the equivalence to only hold on inputs that are duplicate-free\n\nWell, we managed to fix the property, but beware! Adding preconditions leads one down a slippery slope. In fact, if we paid closer attention to the above runs, we would notice something\n\nThe bit about some tests being discarded is ominous. In effect, when the property is constructed with the combinator, QC discards the randomly generated tests on which the precondition is false. In the above case QC grinds away on the remainder until it can meet its target of valid tests. This is because the probability of a randomly generated list meeting the precondition (having distinct elements) is high enough. This may not always be the case.\n\nThe following code is (a simplified version of) the function from the standard library\n\nGiven an element and a list , the function walks along till it finds the first element greater than and it places to the left of that element. Thus\n\nIndeed, the following is the well known insertion-sort algorithm\n\nWe could write our own tests, but why do something a machine can do better?!\n\nNow, the reason that the above works is that the routine preserves sorted-ness. That is while of course the property\n\nthe output is ordered if the input was ordered to begin with\n\nNotice that now, the precondition is more complex – the property requires that the input list be ordered. If we QC the property\n\nUgh! The ordered lists are so sparsely distributed among random lists, that QC timed out well before it found 10000 valid inputs!\n\nAside the above example also illustrates the benefit of writing the property as instead of using the boolean operator to write . In the latter case, there is a flat predicate, and QC doesn’t know what the precondition is, so a property may hold vacuously. For example consider the variant\n\nQC will happily check it for us\n\nUnfortunately, in the above, the tests passed vacuously only because their inputs were not ordered, and one should use to avoid the false sense of security delivered by vacuity.\n\nQC provides us with some combinators for guarding against vacuity by allowing us to investigate the distribution of test cases\n\nWe may use these to write a property that looks like\n\nWhen we run this, as before we get a detailed breakdown of the 100 passing tests\n\nwhere a line means that percent of the inputs had length and satisfied the predicate denoted by the string . Thus, as we see from the above, a paltry 13% of the tests were ordered and that was because they were either empty ( ) or had one ( ). or two elements ( ). The odds of randomly stumbling upon a beefy list that is ordered are rather small indeed!\n\nBefore we start discussing how QC generates data (and how we can help it generate data meeting some pre-conditions), we must ask ourselves a basic question: how does QC behave randomly in the first place?!\n\nEh? This seems most impure – same inputs yielding two totally different outputs! Well, this should give you a clue as to one of the key techniques underlying QC – monads!\n\nA Haskell term that generates a (random value) of type has the type which is defined as\n\nIn effect, the term is a function that takes as input a random number generator and a seed and returns an value. One can easily (and we shall see, profitably!) turn into a by\n\nThe function simply forks the random number generator into two parts; which are used by the left and right parameters of the bind operator . (Aside you should be able to readily spot the similarity between random number generators and the monad – in both cases the basic action is to grab some value and transition the state to the next-value. For more details see Chapter 14, RWH)\n\nQC uses the above to define a typeclass for types for which random values can be generated!\n\nThus, to have QC work with (ie generate random tests for) values of type we need only make an instance of by defining an appropriate function for it. QC defines instances for base types like , , lists etc and lifts them to compound types much like we did for a few lectures back\n\nQC comes loaded with a set of combinators that allow us to create custom instances for our own types.\n\nThe first of these combinators is\n\nwhich takes an interval and returns an random element from that interval. (The typeclass describes types which can be sampled. For example, the following is a randomly chosen set of numbers between and .\n\nWhat is a plausible type for ?\n\nA second useful combinator is\n\nwhich returns a generator that produces values drawn from the input list\n\nwhich allows us to randomly choose between multiple generators\n\nLets try to figure out the implementation of\n\nFinally, is generalized into the combinator\n\nwhich allows us to build weighted combinations of individual generators.\n\nWe can use the above combinators to write generators for lists\n\nCan you spot a problem in the above?\n\nProblem: only generates infinite lists! Hmm. Lets try again,\n\nThis is not bad, but we may want to give the generator a higher chance of not finishing off with the empty list, so lets use\n\nWe can use the above to build a custom generator that always returns ordered lists by piping the generate list into the function\n\nTo check the output of a custom generator we can use the combinator\n\nFor example, we can check that in fact, the combinator only produces ordered lists\n\nand now, we can properly test the property\n\nNext, lets look at how QC can be used to generate structured data, by doing a small case-study on checking a compiler optimization.\n\nRecall the small While language that you wrote an evaluator for in HW2.\n\nwhere the atomic expressions were either variables or values\n\nWe used the expressions to define imperative statements which are either assignments, if-then-else, a sequence of two statements, or a while-loop.\n\nThe behavior of While programs was given using a state which is simply a map from variables to values. Intuitively, a statement will update the state by modifying the values of the variables appropriately.\n\nYour assignment was to (use the monad to) write an evaluator (aka interpreter) for the language that took as input a program and a starting state and returned the final state.\n\nSince you wrote the code for the HW (you DID didn’t you?) we won’t go into the details now – scroll down to the bottom to see how is implemented.\n\nWe could painstakingly write manual test cases, but instead lets write some simple generators for While programs, so that we can then check interesting properties of the programs and the evaluator.\n\nthus, we assume that the programs are over variables drawn from the uppercase alphabet characters. That is, our test programs range over 26 variables (you can change the above if you like.)\n\nSecond, we can write a generator for constant values (that can appear in expressions). Our generator simply chooses between randomly generated and values.\n\nThird, we define a generator for and which selects from the different cases.\n\nFinally, we need to write a generator for so that we can run the While program from some arbitrary input configuration.\n\nIn the above, is a randomly generated list of key-value tuples, which is turned into a by the function.\n\nLet and be two While programs. We say that is equivalent to if for all input configurations the configuration resulting from executing from is the same as that obtained by executing from . Formally,\n\nExcellent! Lets take our generators our for a spin, by checking some compiler optimizations. Intuitively, a compiler optimization (or transformation) can be viewed as a pair of programs – the input program and a transformed program . A transformation is correct iff is equivalent to .\n\nHere’s are some simple sanity check properties that correspond to optimizations.\n\nUh? whats going on? Well, lets look at the generator for expressions.\n\nin effect, its will generate infinite expressions with high probability! (do the math!) So we need some way to control the size, either by biasing the and constructors (which terminate the generation) or by looking at the size of the structure during generation. We can do this with the combinator\n\nwhich lets us write functions that parameterize the generator with an integer (and then turn that into a flat generator.)\n\nIn the above, we keep halving the number of allowed nodes, and when that number goes to we just return an atomic expression (either a variable or a constant.) We can now update the generator for expressions to\n\nAnd now, lets check the property again\n\nwhoops! Forgot about those pesky boolean expressions! If you think about it,\n\nwill assign to the variable while\n\nwill assign to the variable! Urgh. Ok, lets limit ourselves to Integer expressions\n\nusing which, we can tweak the property to limit ourselves to integer expressions\n\nO, Quickcheck, what say you now?\n\nOf course! in the input state where has the value , the result of executing is quite different from executing . Oh well, so much for that optimization, I guess we need some type information before we can eliminate the additions-to-zero!\n\nWell, that first one ran aground because While was untyped (tsk tsk.) and so adding a zero can cause problems if the expression is a boolean. Lets look at another optimization that is not plagued by the int-v-bool conflict. Suppose you have two back-to-back assignments\n\nIt is silly to recompute twice, since the result is already stored in . So, we should be able to optimize the above code to\n\nLets see how we might express the correctness of this transformation as a QC property\n\nHoly transfer function!! It fails?!! And what is that bizarre test? It seems rather difficult to follow. Turns out, QC comes with a test shrinking mechanism; all we need do is add to the instance a function of type\n\nwhich will take a candidate and generate a list of smaller candidates that QC will systematically crunch through till it finds a minimally failing test!\n\nLets try it again to see if we can figure it out!\n\nAha! Consider the two programs\n\nWell, I hope I’ve convinced you that QuickCheck is pretty awesome. The astonishing thing about it is its sheer simplicity – a few fistfuls of typeclasses and a tiny pinch of monads and lo! a shockingly useful testing technique that can find a bunch of subtle bugs or inconsistencies in your code.\n\nMoral of the story – types can go a long way towards making your code obviously correct, but not the whole distance. Make up the difference by writing properties, and have the machine crank out thousands of tests for you!\n\nThere is a lot of literature on QuickCheck on the web. It is used for a variety of commercial applications, both in Haskell and in pretty much every modern language, including Perl. Even if you don’t implement a system in Haskell, you can use QuickCheck to test it, by just using the nifty data generation facilities.\n\nWe don’t have exceptions, so if a variable is not found, return value 0\n\nReturn for arithmetic operations over a value."
    },
    {
        "link": "https://github.com/RevolutionAnalytics/quickcheck/blob/master/docs/tutorial.md",
        "document": "Quickcheck was originally a package for the language Haskell aimed at simplifying the writing of tests. The main idea is the automatic generation of tests based on assertions a function needs to satisfy and the signature of that function. The idea spread to other languages and is now implemented in R with this package (for the first time according to the best of our knowledge). Because of the differences in type systems between Haskell and other languages, the original idea morphed into something different for each language it was translated into. In R, the main ideas retained are that tests are based on assertions and that the developer should not have to specify the inputs and output values of a test. The main difference from Haskell is that, in R, the user needs to specify the type of each variable in an assertion with the optional possibility to fully specify its distribution. The main function in the package, , will randomly generate input values, execute an assertion and collect results. There are several advantages to this approach:\n• each test can be run multiple times on different data points, improving coverage and the ability to detect bugs, at no additional cost for the developer;\n• tests can run on large size inputs, possible but impractical in non-randomized testing;\n• assertions are more self-documenting than specific examples of the I/O relation -- in fact, enough assertions can constitute a specification for the function being tested, but that's not necessary for testing to be useful;\n• it is less likely for the developer to use implicit assumptions in the selection of testing data -- randomized testing \"keeps you honest\".\n\nLet's start with something very simple. Let's say we just wrote the function for transpose. Using the widely used testing package , one can just write a test as follows:\n\nThat works, but has some limitations. For instance, suppose we have to match some fictional military-grade testing which requires to run at least tests per function: writing them this way would be pretty laborious. One solution is to replace examples of what the function is supposed to do with a general statement of one or more properties that a function is supposed to have, also known as an assertion:\n\nThat's progress, yet the testing points are chosen manually and arbitrarily. It's hard to have many or very large input values, and unstated assumptions may affect their choice. For instance, is going to work for non-numeric matrices? can solve or at least alleviate all these problems:\n\nWe recognize the assertion in the previous code snippet, modified to take into account matrices with 0 rows or columns. Here, though, it becomes the body of a function, which is called \"assertion\" in , which has one or more arguments, all with default values, and returns a length-one logical vector. means success, or an error mean failure. Some of those arguments are initialized randomly, in this case using what in is called a Random Data Generator, or RDG -- more on these later. In this case is a function that returns a random matrix. The function creates assertions and does little more than , but its name clarifies intent. The function evaluates the assertion multiple times and produces some messages:\n• the seed used, unique to each test\n• the assertion tested -- useful when scanning a log of a long series of tests\n• when in non-interactive mode, a useful R expression -- more on that later.\n\nThe success of this test means that we have tested that satisfies this assertion on a sample of random matrices, including a variety of sizes, element types and, of course, element values. We don't have to write them one by one and later we will see how we can affect the distribution of such inputs, to make them, say, larger in size or value, or more likely to hit corner cases. If we need to control the number of time the assertion is run, that's very simple:\n\nDone! If one had to write down those 100 matrices one by one, there would never be time to. Let's review the advantages of this setup. We can increase the severity of the test by cranking up the number of runs of the assertion, just by changing a parameter. We can also change the distribution of matrices to test larger inputs, see Section Modifying or defining random data generators and . Moreover tests communicate intent. While each test is run in practice on a small set of examples, the promise implied by the test is unmistakably that it ought to pass for any matrix. Finally, a user doesn't have to guess from a small set of inputs what the function does and what its allowable range is. Assertions are also executable documentation.\n\nUnlike , which requires the constructions of specially defined expectations, accepts logical-valued functions, with a length-one return value and a default value for each argument. For example\n\nare valid assertions -- independent of their success or failure. For readability and safety, can be used, as in . As an added benefit, checks that all arguments have a default. If an assertion returns , it is considered a success. If an assertion returns or generates an error, it is considered a failure. For instance, is a valid assertion but always fails. How can we express the fact that this is 's correct behavior? has a rich set of expectations to capture this and other requirements, such as printing something or generating a warning. has a way to access those, implemented as the function :\n\nBy executing this test successfully we have built confidence that the function will generate an error whenever called with any argument. implements four expectations, \"error\", \"message\", \"output\", \"warning\". Other expectations are easily implemented with ordinary R code and are not supported.\n\ndoesn't fix bugs automatically yet, but tries to assist that activity in a couple of ways. The first is its output:\n\nThis output shows that some of the default 10 runs have failed and then invites us to enter a command, , that will execute the assertion in the debugger with the input data that made it fail. Another way to achieve the same is to run the test with the option which doesn't produce an error and returns the same debugging data. This is convenient for interactive sessions, but less so when running . In fact, the default for the argument is for interactive sessions and otherwise, which should work for most people.\n\nIn most cases all we need to do with the output of is to pass it to another function, :\n\nThis opens the debugger at the beginning of a failed call to the assertion. Now it is up to the developer to fix any bugs.\n\nTo achieve reproducibility, one has to write assertions that depend exclusively on their arguments and are deterministic functions thereof, and leave all the randomness to and the assertion arguments default values. The function seeds the random number generator in a way that ensures reproducibility from one call to the next. The seed is unique to each assertion, to guarantee independence of tests on different assertions and different implementations -- one can't code assuming certain data will occur again and again.\n\nThere is no general answer to this question. One possible criterion is that of test coverage, the fraction of code that has been executed during the execution of tests, which is considered a practical proxy for \"thoroughness\". The other is the strictness assertions. The conjunction of all the assertions in a test set should imply the correctness of a program, in the ideal case and when universally quantified over their inputs. For instance tests one important property of the function for all integer vectors. That doesn't mean it runs the test for all integer vectors, which is impossible, but it means that there should be no failure no matter how many runs we allow the test to include. Also, while this may be the ideal case, we should not let \"perfection be the enemy of the good\". Any set of assertions is better than no assertion.\n\nThe attentive reader may have already noticed that this is not the strictest test we could have written, independent of the fact that it achieves 100% coverage. is supposed to work with any R object, so is also expected to pass and, if universally quantified over all inputs, implies the previous test, which means that it is stricter and better captures the developer's intent. Hence, we should prefer the latter version of this test.\n\nAs a final guideline for test-writing, there is practical and some theoretical evidence that shorter programs can be tested more effectively, provided that the tests are also short. To summarize:\n• Write the strictest set of tests possible. Only a correct program should be able to pass them, given infinite time to run the tests\n\nQuickcheck can help with the second point. Argument to function , when set to TRUE or the name of a function will cause to start a Shiny app detailing coverage for a specific function. To get a package-level coverage report, enter .\n\nThere are built in random data generators for most built-in data types. They follow a simple naming conventions, \"r\" followed by the class name. For instance generates a random integer vector. Another characteristic of random data generators as defined in this package is that they have defaults for every argument, that is they can be called without arguments. That's one difference with R random number generators, such as and , the other being that those return a sample of a specific size, whereas for random data generators even that is random, unless specified otherwise. Like RNGs, quickcheck's generators promise statistical independence between calls -- whatever that means in the pseudo-random setting.\n\nBoth elements and length change from one call to the next and in fact they are both random and independent. This is generally true for all generators, with the exception of the trivial generators created with . Most generators take two arguments, and which are meant to specify the distribution of the elements and size of the returned data structures and whose exact interpretation depends on the specific generator. In general, if the argument is a numeric it is construed as providing parameters of the default RNG invoked to draw the elements, if it is a function, it is called with a single argument to generate the elements of the random data structure. For example:\n\ngenerates some random double vector. The next expression does the same but with expectation 100 and standard deviation 20\n\nand finally this extracts the elements from a uniform distribution with all parameters at default values.\n\nFor other generators the parameters may have different names and semantics, for instance\n\nFor added convenience, the vector of parameters is subject to argument matching as if they were argument to a separate function, for instance:\n\nis equivalent to the previous one, and\n\nleaves the component at its default. The defaults are controlled by package options, see .\n\nThere is also a formula syntax, for instance to modify the parameters of , as in\n\nwhich is the same as\n\nRemember to use the variable anywhere appropriate in the formula, so that it evaluates to exactly elements.\n\nTo summarize, can be:\n• an RNG that takes the sample size as its first argument;\n• a formula containing the variable and evaluating to a length vector.\n\nIn general the RNG or formula should return exactly elements. If not, recycling will be applied after issuing a warning. Recycling random numbers in general changes their stochastic properties and it is not recommended. But there are some use cases, like creating a random-length vector of 0s.\n\nA similar range of options is available for argument . It can be a range, partially or completely specified, a RNG function or a formula returning exactly a vector of length 1.\n\nTwo dimensional data structures have the argument replaced by and , with the same possible values. Nested data structures have an argument . For now can only be one number construed as maximum height and applies only to . To define a test with a random vector of a specific length as input, one can use the generator constructor :\n\nOr, since \"succintness is power\":\n\nWithout the it would be a min size, with it it is deterministic. Sounds contrived, but if one starts with the assumption that in random is the default, it make sense that slightly more complex expressions be necessary to express determinism.\n\nWe can not exclude adjustments to the default distributions in future versions. Please don't write tests that rely on implementation details of the generators.\n\nThere is no reason to limit oneself to built-in generators and one can do much more than just change the parameters. For instance, we may want to make sure that extremes of the allowed range are hit more often than the built-in generators ensure. For instance, uses by default a standard normal, and values like 0 and Inf have very small or 0 probability of occurring. Let's say we want to test the following assertion about the ratio:\n\nWe can have two separate tests, one for values returned by :\n\nand one for the corner cases:\n\nThat's a start, but the two types of values never mix in the same vector. We can combine the two with a custom generator\n\nAnd use it in a more general test.\n\nThe alert reader may have already noticed how generators can be used to define other generators. For instance, a random list of double vectors can be generated with and a list thereof with . Since typing over and over again gets old quickly and adds clutter, we can use as a shortcut ."
    },
    {
        "link": "https://hackage.haskell.org/package/QuickCheck/docs/Test-QuickCheck.html",
        "document": "That's because GHCi will default any type variables in your property to () , so in the example above quickCheck was really testing that () is equal to itself. To avoid this behaviour it is best practise to monomorphise your polymorphic properties when testing:\n\nprop_reverse_bad :: [Int] -> Bool prop_reverse_bad xs = reverse xs == xs\n\nTo use QuickCheck on your own data types you will need to write Arbitrary instances for those types. See the QuickCheck manual for details about how to do that.\n\nTo start using QuickCheck, write down your property as a function returning Bool . For example, to check that reversing a list twice gives back the same list you can write:\n\nThe QuickCheck manual gives detailed information about using QuickCheck effectively. You can also try https://begriffs.com/posts/2017-01-14-design-use-quickcheck.html , a tutorial written by a user of QuickCheck.\n\nQuickCheck provides instances for most types in , except those which incur extra dependencies. For a wider range of instances see the quickcheck-instances package. A generator for values of the given type. It is worth spending time thinking about what sort of test data you want - good generators are often the difference between finding bugs and not finding them. You can use , and to check the quality of your test data. shrink :: a -> [a] Source # Produces a (possibly) empty list of all the possible immediate shrinks of the given value. The default implementation returns the empty list, so will not try to shrink the value. If your data type has no special invariants, you can enable shrinking by defining , but by customising the behaviour of you can often get simpler counterexamples. For example, suppose we have the following implementation of binary trees: shrink Nil = [] shrink (Branch x l r) = -- shrink Branch to Nil [Nil] ++ -- shrink to subterms [l, r] ++ -- recursively shrink subterms [Branch x' l' r' | (x', l', r') <- shrink (x, l, r)]\n• QuickCheck tries the shrinking candidates in the order they appear in the list, so we put more aggressive shrinking steps (such as replacing the whole tree by ) before smaller ones (such as recursively shrinking the subtrees).\n• It is tempting to write the last line as [Branch x' l' r' | x' <- shrink x, l' <- shrink l, r' <- shrink r] but this is the wrong thing! It will force QuickCheck to shrink , and in tandem, and shrinking will stop once one of the three is fully shrunk. There is a fair bit of boilerplate in the code above. We can avoid it with the help of some generic functions. The function tries shrinking a term to all of its subterms and, failing that, recursively shrinks the subterms. Using it, we can define as: shrink x = shrinkToNil x ++ genericShrink x where shrinkToNil Nil = [] shrinkToNil (Branch _ l r) = [Nil] is a combination of , which shrinks a term to any of its subterms, and , which shrinks all subterms of a term. These may be useful if you need a bit more control over shrinking than gives you. A final gotcha: we cannot define as simply as this shrinks to , and shrinking will go into an infinite loop. shrink :: ASCIIString -> [ASCIIString] Source # shrink :: PrintableString -> [PrintableString] Source # shrink :: UnicodeString -> [UnicodeString] Source # shrink :: A -> [A] Source # shrink :: B -> [B] Source # arbitrary :: Gen C Source # shrink :: C -> [C] Source # shrink :: OrdA -> [OrdA] Source # shrink :: OrdB -> [OrdB] Source # shrink :: OrdC -> [OrdC] Source # shrink :: All -> [All] Source # shrink :: Any -> [Any] Source # arbitrary :: Gen Version Source # shrink :: Version -> [Version] Source # shrink :: CChar -> [CChar] Source # shrink :: CClock -> [CClock] Source # shrink :: CDouble -> [CDouble] Source # shrink :: CFloat -> [CFloat] Source # shrink :: CInt -> [CInt] Source # shrink :: CIntMax -> [CIntMax] Source # shrink :: CIntPtr -> [CIntPtr] Source # shrink :: CLLong -> [CLLong] Source # shrink :: CLong -> [CLong] Source # shrink :: CPtrdiff -> [CPtrdiff] Source # shrink :: CSChar -> [CSChar] Source # shrink :: CSUSeconds -> [CSUSeconds] Source # shrink :: CShort -> [CShort] Source # shrink :: CSigAtomic -> [CSigAtomic] Source # shrink :: CSize -> [CSize] Source # shrink :: CTime -> [CTime] Source # shrink :: CUChar -> [CUChar] Source # shrink :: CUInt -> [CUInt] Source # shrink :: CUIntMax -> [CUIntMax] Source # shrink :: CUIntPtr -> [CUIntPtr] Source # shrink :: CULLong -> [CULLong] Source # shrink :: CULong -> [CULong] Source # shrink :: CUSeconds -> [CUSeconds] Source # shrink :: CUShort -> [CUShort] Source # shrink :: CWchar -> [CWchar] Source # shrink :: ExitCode -> [ExitCode] Source # shrink :: Newline -> [Newline] Source # shrink :: NewlineMode -> [NewlineMode] Source # shrink :: Int16 -> [Int16] Source # shrink :: Int32 -> [Int32] Source # shrink :: Int64 -> [Int64] Source # shrink :: Int8 -> [Int8] Source # shrink :: Word16 -> [Word16] Source # shrink :: Word32 -> [Word32] Source # shrink :: Word64 -> [Word64] Source # shrink :: Word8 -> [Word8] Source # shrink :: IntSet -> [IntSet] Source # shrink :: Ordering -> [Ordering] Source # shrink :: Integer -> [Integer] Source # arbitrary :: Gen () Source # shrink :: () -> [()] Source # shrink :: Bool -> [Bool] Source # shrink :: Char -> [Char] Source # shrink :: Double -> [Double] Source # shrink :: Float -> [Float] Source # shrink :: Int -> [Int] Source # shrink :: Word -> [Word] Source # shrink :: Blind a -> [Blind a] Source # shrink :: Fixed a -> [Fixed a] Source # shrink :: InfiniteList a -> [InfiniteList a] Source # shrink :: Large a -> [Large a] Source # shrink :: Negative a -> [Negative a] Source # shrink :: NonEmptyList a -> [NonEmptyList a] Source # shrink :: NonNegative a -> [NonNegative a] Source # shrink :: NonPositive a -> [NonPositive a] Source # shrink :: NonZero a -> [NonZero a] Source # shrink :: OrderedList a -> [OrderedList a] Source # shrink :: Positive a -> [Positive a] Source # shrink :: Shrink2 a -> [Shrink2 a] Source # shrink :: Small a -> [Small a] Source # shrink :: Smart a -> [Smart a] Source # shrink :: SortedList a -> [SortedList a] Source # shrink :: ZipList a -> [ZipList a] Source # shrink :: Complex a -> [Complex a] Source # shrink :: Identity a -> [Identity a] Source # shrink :: First a -> [First a] Source # shrink :: Last a -> [Last a] Source # shrink :: Dual a -> [Dual a] Source # shrink :: Endo a -> [Endo a] Source # shrink :: Product a -> [Product a] Source # shrink :: Sum a -> [Sum a] Source # shrink :: Ratio a -> [Ratio a] Source # shrink :: IntMap a -> [IntMap a] Source # shrink :: Seq a -> [Seq a] Source # WARNING: Users working on the internals of the type via e.g. should be aware that this instance aims to give a good representation of as mathematical sets but *does not* aim to provide a varied distribution over the underlying representation. shrink :: Set a -> [Set a] Source # shrink :: Tree a -> [Tree a] Source # shrink :: Maybe a -> [Maybe a] Source # shrink :: [a] -> [[a]] Source # arbitrary :: Gen (a :-> b) Source # shrink :: (a :-> b) -> [a :-> b] Source # shrink :: Fun a b -> [Fun a b] Source # arbitrary :: Gen (Shrinking s a) Source # shrink :: Shrinking s a -> [Shrinking s a] Source # shrink :: WrappedMonad m a -> [WrappedMonad m a] Source # shrink :: Either a b -> [Either a b] Source # shrink :: Fixed a -> [Fixed a] Source # shrink :: Map k v -> [Map k v] Source # shrink :: (a, b) -> [(a, b)] Source # arbitrary :: Gen (a -> b) Source # shrink :: (a -> b) -> [a -> b] Source # Arbitrary (a b c) => Arbitrary WrappedArrow a b c) Source # arbitrary :: Gen (WrappedArrow a b c) Source # shrink :: WrappedArrow a b c -> [WrappedArrow a b c] Source # shrink :: Const a b -> [Const a b] Source # shrink :: Alt f a -> [Alt f a] Source # shrink :: Constant a b -> [Constant a b] Source # arbitrary :: Gen (a, b, c) Source # shrink :: (a, b, c) -> [(a, b, c)] Source # shrink :: Product f g a -> [Product f g a] Source # arbitrary :: Gen (a, b, c, d) Source # shrink :: (a, b, c, d) -> [(a, b, c, d)] Source # shrink :: Compose f g a -> [Compose f g a] Source # arbitrary :: Gen (a, b, c, d, e) Source # shrink :: (a, b, c, d, e) -> [(a, b, c, d, e)] Source # arbitrary :: Gen (a, b, c, d, e, f) Source # shrink :: (a, b, c, d, e, f) -> [(a, b, c, d, e, f)] Source # arbitrary :: Gen (a, b, c, d, e, f, g) Source # shrink :: (a, b, c, d, e, f, g) -> [(a, b, c, d, e, f, g)] Source # arbitrary :: Gen (a, b, c, d, e, f, g, h) Source # shrink :: (a, b, c, d, e, f, g, h) -> [(a, b, c, d, e, f, g, h)] Source # arbitrary :: Gen (a, b, c, d, e, f, g, h, i) Source # shrink :: (a, b, c, d, e, f, g, h, i) -> [(a, b, c, d, e, f, g, h, i)] Source # arbitrary :: Gen (a, b, c, d, e, f, g, h, i, j) Source # shrink :: (a, b, c, d, e, f, g, h, i, j) -> [(a, b, c, d, e, f, g, h, i, j)] Source #\n\nThe class is used for random generation of showable functions of type . There is a default implementation for , which you can use if your type has structural equality. Otherwise, you can normally use or . function :: (a -> b) -> a :-> b Source # default function :: (Generic a, GFunction (Rep a)) => (a -> b) -> a :-> b Source # function :: (A -> b) -> A :-> b Source # function :: (B -> b) -> B :-> b Source # function :: (C -> b) -> C :-> b Source # function :: (OrdA -> b) -> OrdA :-> b Source # function :: (OrdB -> b) -> OrdB :-> b Source # function :: (OrdC -> b) -> OrdC :-> b Source # function :: (All -> b) -> All :-> b Source # function :: (Any -> b) -> Any :-> b Source # function :: (Newline -> b) -> Newline :-> b Source # function :: (NewlineMode -> b) -> NewlineMode :-> b Source # function :: (Int16 -> b) -> Int16 :-> b Source # function :: (Int32 -> b) -> Int32 :-> b Source # function :: (Int64 -> b) -> Int64 :-> b Source # function :: (Int8 -> b) -> Int8 :-> b Source # function :: (Word16 -> b) -> Word16 :-> b Source # function :: (Word32 -> b) -> Word32 :-> b Source # function :: (Word64 -> b) -> Word64 :-> b Source # function :: (Word8 -> b) -> Word8 :-> b Source # function :: (IntSet -> b) -> IntSet :-> b Source # function :: (Ordering -> b) -> Ordering :-> b Source # function :: (Integer -> b) -> Integer :-> b Source # function :: (() -> b) -> () :-> b Source # function :: (Bool -> b) -> Bool :-> b Source # function :: (Char -> b) -> Char :-> b Source # function :: (Double -> b) -> Double :-> b Source # function :: (Float -> b) -> Float :-> b Source # function :: (Int -> b) -> Int :-> b Source # function :: (Word -> b) -> Word :-> b Source # function :: (Complex a -> b) -> Complex a :-> b Source # function :: (Identity a -> b) -> Identity a :-> b Source # function :: (First a -> b) -> First a :-> b Source # function :: (Last a -> b) -> Last a :-> b Source # function :: (Dual a -> b) -> Dual a :-> b Source # function :: (Product a -> b) -> Product a :-> b Source # function :: (Sum a -> b) -> Sum a :-> b Source # function :: (Ratio a -> b) -> Ratio a :-> b Source # function :: (IntMap a -> b) -> IntMap a :-> b Source # function :: (Seq a -> b) -> Seq a :-> b Source # function :: (Set a -> b) -> Set a :-> b Source # function :: (Tree a -> b) -> Tree a :-> b Source # function :: (Maybe a -> b) -> Maybe a :-> b Source # function :: ([a] -> b) -> [a] :-> b Source # function :: (Either a b -> b0) -> Either a b :-> b0 Source # function :: (Fixed a -> b) -> Fixed a :-> b Source # function :: (Map a b -> b0) -> Map a b :-> b0 Source # function :: ((a, b) -> b0) -> (a, b) :-> b0 Source # function :: (Const a b -> b0) -> Const a b :-> b0 Source # function :: (Alt f a -> b) -> Alt f a :-> b Source # function :: ((a, b, c) -> b0) -> (a, b, c) :-> b0 Source # function :: ((a, b, c, d) -> b0) -> (a, b, c, d) :-> b0 Source # function :: ((a, b, c, d, e) -> b0) -> (a, b, c, d, e) :-> b0 Source # function :: ((a, b, c, d, e, f) -> b0) -> (a, b, c, d, e, f) :-> b0 Source # function :: ((a, b, c, d, e, f, g) -> b0) -> (a, b, c, d, e, f, g) :-> b0 Source #"
    },
    {
        "link": "https://stackoverflow.com/questions/16572446/why-are-if-expressions-frowned-upon-in-haskell",
        "document": "Your first version, the one preferred by your prof, has the following advantages compared to the others:\n• list components are named in the pattern, so no mention of and .\n\nI do think that this one is considered \"best practice\".\n\nWhat's the big deal? Why would we want to avoid especially and ? Well, everybody knows that those functions are not total, so one automatically tries to make sure that all cases are covered. A pattern match on [] not only stands out more than , a series of pattern matches can be checked by the compiler for completeness. Hence, the idiomatic version with complete pattern match is easier to grasp (for the trained Haskell reader) and to proof exhaustive by the compiler.\n\nThe second version is slightly better than the last one because one sees at once that all cases are handled. Still, in the general case the RHS of the second equation could be longer and there could be a where clauses with a couple of definitions, the last of them could be something like:\n\nTo be absolutly sure to understand what the RHS does, one has to make sure common names have not been redefined.\n\nThe 3rd version is the worst one IMHO: a) The 2nd match fails to deconstruct the list and still uses head and tail. b) The case is slightly more verbose than the equivalent notation with 2 equations."
    },
    {
        "link": "https://haskell.org/tutorial/patterns.html",
        "document": "Earlier we gave several examples of pattern matching in defining functions---for example and . In this section we will look at the pattern-matching process in greater detail (§3.17). (Pattern matching in Haskell is different from that found in logic programming languages such as Prolog; in particular, it can be viewed as \"one-way\" matching, whereas Prolog allows \"two-way\" matching (via unification), along with implicit backtracking in its evaluation mechanism.)\n\nPatterns are not \"first-class;\" there is only a fixed set of different kinds of patterns. We have already seen several examples of data constructor patterns; both and defined earlier use such patterns, the former on the constructors of a \"built-in\" type (lists), the latter on a user-defined type ( ). Indeed, matching is permitted using the constructors of any type, user-defined or not. This includes tuples, strings, numbers, characters, etc. For example, here's a contrived function that matches against a tuple of \"constants:\" This example also demonstrates that nesting of patterns is permitted (to arbitrary depth).\n\nTechnically speaking, formal parameters (The Report calls these variables.) are also patterns---it's just that they never fail to match a value. As a \"side effect\" of the successful match, the formal parameter is bound to the value it is being matched against. For this reason patterns in any one equation are not allowed to have more than one occurrence of the same formal parameter (a property called linearity §3.17, §3.3, §4.4.3).\n\nPatterns such as formal parameters that never fail to match are said to be irrefutable, in contrast to refutable patterns which may fail to match. The pattern used in the example above is refutable. There are three other kinds of irrefutable patterns, two of which we will introduce now (the other we will delay until Section 4.4).\n\nSo far we have discussed how individual patterns are matched, how some are refutable, some are irrefutable, etc. But what drives the overall process? In what order are the matches attempted? What if none succeeds? This section addresses these questions.\n\nPattern matching can either fail, succeed or diverge. A successful match binds the formal parameters in the pattern. Divergence occurs when a value needed by the pattern contains an error (_|_). The matching process itself occurs \"top-down, left-to-right.\" Failure of a pattern anywhere in one equation results in failure of the whole equation, and the next equation is then tried. If all equations fail, the value of the function application is _|_, and results in a run-time error.\n\nFor example, if is matched against , then fails to match , so the result is a failed match. (Recall that , defined earlier, is a variable bound to _|_.) But if is matched against , then matching against causes divergence (i.e. _|_).\n\nThe other twist to this set of rules is that top-level patterns may also have a boolean guard, as in this definition of a function that forms an abstract version of a number's sign: Note that a sequence of guards may be provided for the same pattern; as with patterns, they are evaluated top-down, and the first that evaluates to results in a successful match.\n\nThe pattern-matching rules can have subtle effects on the meaning of functions. For example, consider this definition of : \n\n \n\n take 0 _ = []\n\n take _ [] = []\n\n take n (x:xs) = x : take (n-1) xs\n\n \n\n and this slightly different version (the first 2 equations have been reversed): Now note the following:\n\nWe see that is \"more defined\" with respect to its second argument, whereas is more defined with respect to its first. It is difficult to say in this case which definition is better. Just remember that in certain applications, it may make a difference. (The Standard Prelude includes a definition corresponding to .)\n\nPattern matching provides a way to \"dispatch control\" based on structural properties of a value. In many circumstances we don't wish to define a function every time we need to do this, but so far we have only shown how to do pattern matching in function definitions. Haskell's case expression provides a way to solve this problem. Indeed, the meaning of pattern matching in function definitions is specified in the Report in terms of case expressions, which are considered more primitive. In particular, a function definition of the form:\n\nwhere each p is a pattern, is semantically equivalent to:\n\nwhere the are new identifiers. (For a more general translation that includes guards, see §4.4.3.) For example, the definition of given earlier is equivalent to:\n\nA point not made earlier is that, for type correctness, the types of the right-hand sides of a case expression or set of equations comprising a function definition must all be the same; more precisely, they must all share a common principal type.\n\nThe pattern-matching rules for case expressions are the same as we have given for function definitions, so there is really nothing new to learn here, other than to note the convenience that case expressions offer. Indeed, there's one use of a case expression that is so common that it has special syntax: the conditional expression. In Haskell, conditional expressions have the familiar form:\n\nwhich is really short-hand for:\n\nFrom this expansion it should be clear that e must have type , and e and e must have the same (but otherwise arbitrary) type. In other words, - - when viewed as a function has type .\n\nThere is one other kind of pattern allowed in Haskell. It is called a lazy pattern, and has the form pat. Lazy patterns are irrefutable: matching a value v against pat always succeeds, regardless of pat. Operationally speaking, if an identifier in pat is later \"used\" on the right-hand-side, it will be bound to that portion of the value that would result if v were to successfully match pat, and _|_ otherwise.\n\nLazy patterns are useful in contexts where infinite data structures are being defined recursively. For example, infinite lists are an excellent vehicle for writing simulation programs, and in this context the infinite lists are often called streams. Consider the simple case of simulating the interactions between a server process and a client process , where sends a sequence of requests to , and replies to each request with some kind of response. This situation is shown pictorially in Figure 2. (Note that also takes an initial message as argument.)\n\nLet us further assume that the structure of the server and client look something like this: where we assume that is a function that, given a response from the server, determines the next request, and is a function that processes a request from the client, returning an appropriate response.\n\nUnfortunately, this program has a serious problem: it will not produce any output! The problem is that , as used in the recursive setting of and , attempts a match on the response list before it has submitted its first request! In other words, the pattern matching is being done \"too early.\" One way to fix this is to redefine as follows: Although workable, this solution does not read as well as that given earlier. A better solution is to use a lazy pattern: Because lazy patterns are irrefutable, the match will immediately succeed, allowing the initial request to be \"submitted\", in turn allowing the first response to be generated; the engine is now \"primed\", and the recursion takes care of the rest.\n\nAs an example of this program in action, if we define: then we see that:\n\nAs another example of the use of lazy patterns, consider the definition of Fibonacci given earlier: We might try rewriting this using an as-pattern: This version of has the (small) advantage of not using on the right-hand side, since it is available in \"destructured\" form on the left-hand side as .\n\n[This kind of equation is called a pattern binding because it is a top-level equation in which the entire left-hand side is a pattern; i.e. both and become bound within the scope of the declaration.]\n\nNow, using the same reasoning as earlier, we should be led to believe that this program will not generate any output. Curiously, however, it does, and the reason is simple: in Haskell, pattern bindings are assumed to have an implicit in front of them, reflecting the most common behavior expected of pattern bindings, and avoiding some anomalous situations which are beyond the scope of this tutorial. Thus we see that lazy patterns play an important role in Haskell, if only implicitly.\n\nIt is often desirable to create a nested scope within an expression, for the purpose of creating local bindings not seen elsewhere---i.e. some kind of \"block-structuring\" form. In Haskell there are two ways to achieve this:\n\nThese two forms of nested scope seem very similar, but remember that a expression is an expression, whereas a clause is not---it is part of the syntax of function declarations and case expressions.\n\nThe reader may have been wondering how it is that Haskell programs avoid the use of semicolons, or some other kind of terminator, to mark the end of equations, declarations, etc. For example, consider this expression from the last section: \n\n \n\n let y = a*b\n\n f x = (x+y)/y\n\n in f c + f d\n\n \n\n How does the parser know not to parse this as: \n\n \n\n let y = a*b f\n\n x = (x+y)/y\n\n in f c + f d\n\n \n\n ?\n\nThe answer is that Haskell uses a two-dimensional syntax called layout that essentially relies on declarations being \"lined up in columns.\" In the above example, note that and begin in the same column. The rules for layout are spelled out in detail in the Report (§2.7, §B.3), but in practice, use of layout is rather intuitive. Just remember two things:\n\nFirst, the next character following any of the keywords , , or is what determines the starting column for the declarations in the where, let, or case expression being written (the rule also applies to used in the class and instance declarations to be introduced in Section 5). Thus we can begin the declarations on the same line as the keyword, the next line, etc. (The keyword, to be discussed later, also uses layout).\n\nSecond, just be sure that the starting column is further to the right than the starting column associated with the immediately surrounding clause (otherwise it would be ambiguous). The \"termination\" of a declaration happens when something appears at or to the left of the starting column associated with that binding form. (Haskell observes the convention that tabs count as 8 blanks; thus care must be taken when using an editor which may observe some other convention.)\n\nLayout is actually shorthand for an explicit grouping mechanism, which deserves mention because it can be useful under certain circumstances. The example above is equivalent to: \n\n \n\n let { y = a*b\n\n ; f x = (x+y)/y\n\n }\n\n in f c + f d\n\n \n\n Note the explicit curly braces and semicolons. One way in which this explicit notation is useful is when more than one declaration is desired on a line; for example, this is a valid expression: \n\n \n\n let y = a*b; z = a/b\n\n f x = (x+y)/z\n\n in f c + f d\n\n \n\n For another example of the expansion of layout into explicit delimiters, see §2.7.\n\nThe use of layout greatly reduces the syntactic clutter associated with declaration lists, thus enhancing readability. It is easy to learn, and its use is encouraged."
    },
    {
        "link": "https://reddit.com/r/haskell/comments/5qvqwe/cleanly_handling_pattern_matching_errors",
        "document": "Hi r/Haskell, I've been working on a small project where the public API is written in terms of the MTL stack , so I tend to write code that looks a lot like the following.\n\nIn other words, I pattern match on some expression, and if it's valid, then I perform some computation, or else I throw an error and dump the application state to the user.\n\nSince this shows up frequently, I figure I could write and export a set of functions that implements the above functionality on a set of common patterns (most matches tend to happen on expressions of the type of the application state). But the thing is, you can't write a general function that takes , and that expands to the above without using some metaprogramming facility like TH.\n\nSo, is it worth encoding this pattern into a set of functions or just leave the user to handle extraneous patterns themselves?"
    },
    {
        "link": "https://stackoverflow.com/questions/2225774/haskell-pattern-matching-what-is-it",
        "document": "There are other good answers, so I'm going to give you a very technical answer. Pattern matching is the elimination construct for algebraic data types:\n• None \"Elimination construct\" means \"how to consume or use a value\"\n• None \"Algebraic data type\", in addition to first-class functions, is the big idea in a statically typed functional language like Clean, F#, Haskell, or ML\n\nThe idea of algebraic data types is that you define a type of thing, and you say all the ways you can make that thing. As an example, let's define \"Sequence of String\" as an algebraic data type, with three ways to make it:\n\nNow, there are all sorts of things wrong with this definition, but as an example it's interesting because it provides constant-time concatenation of sequences of arbitrary length. (There are other ways to achieve this.) The declaration introduces , , and , which are all the ways there are of making sequences. (That makes each one an introduction construct—a way to make things.)\n• You can make an empty sequence without any other values.\n• To make a sequence with , you need two other sequences.\n• To make a sequence with , you need an element (in this case a string)\n\nHere comes the punch line: the elimination construct, pattern matching, gives you a way to scrutinize a sequence and ask it the question what constructor were you made with?. Because you have to be prepared for any answer, you provide at least one alternative for each constructor. Here's a length function:\n\nAt the core of the language, all pattern matching is built on this construct. However, because algebraic data types and pattern matching are so important to the idioms of the language, there's special \"syntactic sugar\" for doing pattern matching in the declaration form of a function definition:\n\nWith this syntactic sugar, computation by pattern matching looks a lot like definition by equations. (The Haskell committee did this on purpose.) And as you can see in the other answers, it is possible to specialize either an equation or an alternative in a expression by slapping a guard on it. I can't think of a plausible guard for the sequence example, and there are plenty of examples in the other answers, so I'll leave it there."
    },
    {
        "link": "https://classes.cs.uchicago.edu/archive/2020/winter/15100-1/tr-guide/part-06.html",
        "document": ""
    }
]