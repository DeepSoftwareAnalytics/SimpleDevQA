[
    {
        "link": "https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.utility/invoke-restmethod?view=powershell-7.5",
        "document": "The cmdlet sends HTTP and HTTPS requests to Representational State Transfer (REST) web services that return richly structured data. PowerShell formats the response based to the data type. For an RSS or ATOM feed, PowerShell returns the Item or Entry XML nodes. For JavaScript Object Notation (JSON) or XML, PowerShell converts, or deserializes, the content into objects. Comments are permitted in the JSON data. When the REST endpoint returns multiple objects, the objects are received as an array. If you pipe the output from to another command, it's sent as a single object. The contents of that array aren't enumerated for the next command on the pipeline. This cmdlet is introduced in Windows PowerShell 3.0. Beginning in PowerShell 7.0, supports proxy configuration defined by environment variables. See the NOTES section of this article. Beginning in PowerShell 7.4, character encoding for requests defaults to UTF-8 instead of ASCII. If you need a different encoding, you must set the attribute in the header.\n\nExample 1: Get the PowerShell RSS feed\n\nExample 6: Enumerate returned items on the pipeline\n\nSpecifies the body of the request. The body is the content of the request that follows the headers. You can also pipe a body value to . The Body parameter can be used to specify a list of query parameters or specify the content of the response. For query parameters, the cmdlet uses the System.Net.WebUtility.UrlEncode method method to encode the key-value pairs. For more information about encoding strings for URLs, see the UrlEncode() method reference. When the input is a POST request and the body is a String, the value to the left of the first equals sign ( ) is set as a key in the form data and the remaining text is set as the value. To specify multiple keys, use an IDictionary object, such as a hash table, for the Body. When the input is a GET request and the body is an IDictionary (typically, a hash table), the body is added to the URI as query parameters. For other request types (such as PATCH), the body is set as the value of the request body in the standard format with the values URL-encoded. When the input is a System.Xml.XmlNode object and the XML declaration specifies an encoding, that encoding is used for the data in the request unless overridden by the ContentType parameter. When the body is a form, or it's the output of another call, PowerShell sets the request content to the form fields. The Body parameter can also accept a System.Net.Http.MultipartFormDataContent object, which facilitates requests. When a MultipartFormDataContent object is supplied for Body, any content related headers supplied to the ContentType, Headers, or WebSession parameters are overridden by the content headers of the object. This feature was added in PowerShell 6.0.0."
    },
    {
        "link": "https://learn.microsoft.com/en-us/powershell/module/Microsoft.PowerShell.Utility/invoke-restmethod?view=powershell-5.1",
        "document": "The cmdlet sends HTTP and HTTPS requests to Representational State Transfer (REST) web services that return richly structured data. PowerShell formats the response based to the data type. For an RSS or ATOM feed, PowerShell returns the Item or Entry XML nodes. For JavaScript Object Notation (JSON) or XML, PowerShell converts, or deserializes, the content into objects. Comments aren't permitted in the JSON data. When the REST endpoint returns multiple objects, the objects are received as an array. If you pipe the output from to another command, it is sent as a single object. The contents of that array are not enumerated for the next command on the pipeline. This cmdlet is introduced in Windows PowerShell 3.0. By default, script code in the web page may be run when the page is being parsed to populate the property. Use the UseBasicParsing switch to suppress this.\n\nExample 1: Get the PowerShell RSS feed\n\nIn the following example, a user runs to perform a POST request on an intranet website in the user's organization. $Cred = Get-Credential # Next, allow the use of self-signed SSL certificates. [System.Net.ServicePointManager]::ServerCertificateValidationCallback = { $true } # Create variables to store the values consumed by the Invoke-RestMethod command. # The search variable contents are later embedded in the body variable. $Server = 'server.contoso.com' $Url = \"https://${server}:8089/services/search/jobs/export\" $Search = \"search index=_internal | reverse | table index,host,source,sourcetype,_raw\" # The cmdlet handles URL encoding. The body variable describes the search criteria, specifies CSV as # the output mode, and specifies a time period for returned data that starts two days ago and ends # one day ago. The body variable specifies values for parameters that apply to the particular REST # API with which Invoke-RestMethod is communicating. $Body = @{ search = $Search output_mode = \"csv\" earliest_time = \"-2d@d\" latest_time = \"-1d@d\" } # Now, run the Invoke-RestMethod command with all variables in place, specifying a path and file # name for the resulting CSV output file. Invoke-RestMethod -Method Post -Uri $url -Credential $Cred -Body $body -OutFile output.csv {\"preview\":true,\"offset\":0,\"result\":{\"sourcetype\":\"contoso1\",\"count\":\"9624\"}} {\"preview\":true,\"offset\":1,\"result\":{\"sourcetype\":\"contoso2\",\"count\":\"152\"}} {\"preview\":true,\"offset\":2,\"result\":{\"sourcetype\":\"contoso3\",\"count\":\"88494\"}} {\"preview\":true,\"offset\":3,\"result\":{\"sourcetype\":\"contoso4\",\"count\":\"15277\"}}\n\nExample 4: Enumerate returned items on the pipeline\n\nSpecifies the body of the request. The body is the content of the request that follows the headers. You can also pipe a body value to . The Body parameter can be used to specify a list of query parameters or specify the content of the response. When the input is a GET request, and the body is an IDictionary (typically, a hash table), the body is added to the URI as query parameters. For other request types (such as POST), the body is set as the value of the request body in the standard name=value format. The verbose output of a POST body will end with , even though the size of the body is both known and sent in the HTTP header.\n\nSpecifies the content type of the web request. If the value for ContentType contains the encoding format (as ), the cmdlet uses that format to encode the body of the web request. If the ContentType doesn't specify an encoding format, the default encoding format is used instead. An example of a ContentType with an encoding format is , which specifies the Latin/Cyrillic alphabet. If you omit the parameter, the content type may be different based on the HTTP method you use:\n‚Ä¢ For a POST method, the content type is\n‚Ä¢ For a PUT method, the content type is\n‚Ä¢ For other methods, the content type isn't specified in the request If you are using the InFile parameter to upload a file, you should set the content type. Usually, the type should be . However, you need to set the content type based on the requirements of the endpoint.\n\nCreates a variable containing the web request session. Enter a variable name without the dollar sign ( ) symbol. When you specify a session variable, creates a web request session object and assigns it to a variable with the specified name in your PowerShell session. You can use the variable in your session as soon as the command completes. Unlike a remote session, the web request session isn't a persistent connection. It's an object that contains information about the connection and the request, including cookies, credentials, the maximum redirection value, and the user agent string. You can use it to share state and data among web requests. To use the web request session in subsequent web requests, specify the session variable in the value of the WebSession parameter. PowerShell uses the data in the web request session object when establishing the new connection. To override a value in the web request session, use a cmdlet parameter, such as UserAgent or Credential. Parameter values take precedence over values in the web request session. You can't use the SessionVariable and WebSession parameters in the same command."
    },
    {
        "link": "https://stackoverflow.com/questions/51649275/how-to-use-json-to-powershell-invoke-restmethod",
        "document": "I am trying to invoke the API using this request. This request is working fine in Postman. But how can I convert it to PowerShell ?\n\nThis is what I tried.\n\nI tried the JSON code in Postman. It's working fine. How can I use the same JSON code in PowerShell?"
    },
    {
        "link": "https://education.launchcode.org/azure/chapters/powershell-intro/cmdlet-invoke-restmethod.html",
        "document": "Invoke-RestMethod is a PowerShell cmdlet that provides the ability to send requests from the command line to a REST API.\n\ncan be used to make web requests to any server, but is specifically intended to work with REST APIs that use JSON as their data representations.\n\nThroughout this class, we have used Postman as a way for making requests to a RESTful API. Postman offers a GUI that is a very pleasant interface to work with. However, a GUI is not always the best interface for a given job. A benefit of making requests from a CLI is that you can combine as many requests as necessary into a single script. This creates the ability to automate interactions with a RESTful API.\n\nSimilarly to Postman, allows you to fully configure each HTTP request including setting the: The JSON responses received by an call are automatically converted from a JSON-formatted string to a PSCustomObject. The fields of the JSON response are then accessible as properties of this object using dot notation. These response objects can be used directly within a PowerShell session, in a script, or can be saved to a JSON file.\n\nOpen-Notify is a publicly available REST API that returns information about astronauts in space. The Open-Notify API contains live data that is continuously updated. Let‚Äôs explore this API by making a simple request for its resource using . The resource has the following shape: The field is an array of resources with the following shape: Let‚Äôs make a request for the resource. If you don‚Äôt specify the request method it will default to . will convert the JSON response to a . By default, these custom objects are printed in the terminal in a table presentation: 9.8.3.3. Grouping to Access Fields of the JSON Response¬∂ Using the grouping operator, we can access the array property of the custom object in the following way: The grouping operator will cause the to be executed first. The resulting custom object can then have its properties accessed using dot notation on the closing parenthesis: . Because we are working with objects, we can filter the response down further by piping the array object to the cmdlet: Storing the result in a variable becomes useful, so that we don‚Äôt have to keep making the same request to access its data: We can then work with the data through the variable. For example, we can access the field: We can also access the nested field of one of the astronauts by chaining property and array access: We can even use our variable to control how the array is sorted by piping it to the cmdlet: We can combine these steps in a longer pipe that:\n‚Ä¢ Sorts each element by their nested field In many cases it is beneficial to save transformed responses to a file for later use. Rather than just printing the converted results we can use the cmdlet to write to a file: You can then use the cmdlet to view the CSV contents as strings: If we wanted to save in a JSON format we would need to add an additional step in our pipeline to convert the custom object back to a JSON string. We use the cmdlet to accomplish this serialization from an object back to a JSON string: We can also split up this pipeline to make it more readable: This approach is invaluable for practicing with data transformations. Whereas a variable in our PowerShell terminal will disappear after closing, a file can be reused indefinitely and shared with others. You can then load the JSON contents as a string using : > Get-Content \"people.json\" [ { \"craft\": \"ISS\", \"name\": \"Anatoly Ivanishin\" }, { \"craft\": \"ISS\", \"name\": \"Bob Behnken\" }, { \"craft\": \"ISS\", \"name\": \"Chris Cassidy\" }, { \"craft\": \"ISS\", \"name\": \"Doug Hurley\" }, { \"craft\": \"ISS\", \"name\": \"Ivan Vagner\" } ] However, in order to work with the JSON contents as custom objects we need to convert it back (deserialize) using the cmdlet. This will enable dot-notation access of fields like in the original output: The cmdlet is a powerful tool for working with APIs. When combined with our knowledge of PowerShell, we have many options for interacting with a REST API and transforming the data we receive.\n\nLet‚Äôs test this out with our Coding Events API. To keep things simple, let‚Äôs use the branch so we don‚Äôt need to worry about setting up a database, a secrets manager, or AADB2C. Run this branch to start the Coding Events API on your local machine. To get a collection of coding events you could use: To get an individual coding event entity you could use: To delete an existing coding event entity you could use: To create a new coding event we need to use two additional options:\n‚Ä¢ : to define the body of the request To provide the body of the request you can use a HashTable object or a here-string. The object is simple to create: The object does not have any commas and uses the assignment operator for defining each key-value entry. However, before it can be used in the request it must be converted to JSON with an appropriate header.\n‚Ä¢ : in a grouped expression to serialize the as a JSON string\n‚Ä¢ The option: to automatically set the header of You can also load the body from a JSON file. This allows you to use existing files or a GUI editor to create the JSON body in a more intuitive way. Let‚Äôs assume we have a file with the following contents: > Get-Content ~\\coding-event.json { \"Title\": \"test title is long\", \"Description\": \"test description goes here\", \"Date\": \"2020-10-31\" } We could use this file as the contents of the request body using a grouped expression: You can use any of these defining approaches for creating and adding bodies to and requests as well. When used on a request the body will be converted to query string parameters in the URI.\n\n, like Postman, has many additional options we can use to further configure requests. You can look over the documentation of Invoke-RestMethod to get an understanding of its capabilities. You can work with any RESTful APIs using the cmdlet. To continue practicing you can work with any publicly available APIs like the GitHub Developer API."
    },
    {
        "link": "https://stackoverflow.com/questions/75669778/powershell-get-json-response-from-rest-api-update-a-property-and-then-put-jso",
        "document": "I am creating a Powershell script for a user that downloads a JSON object from our REST API, updates a value, then updates the API with the new version of the object. I cannot get this to work, our API either reports that the body is empty or malformed.\n\nThis is an example of the code that I am using:\n\nWhen done like this, the API reports that the body is empty. If I try to use ConvertTo-JSON, the API reports that the body is malformed.\n\nI need to use Powershell, as this script is run by another service that can only use Powershell scripts. The target machine is running Powershell 7.3.3."
    },
    {
        "link": "https://stackoverflow.com/questions/45470999/powershell-try-catch-and-retry",
        "document": "I created the following function for this same purpose. I use it in a bunch of my scripts. It allows for retries on both terminating errors (i.e. thrown exceptions) and non-terminating errors (i.e. Write-Error), provides an optional exponential backoff, and allows specified types of errors to not be retries (e.g. there's no point trying to retry ).\n\nAnd here is an example of using it:\n\nHere's another example of using it for a web request:\n\nYou can read more about building the function, see more examples, and get the latest code here."
    },
    {
        "link": "https://endjin.com/blog/2014/07/how-to-retry-commands-in-powershell",
        "document": "Recently while working on a set of scripts to provision some infrastructure in Azure, I needed to be able to retry various commands in case of intermittent failures.\n\nWith remote infrastructure in particular it is worth considering retry logic, because you never know when you might have trouble reaching it, or internal problems in the remote data centre.\n\nI was also parallelising some tasks using PowerShell background jobs. Each job at some point needed to access a configuration file. However without the ability to retry accessing the file, errors were occasionally being seen due to the file being locked by another process.\n\nHaving suitable retry logic can result in a much more robust application (or set of scripts)!\n\nWhat I needed was a PowerShell equivalent to the Endjin.Retry framework.\n\nAfter a little searching, I realised I'd have to implement the retry logic myself. As very similar retry behaviour ended up being used in multiple places, it was pulled out into a separate function, called Retry-Command:\n\nVerbose output for a failed Get-Process command that has retried the default number of times:\n\nAnd there we have it!\n\nI am aware that PowerShell Workflows allow retrying of activities, but didn't want to get into workflows for this particular requirement."
    },
    {
        "link": "https://sharepointdiary.com/2022/07/how-to-implement-retry-on-error-logic-in-powershell.html",
        "document": "When you‚Äôre running PowerShell scripts, errors are bound to happen: network timeouts, locked files, or even simple syntax issues. But instead of letting a script fail outright, wouldn‚Äôt it be better if it could retry the operation a few times before giving up? That‚Äôs where retry logic in PowerShell comes in.\n\nWhen using remote services such as SharePoint Online, Azure, or REST APIs, implementing retry logic in PowerShell is crucial for managing the temporary errors or network problems that may occur.\n\nRetry logic helps to automatically attempt the operation again, giving the script a chance to succeed without manual intervention. in this tutorial, I will walk you through the process of implementing retry logic in PowerShell using an approach that is both simple and highly effective.\n\nBefore we talk about retrying commands, let‚Äôs first understand how PowerShell handles errors. Not all errors are the same, and knowing the difference helps us decide when and how to retry.\n‚Ä¢ Terminating Errors ‚Äì These stop the script immediately unless handled by a / block.\n‚Ä¢ Non-Terminating Errors ‚Äì These allow the script to continue running, but they still get logged in the array.\n\nIf you want PowerShell to treat all errors as terminating (which is useful for retries), you can set:\n\nA / block is a structured way to handle errors:\n\nAnother way to manage errors is by using the parameter, which lets you control how PowerShell reacts when a command fails:\n\nBut setting at the top of your script applies this behavior globally.\n\nNow, let‚Äôs get to the meat of the matter ‚Äì implementing basic retry logic. The core idea is simple: if an operation fails, try it again‚Ä¶ within reason, of course! Retrying commands isn‚Äôt just about running them again and again. It‚Äôs about retrying smartly ‚Äì with limits, delays, and proper handling.\n\nA simple way to implement retry logic is by using a loop:\n\nThis script tries a web request up to five times, waiting two seconds between each attempt. If it succeeds, it stops retrying. Let‚Äôs make it reusable function:\n\nUsing Try-Catch to Retry on Error in PowerShell\n\nInstead of using a loop separately, we can embed retry logic directly inside a / :\n\nThis script tries to delete a locked file and retries up to three times if it fails.\n\nSometimes, you need to handle different exceptions differently:\n\nBy adhering to these best practices, we can create more robust, reliable, and maintainable PowerShell scripts that gracefully handle errors and implement effective retry strategies.\n\nSometimes, we want to retry only if a specific type of error occurs. For example, retrying only if a command fails due to a timeout:\n\nLet‚Äôs create a reusable function to handle retries. This function will execute a block of code, and if it fails, it will wait for a specified interval before retrying the operation up to a maximum number of attempts.\n\nThe goal here is to attempt an operation multiple times before giving up, which can be particularly useful for dealing with transient errors or temporary resource unavailability.\n\nUse the function to wrap any operation that you want to implement retry logic for. Here‚Äôs an example of using this function to handle a web request:\n\nThis function takes a script block as input, along with optional parameters for the maximum number of attempts and delay between retries. It then executes the script block, catching any errors and retrying up to the specified number of times.\n\nLet‚Äôs say you want to retrieve data from a SharePoint Online site and handle transient errors. Here‚Äôs how you can use the retry logic function for this scenario:\n\nThis simple retry mechanism can significantly improve the reliability of our scripts, especially when dealing with operations that may fail due to temporary issues.\n\nTo solidify our understanding of PowerShell retry mechanisms, let‚Äôs explore some real-world examples where implementing retry logic can significantly improve script reliability and robustness. These examples draw from my personal experiences and common scenarios I‚Äôve encountered in various projects.\n\nExample 1: Add App to SharePoint with Retry Logic\n\nExample 3: Retry in File Copy using Do-While Loop\n\nExample 4: Get Sign-in Logs with Endless Retry Logic\n\nIn this scenario, we‚Äôre interacting with an API that has rate limiting. We‚Äôll implement a retry mechanism that respects these limits:\n\nThis function handles rate limiting (HTTP 429 status) differently from other errors, implementing an exponential backoff strategy.\n\nThese real-world examples demonstrate how to apply retry logic in various scenarios, handling specific error conditions and implementing appropriate delay strategies. By adapting these patterns to your specific needs, you can significantly improve the reliability and resilience of your PowerShell scripts in production environments.\n\nWhile implementing retry logic can significantly improve the reliability of our PowerShell scripts, there are several common pitfalls that we need to be aware of and avoid. Based on my experience, here are some of the most frequent issues and how to mitigate them:\n\nNot all errors should be retried. For instance, retrying authentication failures due to invalid credentials won‚Äôt suddenly make them valid. Be selective about which errors trigger a retry.\n\nSimply retrying without addressing or logging the root cause can mask underlying issues. Always log detailed error information.\n\nAlways implement a maximum retry count or a timeout to prevent infinite loops.\n\nLogging retry attempts can be useful for debugging:\n\nFor some operations, especially those involving external services, retrying too quickly can exacerbate the problem. Implement exponential backoff to space out retry attempts.\n\nAggressive retries can sometimes overwhelm external systems. Be mindful of rate limits and the load you‚Äôre putting on other services.\n\nLet me share some best practices and mistakes I‚Äôve made so you don‚Äôt have to:\n‚Ä¢ Use appropriate retry intervals ‚Äì Short delays prevent unnecessary waits; long delays prevent excessive resource use.\n‚Ä¢ Set reasonable maximum attempts ‚Äì Avoid endless loops that might crash the script.\n‚Ä¢ Handle different error scenarios ‚Äì Retry only when necessary.\n‚Ä¢ Don‚Äôt retry on all errors ‚Äì some errors (like authentication failures) won‚Äôt be resolved by retrying\n‚Ä¢ Handle Cleanup in Finally Blocks: Use blocks to ensure resources are properly cleaned up, regardless of whether the operation succeeded or failed.\n\nBy adhering to these best practices, we can create more robust, reliable, and maintainable PowerShell scripts that gracefully handle errors and implement effective retry strategies.\n\nThrough this article, I‚Äôve shared my real-world experience with PowerShell retry implementations. Implementing retry logic in PowerShell scripts is a smart way to make your scripts more resilient to transient errors ‚Äì especially when working with networks, APIs, and file operations. Whether you use loops, Try-Catch, or reusable functions, the key is retrying smartly to prevent unnecessary failures.\n\nImplementing retry logic in PowerShell isn‚Äôt just about copying and pasting code ‚Äì it‚Äôs about understanding your specific use case and crafting a solution that fits. Start with the basic patterns I‚Äôve shared, adapt them to your needs, and always test thoroughly."
    },
    {
        "link": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry",
        "document": "Enable an application to handle transient failures when it tries to connect to a service or network resource, by transparently retrying a failed operation. This can improve the stability of the application.\n\nAn application that communicates with elements running in the cloud has to be sensitive to the transient faults that can occur in this environment. Faults include the momentary loss of network connectivity to components and services, the temporary unavailability of a service, or timeouts that occur when a service is busy.\n\nThese faults are typically self-correcting, and if the action that triggered a fault is repeated after a suitable delay it's likely to be successful. For example, a database service that's processing a large number of concurrent requests can implement a throttling strategy that temporarily rejects any further requests until its workload has eased. An application trying to access the database might fail to connect, but if it tries again after a delay it might succeed.\n\nIn the cloud, transient faults should be expected and an application should be designed to handle them elegantly and transparently. Doing so minimizes the effects faults can have on the business tasks the application is performing. The most common design pattern to address is to introduce a retry mechanism.\n\nThe diagram above illustrates invoking an operation in a hosted service using a retry mechanism. If the request is unsuccessful after a predefined number of attempts, the application should treat the fault as an exception and handle it accordingly.\n\nIf an application detects a failure when it tries to send a request to a remote service, it can handle the failure using the following strategies:\n‚Ä¢ None Cancel. If the fault indicates that the failure isn't transient or is unlikely to be successful if repeated, the application should cancel the operation and report an exception.\n‚Ä¢ None Retry immediately. If the specific fault reported is unusual or rare, like a network packet becoming corrupted while it was being transmitted, the best course of action may be to immediately retry the request.\n‚Ä¢ None Retry after delay. If the fault is caused by one of the more commonplace connectivity or busy failures, the network or service might need a short period while the connectivity issues are corrected or the backlog of work is cleared, so programatically delaying the retry is a good strategy. In many cases, the period between retries should be chosen to spread requests from multiple instances of the application as evenly as possible to reduce the chance of a busy service continuing to be overloaded.\n\nIf the request still fails, the application can wait and make another attempt. If necessary, this process can be repeated with increasing delays between retry attempts, until some maximum number of requests have been attempted. The delay can be increased incrementally or exponentially, depending on the type of failure and the probability that it'll be corrected during this time.\n\nThe application should wrap all attempts to access a remote service in code that implements a retry policy matching one of the strategies listed above. Requests sent to different services can be subject to different policies.\n\nAn application should log the details of faults and failing operations. This information is useful to operators. That being said, in order to avoid flooding operators with alerts on operations where subsequently retried attempts were successful, it is best to log early failures as informational entries and only the failure of the last of the retry attempts as an actual error. Here is an example of how this logging model would look like.\n\nIf a service is frequently unavailable or busy, it's often because the service has exhausted its resources. You can reduce the frequency of these faults by scaling out the service. For example, if a database service is continually overloaded, it might be beneficial to partition the database and spread the load across multiple servers.\n\nYou should consider the following points when deciding how to implement this pattern.\n\nThe retry policy should be tuned to match the business requirements of the application and the nature of the failure. For some noncritical operations, it's better to fail fast rather than retry several times and impact the throughput of the application. For example, in an interactive web application accessing a remote service, it's better to fail after a smaller number of retries with only a short delay between retry attempts, and display a suitable message to the user (for example, \"please try again later\"). For a batch application, it might be more appropriate to increase the number of retry attempts with an exponentially increasing delay between attempts.\n\nAn aggressive retry policy with minimal delay between attempts, and a large number of retries, could further degrade a busy service that's running close to or at capacity. This retry policy could also affect the responsiveness of the application if it's continually trying to perform a failing operation.\n\nIf a request still fails after a significant number of retries, it's better for the application to prevent further requests going to the same resource and simply report a failure immediately. When the period expires, the application can tentatively allow one or more requests through to see whether they're successful. For more details of this strategy, see the Circuit Breaker pattern.\n\nConsider whether the operation is idempotent. If so, it's inherently safe to retry. Otherwise, retries could cause the operation to be executed more than once, with unintended side effects. For example, a service might receive the request, process the request successfully, but fail to send a response. At that point, the retry logic might re-send the request, assuming that the first request wasn't received.\n\nA request to a service can fail for a variety of reasons raising different exceptions depending on the nature of the failure. Some exceptions indicate a failure that can be resolved quickly, while others indicate that the failure is longer lasting. It's useful for the retry policy to adjust the time between retry attempts based on the type of the exception.\n\nConsider how retrying an operation that's part of a transaction will affect the overall transaction consistency. Fine tune the retry policy for transactional operations to maximize the chance of success and reduce the need to undo all the transaction steps.\n‚Ä¢ None Ensure that all retry code is fully tested against a variety of failure conditions. Check that it doesn't severely impact the performance or reliability of the application, cause excessive load on services and resources, or generate race conditions or bottlenecks.\n‚Ä¢ None Implement retry logic only where the full context of a failing operation is understood. For example, if a task that contains a retry policy invokes another task that also contains a retry policy, this extra layer of retries can add long delays to the processing. It might be better to configure the lower-level task to fail fast and report the reason for the failure back to the task that invoked it. This higher-level task can then handle the failure based on its own policy.\n‚Ä¢ None Log all connectivity failures that cause a retry so that underlying problems with the application, services, or resources can be identified.\n‚Ä¢ None Investigate the faults that are most likely to occur for a service or a resource to discover if they're likely to be long lasting or terminal. If they are, it's better to handle the fault as an exception. The application can report or log the exception, and then try to continue either by invoking an alternative service (if one is available), or by offering degraded functionality. For more information on how to detect and handle long-lasting faults, see the Circuit Breaker pattern.\n\nWhen to use this pattern\n\nUse this pattern when an application could experience transient faults as it interacts with a remote service or accesses a remote resource. These faults are expected to be short lived, and repeating a request that has previously failed could succeed on a subsequent attempt.\n\nThis pattern might not be useful:\n‚Ä¢ When a fault is likely to be long lasting, because this can affect the responsiveness of an application. The application might be wasting time and resources trying to repeat a request that's likely to fail.\n‚Ä¢ For handling failures that aren't due to transient faults, such as internal exceptions caused by errors in the business logic of an application.\n‚Ä¢ As an alternative to addressing scalability issues in a system. If an application experiences frequent busy faults, it's often a sign that the service or resource being accessed should be scaled up.\n\nAn architect should evaluate how the Retry pattern can be used in their workload's design to address the goals and principles covered in the Azure Well-Architected Framework pillars. For example:\n\nAs with any design decision, consider any tradeoffs against the goals of the other pillars that might be introduced with this pattern.\n\nRefer to the Implement a retry policy with .NET guide for a detailed example using the Azure SDK with built-in retry mechanism support.\n‚Ä¢ None Before writing custom retry logic, consider using a general framework such as Polly for .NET or Resilience4j for Java.\n‚Ä¢ None When processing commands that change business data, be aware that retries can result in the action being performed twice, which could be problematic if that action is something like charging a customer's credit card. Using the Idempotence pattern described in this blog post can help deal with these situations.\n‚Ä¢ None Reliable web app pattern shows you how to apply the retry pattern to web applications converging on the cloud.\n‚Ä¢ None For most Azure services, the client SDKs include built-in retry logic.\n‚Ä¢ None Circuit Breaker pattern. If a failure is expected to be more long lasting, it might be more appropriate to implement the Circuit Breaker pattern. Combining the Retry and Circuit Breaker patterns provides a comprehensive approach to handling faults."
    },
    {
        "link": "https://blog.danskingdom.com/A-PowerShell-function-to-easily-retry-any-code",
        "document": "Performing retries to make your code more resilient is a common pattern. By leveraging a PowerShell , we can create a function to avoid constantly rewriting the same retry logic again and again.\n\nThis post shows how you can build a PowerShell function to easily retry any PowerShell code that produces a terminating or non-terminating error. If you want to skip the explanation and evolution of the code, jump to the bottom of this post to see the final function and examples, or view them on my GitHub gist here.\n\nHere‚Äôs the traditional way that you might write some code with retry logic:\n\nYou can see that the code above will attempt to perform the command up to 5 times, waiting 3 seconds between each attempt. If all 5 attempts fail, it will throw the exception.\n\nNow suppose later in your code you need to call , and then , and you wanted retry logic for those as well. Rather than repeating all of the above code, we can wrap it in a function and pass in the to execute.\n\nHere is what the function might look like:\n\nYou can see that the code is pretty much identical, except the function takes in the to execute and the maximum number of attempts as parameters, and instead of calling directly, we use to execute the .\n\nWith this function defined, we can now execute our commands, with retries, like this:\n\nYou may have noticed a potential problem with our function. It will only retry terminating errors; that is, exceptions that are n, but not non-terminating errors, such as when the error action is (the default).\n\nOn potential solution is to convert all non-terminating errors to terminating errors by using the variable at the start of your script:\n\nThis will affect the entire script though, and is likely not what you want. Another alternative is to use the parameter of the specific cmdlets that might produce non-terminating errors. In our previous example, you could do this:\n\nThis would ensure that any errors written by the cmdlet would be treated as terminating errors (e.g. thrown exceptions) and would get retried. Having to add to every cmdlet is tedious and error prone though.\n\nA better way we can address this is to add a check for non-terminating errors and throw them if they occur, by making use of the parameter on our :\n\nNow both terminating and non-terminating errors will be retried üôÇ\n\nNow that we have a nice reusable function, let‚Äôs improve it to make it more flexible and use parameter validation. We can add parameters so the user can configure how long to wait between retries, whether to use exponential backoff, provide a list of errors that should not be retried, and whether to retry non-terminating errors or not:\n\n\"The maximum number of times to attempt the script block when it returns an error.\" \"The number of milliseconds to wait between retry attempts.\" \"If true, the number of milliseconds to wait between retry attempts will be multiplied by the number of attempts.\" \"List of error messages that should not be retried. If the error message contains one of these strings, the script block will not be retried.\" \"If true, only terminating errors (e.g. thrown exceptions) will cause the script block will be retried. By default, non-terminating errors will also trigger the script block to be retried.\" # Break out of the while-loop since the command succeeded. # If the errorMessage contains one of the errors that should not be retried, then throw the error. ' was found in the error message, so not retrying.\"\n\nHere is a contrived example of how you might use the updated function:\n\nAnd here is the output you might see when running the above code, where it first fails with an exception, and then fails with an error, and succeeds on the 3rd attempt:\n\nIf you do not want non-terminating errors to be retried (e.g. the cases in the above), provide the switch parameter.\n\nYou may have noticed that the verbose output includes the error message and error details. This is because some cmdlets, such as , sometimes put the error message in the ErrorDetails property.\n\nHere are some more practical examples:\n\nExample 1: Stop a service if it exists\n\nThis will only retry if the service ‚ÄúSomeService‚Äù exists. If it doesn‚Äôt, the error message ‚ÄúCannot find any service with service name ‚ÄòSomeService‚Äô.‚Äù would be returned and the function won‚Äôt bother retrying.\n\nNote: PowerShell 6+ have built-in Retry parameters on the Invoke-WebRequest and Invoke-RestMethod cmdlets that could be used instead.\n\nIf you want to take additional actions on failures that still occur after all of the retries, you can catch the exception and handle it as needed.\n\nExample 4: Do not retry expected errors\n\nThere may be certain errors that are expected in certain situations, or where you know a retry will not help. To save time, specify not to retry on these errors:\n\nBecause we use a scriptblock, we can perform multiple actions and if any of them fail, the entire scriptblock will be retried:\n\nOne caveat with the above implementation is that non-terminating errors will be thrown as terminating errors if they are still failing after all of the retries, which may not be the desired behavior. I typically prefer to have all persisting errors thrown, as it allows for a single way to handle any errors produced by the script block (i.e. with a try-catch block).\n\nFor those that do not want this behaviour, I offer this final implementation that is not quite as straightforward, but provides an additional parameter that allows for non-terminating errors to not be thrown if they are still failing after all of the retries:\n\n\"The maximum number of times to attempt the script block when it returns an error.\" \"The number of milliseconds to wait between retry attempts.\" \"If true, the number of milliseconds to wait between retry attempts will be multiplied by the number of attempts.\" \"List of error messages that should not be retried. If the error message contains one of these strings, the script block will not be retried.\" \"If true, only terminating errors (e.g. thrown exceptions) will cause the script block will be retried. By default, non-terminating errors will also trigger the script block to be retried.\" \"If true, any non-terminating errors that occur on the final retry attempt will not be thrown as a terminating error.\" # Break out of the while-loop since the command succeeded. # If the errorMessage contains one of the errors that should not be retried, then do not retry. ' was found in the error message, so not retrying.\" # Break out of the foreach-loop since we found a match. # Just break out of the while-loop since the error was already written to the error stream. # Throw the error so it's obvious one occurred.\n\nYou can also find this implementation and examples on my GitHub gist here.\n\nBy using a function like , you can make your scripts more resilient to failures and avoid repeating the same retry logic over and over.\n\nThis is a function that I use in many of my scripts. Feel free to use it as-is, or update it to suit your needs. Have feedback or suggestions? Let me know by leaving a comment below."
    }
]